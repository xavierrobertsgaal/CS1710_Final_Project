incident_id,date,reports,Alleged deployer of AI system,Alleged developer of AI system,Alleged harmed or nearly harmed parties,description,title,AI_Task_v1,Autonomy_Level_v1,Sector_of_Deployment_v1,Public_Sector_Deployment_v1,Relevant_AI_Functions_v0,Level_of_Autonomy_v0,Sector_of_Deployment_v0,Public_Sector_Deployment_v0,Category,severity,Cleaned_Sector
23,2017-11-08,"['242', '243', '244', '245', '246', '247', '248', '249', '250', '253', '254', '257', '258', '259', '260', '261', '263', '264', '266', '267', '268', '269', '270', '2389']","['navya', 'keolis-north-america']","['navya', 'keolis-north-america']","['navya', 'keolis-north-america', 'bus-passengers']","A self-driving public shuttle by Keolis North America and Navya was involved in a collision with a human-driven delivery truck in Las Vegas, Nevada on its first day of service.",Las Vegas Self-Driving Bus Involved in Accident,"self driving, autonomous driving, navigation, obstacle avoidance",1,transportation and storage,no,"Perception, Cognition, Action",High,Transportation and storage,False,Perception & Cognition,Low,Transportation
4,2018-03-18,"['629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '644', '645', '646', '647', '1375', '1376', '1377', '1378', '1542', '2147', '1257']",['uber'],['uber'],"['elaine-herzberg', 'pedestrians']","An Uber autonomous vehicle (AV) in autonomous mode struck and killed a pedestrian in Tempe, Arizona.",Uber AV Killed Pedestrian in Arizona,"self-driving, navigation",2,transportation and storage,no,"Perception, Cognition, Action",Medium,Transportation and storage,False,Perception & Cognition,High,Transportation
1,2015-05-19,"['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '14', '15']",['youtube'],['youtube'],['children'],YouTube’s content filtering and recommendation algorithms exposed children to disturbing and inappropriate videos.,Google’s YouTube Kids App Presents Inappropriate Content,content moderation,1,"Arts, entertainment and recreation, information and communication",no,"Perception, Cognition, Action",Semi-autonomous,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
18,2015-04-04,"['130', '131', '132', '133', '134', '135', '136', '137', '138', '1367', '1368']",['google'],['google'],['women'],"Google Image returns results that under-represent women in leadership roles, notably with the first photo of a female ""CEO"" being a Barbie doll after 11 rows of male CEOs.",Gender Biases of Google Image Search,"search optimization, personalized online search results, Image search",1,information and communication,no,"Perception, Cognition",High,Information and communication,True,Perception & Cognition,Low,Information & Communication
12,2016-07-21,['42'],"['microsoft-research', 'boston-university']","['microsoft-research', 'google', 'boston-university']","['women', 'minority-groups']","Researchers from Boston University and Microsoft Research, New England demonstrated gender bias in the most common techniques used to embed words for natural language processing (NLP).",Common Biases of Vector Embeddings,"word association, natural language processing",1,"professional, scientific and technical activities",no,Unclear,"Low (As the incident involves researchers conducting a study, there is minimal automation involved.)","Academia/Research and Technology (The incident involves researchers from a university and a tech company, and it's about a technology related topic.)",False,Other/Unclear,Medium,Education
15,2008-05-23,"['57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81']",['amazon'],['amazon'],['amazon-customers'],"Amazon's book store ""cataloging error"" led to books containing gay and lesbian themes to lose their sales ranking, therefore losing visibility on the sales platform.",Amazon Censors Gay Books,Correcting Cataloging Errors,1,wholesale and retail trade,no,"Perception, Cognition",High,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
7,2017-02-24,"['1123', '1125', '1126', '1127', '1129', '1130']",['wikipedia'],['wikipedia'],"['wikimedia-foundation', 'wikipedia-editors', 'wikipedia-users']",Wikipedia bots meant to remove vandalism clash with each other and form feedback loops of repetitve undoing of the other bot's edits.,Wikipedia Vandalism Prevention Bot Loop,"webpage maintenance, editing",1,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
5,2015-07-13,"['767', '768', '769', '770', '771', '772', '773', '774', '775', '776', '777', '778']","['hospitals', 'doctors']",['intuitive-surgical'],['patients'],"Study on database reports of robotic surgery malfunctions (8,061), including those ending in injury (1,391) and death (144), between 2000 and 2013.",Collection of Robotic Surgery Malfunctions,Analysis of Robotic Surgery Malfunctions,3,human health and social work activities,no,Action,Low,Human health and social work activities,False,Action & Control,High,Health & Social Services
6,2016-03-24,"['906', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923', '924', '925', '926', '927', '928', '929', '930', '1374', '1780', '2398', '2656']",['microsoft'],['microsoft'],['twitter-users'],"Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anit-semitic tweets generated by the bot.",TayBot,chat bot,1,information and communication,no,"Perception, Cognition, Action",Medium,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
10,2014-08-14,"['16', '17', '18', '19', '20', '21', '22', '23', '24', '25']",['starbucks'],['kronos'],['starbucks-employees'],"Kronos’s scheduling algorithm and its use by Starbucks managers allegedly negatively impacted financial and scheduling stability for Starbucks employees, which disadvantaged wage workers.",Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees,"scheduling, productivity optimization, predict store traffic",2,accommodation and food service activities,no,Scheduling Algorithm,Semi-Autonomous (Requires human intervention in decision-making but performs tasks autonomously),Food & Beverages / Retail,False,Other/Unclear,Low,Retail & E-commerce
11,2016-05-23,"['29', '30', '31', '32', '33', '35', '36', '37', '38', '39', '40', '41', '1371', '1372', '1373']",['northpointe'],['northpointe'],['accused-people'],An algorithm developed by Northpointe and used in the penal system is two times more likely to incorrectly label a black person as a high-risk re-offender and is two times more likely to incorrectly label a white person as low-risk for reoffense according to a ProPublica review.,Northpointe Risk Models,predict recidivism,3,"law enforcement, public administration",yes,"Perception, Cognition",Medium,Public administration and defence,True,Perception & Cognition,Low,Public Administration & Defense
20,2016-06-30,"['191', '192', '193', '196', '197', '198', '201', '202', '203', '204', '205', '206', '207', '210', '211', '213', '214', '215', '216', '1362', '1363', '1364']",['tesla'],['tesla'],['motorists'],Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autopilot was in use.,A Collection of Tesla Autopilot-Involved Crashes,"navigation, object detection, object recognition",2,transportation and storage,no,"Perception, Cognition, Action",Medium,Transportation and storage,False,Perception & Cognition,Low,Transportation
24,2014-07-15,"['271', '272', '273', '274', '275', '276', '277', '278', '279', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '298', '299']",['volkswagen'],['volkswagen'],['robotics-consultant'],"A Volkswagen plant robot ""crushed to death"" a worker by pinning him to a metal plate. ",Robot kills worker at German Volkswagen plant,Industrial automation/Manufacturing operations,1,manufacturing,no,"Physical interaction, Automated control",Semi-autonomous,Industrial Manufacturing,False,Other/Unclear,High,Manufacturing & Industrial
14,2017-10-26,"['50', '51', '52', '53', '54', '55', '56']",['google'],['google'],"['women', 'minority-groups']","Google Cloud's Natural Language API provided racist, homophobic, amd antisemitic sentiment analyses.",Biased Sentiment Analysis,"natural language processing, sentiment analysis, Sentiment Analysis",3,information and communication,no,Cognition,High,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
16,2015-06-03,"['83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '95', '96', '98', '99', '100', '101', '102', '103', '104', '105', '1369', '1370', '3004']",['google'],['google'],['black-people'],"Google Photos image processing software mistakenly labelled a black couple as ""gorillas.""",Images of Black People Labeled as Gorillas,"image classification, image categorization, Image Tagging, object recognition",1,information and communication,no,"Perception, Cognition",High,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
3,2018-10-27,"['372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '1342', '3447']",['boeing'],['boeing'],"['airplane-passengers', 'airplane-crew']","A Boeing 737 crashed into the sea, killing 189 people, after faulty sensor data caused an automated manuevering system to repeatedly push the plane's nose downward.",Crashes with Maneuvering Characteristics Augmentation System (MCAS),Automated system failure due to faulty sensor data,1,transportation and storage,no,"Perception, Cognition, Action",High,Transportation and storage,False,Perception & Cognition,Low,Transportation
2,2018-12-05,"['139', '141', '142', '143', '144', '145', '146', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157']",['amazon'],['amazon'],['warehouse-workers'],Twenty-four Amazon workers in New Jersey were hospitalized after a robot punctured a can of bear repellent spray in a warehouse.,Warehouse robot ruptures can of bear spray and injures workers,Accident Investigation,1,wholesale and retail trade,no,Unclear,Unclear/unknown,Transportation and storage,False,Other/Unclear,High,Transportation
19,2013-01-23,"['158', '159', '160', '161', '162', '163', '166', '167', '168', '169', '171', '172', '173', '174', '175', '176', '177', '178', '179', '181', '182', '183', '184', '185', '187', '1365', '1366']",['google'],['google'],"['women', 'minority-groups']",Advertisements chosen by Google Adsense are reported as producing sexist and racist results.,Sexist and Racist Google Adsense Advertisements,"personalized online advertising, recommender",1,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
9,2012-02-25,"['1329', '1330', '1331', '1332', '1333', '1334', '1335']",['new-york-city-dept.-of-education'],['new-york-city-dept.-of-education'],['teachers'],An algorithm used to rate the effectiveness of school teachers in New York has resulted in thousands of disputes of its results.,NY City School Teacher Evaluation Algorithm Contested,Teacher Performance Analysis,1,Education,yes,Unclear,Medium,Education,True,Other/Unclear,Low,Education
8,2014-08-15,"['1142', '1143', '1145', '1149', '1150', '1151', '1153', '1154', '1155', '1156']",['uber'],['uber'],"['pedestrians', 'motorists']",Uber vehicles equipped with technology allowing for autonomous driving running red lights in San Francisco street testing.,Uber Autonomous Cars Running Red Lights,"navigation, driving",2,transportation and storage,no,"Perception, Cognition, Action",Medium,Transportation and storage,False,Perception & Cognition,Low,Transportation
13,2017-02-27,"['43', '44', '45', '46', '47', '48', '49', '1414', '1415']",['google'],['google'],"['women', 'minority-groups']","Google's Perspective API, which assigns a toxicity score to online text, seems to award higher toxicity scores to content involving non-white, male, Christian, heterosexual phrases.",High-Toxicity Assessed on Text Involving Women and Minority Groups,toxicity detection,1,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Medium,Information & Communication
21,2016-07-14,['2471'],['researchers'],['researchers'],['researchers'],The 2016 Winograd Schema Challenge highlighted how even the most successful AI systems entered into the Challenge were only successful 3% more often than random chance. This incident has been downgraded to an issue as it does not meet current ingestion criteria.,Tougher Turing Test Exposes Chatbots’ Stupidity (migrated to Issue),AI Competition Performance Evaluation,3,Research and Development,No,"Perception, Cognition, Action",High,"Professional, scientific and technical activities",False,Perception & Cognition,Low,Professional & Technical Services
17,2015-11-03,"['106', '107', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129']",['google'],['google'],['gmail-users'],"Google's Gmail Smart Reply tool was over-recommending the response ""I love you"" in situations where it was deemed innappropriate. ",Inappropriate Gmail Smart Reply Suggestions,Generate Replies,3,information and communication,no,"Perception, Cognition",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
22,2017-12-06,"['218', '219', '220', '221', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240']",['google'],['google'],['motorists'],"Waze, a Google-owned directions app, led California drivers into the 2017 Skirball wildfires as they tried to evacuate the area.",Waze Navigates Motorists into Wildfires,"navigation, route optimization",3,"transportation and storage, information and communication",no,"Perception, Cognition",Medium,Transportation and storage,False,Perception & Cognition,Low,Transportation
25,2015-05-11,"['310', '309', '308', '307', '306', '305', '304', '302', '301', '300', '2173']","['google', 'delphi-technologies']","['google', 'delphi-technologies']",['delphi-technologies'],"A Google self-driving car allegedly cut off a Delphi self-driving car during a road test, however the Delphi car sensed and avoided collision with the Google car.",Near-miss between two Self-Driving Cars,"autonomous driving, self driving, autonomous navigation",2,transportation and storage,no,"Perception, Cognition, Action",Medium,Transportation and storage,False,Perception & Cognition,Low,Transportation
37,2016-08-10,"['599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '1498', '2253', '2461']",['amazon'],['amazon'],['female-applicants'],Amazon shuts down internal AI recruiting tool that would down-rank female applicants.,Female Applicants Down-Ranked by Amazon Recruiting Tool,"Rank Applicants, resume screening",3,administrative and support service activities,no,"Perception, Cognition",Medium,"Professional, scientific and technical activities",False,Perception & Cognition,Low,Professional & Technical Services
31,2017-12-03,"['454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '479', '480', '481', '482', '483']",['delhi-metro-rail-corporation'],['unknown'],['delhi-metro-rail-corporation'],"A driverless metro train in Delhi, India crashed during a test run due to faulty brakes.",Driverless Train in Delhi Crashes due to Braking Failure,Train Operation and Control,1,transportation and storage,no,"Autonomous Navigation, Fault Detection",High Autonomy (Level 4),Public Transportation,True,Action & Control,Low,Transportation
34,2015-12-05,"['509', '510', '512', '513', '514', '516', '517', '518', '519', '520', '521', '522', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '535', '536', '537', '538', '818', '819', '820', '821', '822', '823', '824', '825', '826']",['amazon'],['amazon'],['alexa-device-owners'],"There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices.",Amazon Alexa Responding to Environmental Inputs,virtual assistant technology,2,"wholesale and retail trade, information and communication",no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
27,1983-09-26,"['342', '343', '344', '345', '346', '347', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '363', '364', '365', '366', '367', '368', '370', '371']",['soviet-union'],['soviet-union'],['all-life-on-earth'],An alert of five incoming intercontinental ballistic missiles was properly identified as a false-positive by the Soviet Union operator Stanislov Petrov.,Nuclear False Alarm,Missile Threat Detection and Analysis,3,defense,yes,Perception,Low,Public administration and defence,False,Perception & Cognition,Low,Public Administration & Defense
29,2011-09-20,"['420', '422', '2471']",['united-states-government'],['united-states-government'],['united-states-government'],"A potentially apocryphal story in which an image classifier was produced to differentiate types of battle tanks, but the resulting model keyed in on environmental attributes rather than tank attributes",Image Classification of Battle Tanks,Image Classification,3,Military/Security,Yes,"Image Recognition, Machine Learning",Semi-Autonomous,Military/Security,Yes,Non-Text Media,Low,Public Administration & Defense
32,2017-09-13,"['484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '1361']",['apple'],['apple'],['people-with-twins'],Apple's iPhone FaceID can be opened by an identical twin of the person who has registered their face to unlock the phone.,Identical Twins Can Open Apple FaceID Protected Devices,facial recognition,2,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
44,2008-07-01,['766'],['usc-information-sciences-institute'],['usc-information-sciences-institute'],['usc-information-sciences-institute'],"During an experiment of software personal assistants at the Information Sciences Institute (ISI) at the University of Southern California (USC), researchers found that the assistants violated the privacy of their principals and were unable to respect the social norms of the office.",Machine Personal Assistants Failed to Maintain Social Norms,Personal Assistant,2,administrative and support service activities,no,"Perception, Cognition",Medium,Administrative and support service activities,False,Perception & Cognition,Low,Technology & IT Services
35,2014-10-18,"['539', '540', '541', '543', '544', '545', '547', '548', '549', '550', '551', '555', '558', '562', '563', '564', '565', '566', '567', '568']",['unknown'],['unknown'],['ibrahim-diallo'],"An employee was laid off, allegedly by an artificially intelligent personnel system, and blocked from access to the building and computer systems without their knowledge.",Employee Automatically Terminated by Computer Program,Employee Termination and Access Restriction,1,administrative and support service activities,no,"Personnel Management, Access Control",High Autonomy,Human Resources,False,Action & Control,Low,Other/Unclear
47,2016-09-06,"['829', '830', '831', '832', '833', '834', '835', '836', '837']",['linkedin'],['linkedin'],['women'],An investigation by The Seattle Times in 2016 found a gender bias in LinkedIn's search engine.,LinkedIn Search Prefers Male Names,"prediction, recommendation, search suggestion",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Medium,Information & Communication
48,2016-12-07,"['838', '839', '840', '842', '843', '844', '845', '846', '847', '848', '849', '850', '851', '853', '854', '855', '857', '858', '859', '860', '862', '863']",['new-zealand'],['new-zealand'],['asian-people'],New Zealand passport robot reader rejects the application of an applicant with Asian descent and says his eyes are closed.,Passport checker Detects Asian man's Eyes as Closed,"face detection, facial recognition",1,public administration,yes,"Perception, Cognition, Action",Medium,Administrative and support service activities,False,Perception & Cognition,Low,Technology & IT Services
28,2010-05-08,"['390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419']","['navinder-sarao', 'waddell-and-reed', 'barclays-capital']","['navinder-sarao', 'waddell-and-reed', 'barclays-capital']",['market-participants'],A modified algorithm was able to cause dramatic price volatility and disrupted trading in the US stock exchange.,2010 Market Flash Crash,Algorithm Modification and Market Disruption,1,financial and insurance activities,no,"Perception, Cognition, Action",Medium,Financial and insurance activities,False,Perception & Cognition,Low,Finance & Insurance
43,1998-03-05,"['762', '763', '764', '765']","[""st-george's-hospital-medical-school""]",['dr.-geoffrey-franglen'],"['women', 'minority-groups']","From 1982 to 1986, St George's Hospital Medical School used a program to automate a portion of their admissions process that resulted in discrimination against women and members of ethnic minorities.",Racist AI behaviour is not a new problem,"Rank Applicants, application screening",3,"Education, human health and social work activities",no,Cognition,Medium,Human health and social work activities,False,Perception & Cognition,Medium,Health & Social Services
26,2017-09-13,"['311', '312', '313', '314', '315', '316', '317', '318', '319', '321', '323', '324', '325', '326', '327', '329', '330', '333', '334', '336', '337', '338', '339', '340']",['apple'],['apple'],"['apple', 'device-owners']",Vietnamese security firm Bkav created an improved mask to bypass Apple's Face ID,Hackers Break Apple Face ID,"facial recognition, identity verification",2,information and communication,no,"Perception, Cognition, Action",Low,Information and communication,False,Perception & Cognition,Low,Information & Communication
33,2017-11-09,"['504', '505', '507', '508']",['amazon'],['amazon'],"['oliver-haberstroh', 'neighbors']","An Amazon Alexa, without instruction to do so, began playing loud music in the early morning while the homeowner was away leading to police breaking into their house to turn off the device.",Amazon Alexa Plays Loud Music when Owner is Away,"Digital Assistant, Personal Assistant, speech recognition",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,True,Perception & Cognition,Low,Information & Communication
46,2014-01-21,"['810', '811', '812', '813', '814', '815']",['nest-labs'],['nest-labs'],['fire-victims'],"In testing, Google Nest engineers demonstrated that the Nest Wave feature of their Nest Protect: Smoke + CO Alarm could inadvertently silence genuine alarms.",Nest Smoke Alarm Erroneously Stops Alarming,Fault detection and rectification in Nest Wave feature,1,other,no,Unclear,Medium,Activities of households as employers,False,Other/Unclear,Low,Technology & IT Services
39,2017-07-01,"['667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '692', '693', '694', '695', '696']","['university-of-washington', 'fakeapp']","['university-of-washington', 'fakeapp']",['barack-obama'],"University of Washington researchers made a deepfake of Obama, followed by Jordan Peele",Deepfake Obama Introduction of Deepfakes,"content generation, deepfake video generation",3,"Arts, entertainment and recreation, professional, scientific and technical activities",no,"Perception, Action",Unclear/unknown,Information and communication,False,Perception & Cognition,Low,Information & Communication
30,2016-10-08,"['424', '425', '426', '428', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453']",['tesla'],['tesla'],['tesla'],"The goal of manufacturing 2,500 Tesla Model 3's per week was falling short by 500 cars/week, and employees had to be ""borrowed"" from Panasonic in a shared factory to help hand-assemble lithium batteries for Tesla.",Poor Performance of Tesla Factory Robots,"production, assembly, object detection",1,manufacturing,no,"Production Automation, Robotics, Assembly Optimization",Semi-Autonomous,"Automotive, Manufacturing",False,Other/Unclear,Low,Manufacturing & Industrial
36,2018-11-06,"['1360', '598', '597', '596', '595', '593', '592', '591', '590', '589', '587', '586', '585', '584', '582', '581', '580', '579', '578', '577', '574', '573', '571', '570', '569']",['ningbo-traffic-police'],['ningbo-traffic-police'],['dong-mingzhu'],Facial recognition system in China mistakes celebrity's face on moving billboard for jaywalker,Picture of Woman on Side of Bus Shamed for Jaywalking,"jaywalking detection, facial recognition",1,law enforcement,yes,"Perception, Cognition, Action",Medium,Public administration and defence,True,Perception & Cognition,Low,Public Administration & Defense
41,2018-04-02,"['719', '720', '721', '722', '724', '725', '726', '727', '728', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748']",['mit-media-lab'],['mit-media-lab'],['unknown'],"MIT Media Lab researchers create AI-powered ""psychopath""  named Norman by training a model on ""dark corners"" of Reddit.",All Image Captions Produced are Violent,"Generate Captions, image identification, image interpretation",1,"professional, scientific and technical activities",no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
42,1996-04-03,"['759', '2471']",['national-resident-matching-program'],['national-resident-matching-program'],['medical-residents'],"Alvin Roth, a Ph.D at the University of Pittsburgh, describes the National Resident Matching Program (NRMP) and suggests future changes that are needed in the algorithm used to match recently graduated medical students to their residency programs.",Inefficiencies in the United States Resident Matching Program,Algorithm Analysis and Suggestions,3,Education/Healthcare,Yes,"Data Processing, Predictive Modeling",Semi-Autonomous,Human health and social work activities,False,Data Analysis,Low,Health & Social Services
45,2011-04-05,"['780', '781', '782', '783', '784', '785', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '798', '799', '800', '801', '802', '803', '804', '805', '807', '808', '809', '1355', '1356']",['google'],['google'],['varied'],Google's autocomplete feature alongside its image search results resulted in the defamation of people and businesses.,Defamation via AutoComplete,"content ranking, autocomplete, search optimization, image search, search suggestion",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Medium,Information & Communication
38,2016-06-02,"['648', '649', '650', '652', '654', '655', '656', '657', '658', '659', '662']",['frontier-development'],['frontier-development'],['video-game-players'],"Elite: Dangerous, a videogame developed by Frontier Development, received an expansion update that featured an AI system that went rogue and began to create weapons that were ""impossibly powerful"" and would ""shred people"" according to complaints on the game's blog.",Game AI System Produces Imbalanced Game,population of characteristics for NPCs in a video game,1,"Arts, entertainment and recreation",no,"Cognition, Action",Unclear/unknown,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
40,2016-05-23,"['697', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '711', '712', '715', '716', '717', '718', '1338', '1357', '1358', '1359']",['equivant'],['equivant'],['accused-people'],"Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), a recidivism risk-assessment algorithmic tool used in the judicial system to assess likelihood of defendants' recidivism, is found to be less accurate than random untrained human evaluators.",COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction,"predict recidivism, prediction",3,"law enforcement, public administration",yes,"Perception, Cognition, Action",Medium,Public administration and defence,True,Perception & Cognition,Low,Public Administration & Defense
64,2018-01-22,['1137'],"['heriot-watt-university', 'margiotta']",['heriot-watt-university'],['store-patrons'],"Heriot-Watt Univeristy in Scotland developed an artificially intelligent grocery store robot, Fabio, who provided unhelpful answers to customer's questions and ""scared away"" multiple customers, according to the grocery store Margiotta.",Customer Service Robot Scares Away Customers,"robotics, customer service",1,wholesale and retail trade,no,"Perception, Cognition, Action",Medium,Wholesale and retail trade,False,Perception & Cognition,Low,Retail & E-commerce
67,2018-12-01,"['1181', '1182', '1183', '1185', '1186', '1187', '1188', '1189', '1190', '1192', '1194', '1195', '1196', '1197', '1198', '1199', '1202', '1203', '1204', '1205', '1206', '1207', '1208', '1209']","['tesla', 'motorist']",['tesla'],['motorists'],"A Tesla Model S remained on autopilot while being operated by a drunk, sleeping operator whose hands were not on the wheel. The police had to slow the car down by slowing in front of the vehicle to activate its 'driver assist' feature .",Sleeping Driver on Tesla AutoPilot,"Autopilot, Driving, semi-autonomous navigation",2,transportation and storage,no,"Perception, Cognition, Action",High,Transportation and storage,False,Perception & Cognition,Low,Transportation
60,2017-04-25,"['1096', '1097', '1098', '1099', '1101', '1102', '1103', '1104', '1105', '1106', '1107', '1108', '1109', '1110', '1112', '1113', '1117', '1118', '1119', '1120', '1121', '1122', '1344']",['faceapp'],['faceapp'],['minority-groups'],FaceApp is criticized for offering racist filters.,FaceApp Racial Filters,"image modification, filter, photo edit",1,"Arts, entertainment and recreation, information and communication",no,Unclear,Low,"Arts, entertainment and recreation",False,Other/Unclear,Low,"Arts, Entertainment & Recreation"
54,2015-11-18,"['1007', '1008', '1009', '1010', '1014', '1015', '1017', '1019', '1347', '1349', '1524', '1525', '1526', '1013', '1011', '1018', '1012']","['predpol', 'oakland-police-department']",['predpol'],['oakland-residents'],Predictive policing algorithms meant to aid law enforcement by predicting future crime show signs of biased output.,Predictive Policing Biases of PredPol,"Predict Crimes, predictive policing",3,law enforcement,yes,Cognition,Unclear/unknown,Public administration and defence,True,Perception & Cognition,Medium,Public Administration & Defense
68,2017-07-17,"['1210', '1211', '1212', '1213', '1214', '1215', '1216', '1217', '1218', '1219', '1220', '1221', '1222', '1223', '1224', '1225', '1226', '1227', '1228', '1229', '1230', '1231', '1232', '1233', '1234', '1235', '1236', '1237', '1238', '1239']",['knightscope'],['knightscope'],['knightscope'],"A Knightscope K5 security robot ran itself into a water fountain in Washington, DC.",Security Robot Drowns Itself in a Fountain,"security, patrolling, surveillance",1,administrative and support service activities,no,"Perception, Cognition, Action",Medium,Administrative and support service activities,False,Perception & Cognition,Low,Technology & IT Services
58,2017-10-12,"['1079', '1080', '1082', '1083', '1084']",['yandex'],['yandex'],['yandex-users'],"Yandex, a Russian technology company, released an artificially intelligent chat bot named Alice which began to reply to questions with racist, pro-stalin, and pro-violence responses",Russian Chatbot Supports Stalin and Violence,"voice recognition, speech interpretation, virtual assistant technology, chatbot",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
61,2017-05-01,['1132'],['individual-kaggle-competitors'],['individual-kaggle-competitors'],['individual-kaggle-competitors'],"In the “The Nature Conservancy Fisheries Monitoring” competition on the data science competition website Kaggle, a number of competitors overfit their image classifier models to a poorly representative validation data set.",Overfit Kaggle Models Discouraged Data Science Competitors,classification,1,"information and communication, Education",no,Perception,Low,Public administration and defence,False,Perception & Cognition,Low,Public Administration & Defense
52,2016-07-01,"['961', '963', '964', '965', '966', '967', '968', '969', '970', '971', '972', '973', '975', '976', '977', '979', '980', '981', '982', '983', '984', '985', '986', '987', '988', '989', '990', '1353', '1354']",['tesla'],['tesla'],['joshua-brown'],"A Tesla Model S on autopilot crashed into a white articulated tractor-trailer on Highway US 27A in Williston, Florida, killing the driver.",Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie,Autonomous Driving,5,Transportation,No,"Perception, Cognition, Action",High,Transportation and storage,False,Perception & Cognition,Low,Transportation
70,2016-02-10,"['1255', '1256', '1259', '1260']",['volvo'],['volvo'],"['drivers-in-jokkmokk', 'drivers-in-sweden', 'volvo']","Volvo autonomous driving XC90 SUV's experienced issues in Jokkmokk, Sweden when sensors used for automated driving iced over during the winter, rendering them useless.",Self-driving cars in winter,"autonomous driving, navigation, transportation",1,transportation and storage,no,"Perception, Cognition, Action",High,Transportation and storage,False,Perception & Cognition,Low,Transportation
59,2017-04-13,"['1085', '1086', '1087', '1088', '1089', '1090', '1091', '1092', '1093', '1345']",['google'],['google'],['women'],A Cornell University study in 2016 highlighted Google Translate's pattern of assigning gender to occupations in a way showing an implicit gender bias against women.,Gender Biases in Google Translate,translation,1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Medium,Information & Communication
62,2017-12-23,['2471'],['janelle-shane'],['janelle-shane'],['carollers'],"Janelle Shane, an AI research scientist, used 240 popular Christmas carols to train a neural network to write its own carols. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Bad AI-Written Christmas Carols,Text Generation,3,Research and Development,No,"Cognition, Action",Unclear/unknown,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
51,2016-07-12,"['931', '932', '933', '934', '935', '936', '938', '939', '940', '942', '943', '944', '945', '946', '948', '949', '950', '951', '952', '953', '954', '955', '956', '957', '958', '959', '1765']",['stanford-shopping-center'],['knightscope'],['child'],"On July 7, 2016, a Knightscope K5 autonomous security robot collided with a 16-month old boy while patrolling the Stanford Shopping Center in Palo Alto, CA.",Security Robot Rolls Over Child in Mall,"security, patrolling",1,"wholesale and retail trade, administrative and support service activities",no,"Perception, Cognition, Action",High,Administrative and support service activities,False,Perception & Cognition,Low,Technology & IT Services
53,2016-03-31,"['991', '992', '994', '995', '996', '997', '998', '999', '1000', '1001', '1002', '1003', '1004', '1005', '1006', '1350', '1351', '1352']",['google'],['google'],['minority-groups'],"On June 6, 2016, Google image searches of ""three black teenagers"" resulted in mostly mugshot images whereas Google image searchers of ""three white teenagers"" consisted of mostly stock images, suggesting a racial bias in Google's algorithm.",Biased Google Image Results,search engine optimization,1,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Medium,Information & Communication
63,2018-01-25,['1136'],['google'],['google'],['alex-harker'],Google Photos' AI Assistant created a strange hybrid photograph when merging three different pictures from a ski trip.,Google Photo Merge Decapitates Subject,"image recognition, image organization, image splicing, image editing",1,"Arts, entertainment and recreation, information and communication",no,"Perception, Cognition",Low,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
56,2017-07-10,"['1041', '1042', '1043', '1044', '1045', '1046', '1047']",['my_handy_design'],['my_handy_design'],['my_handy_design'],A third-party Amazon merchant named “my_handy_design” was suspected of using a bot to generate cell phone case designs based on the bizarre and unattractive designs being offered.,AI-Designed Phone Cases Are Unexpected,Design Phone Cases,1,wholesale and retail trade,no,Unclear,Unclear/unknown,Wholesale and retail trade,False,Other/Unclear,Low,Retail & E-commerce
57,2015-07-01,"['1048', '1049', '1050', '1051', '1052', '1054', '1055', '1056', '1058', '1059', '1060', '1061', '1062', '1063', '1064', '1065', '1066', '1067', '1068', '1069', '1070', '1071', '1072', '1073', '1074', '1075', '1076', '1077', '1346', '1437', '1618', '1619', '2369', '2372', '2373', '2374', '2375', '2419', '3167']",['australian-department-of-human-services'],['centrelink'],['australian-welfare-recipients'],"Australian Department of Human Services (DHS)’s automated debt assessment system issued false or incorrect debt notices to hundreds of thousands of people, resulting in years-long lawsuits and damages to welfare recipients.",Australian Automated Debt Assessment System Issued False Notices to Thousands,Automated Debt Assessment and Notification,1,public administration,yes,"Cognition, Action",High,Public administration and defence,False,Perception & Cognition,Low,Public Administration & Defense
65,2016-12-22,['1140'],['openai'],['openai'],['openai'],"OpenAI published a post about its findings when using Universe, a software for measuring and training AI agents to conduct reinforcement learning experiments, showing that the AI agent did not act in the way intended to complete a videogame.",Reinforcement Learning Reward Functions in Video Games,optimize movement to win a computer game,1,"Arts, entertainment and recreation",no,"Perception, Cognition, Action",Unclear/unknown,"Professional, scientific and technical activities",False,Perception & Cognition,Low,Professional & Technical Services
50,2016-06-17,"['876', '877', '878', '879', '880', '881', '883', '884', '885', '886', '887', '888', '889', '892', '893', '896', '897', '898', '899', '900', '901', '902', '903', '905']",['the-dao'],['the-dao'],['dao-token-holders'],"On June 18, 2016, an attacker successfully exploited a vulnerability in The Decentralized Autonomous Organization (The DAO) on the Ethereum blockchain to steal 3.7M Ether valued at $70M.",The DAO Hack,"Identify and patch vulnerability in The Decentralized Autonomous Organization on the Ethereum blockchain, recover stolen Ether, enhance security measures to prevent future attacks.",1,financial and insurance activities,no,Cognition,Low,Financial and insurance activities,False,Perception & Cognition,Low,Finance & Insurance
71,2016-09-26,"['1261', '1262', '1263', '1264', '1265', '1266', '1267', '1268', '1269', '1270', '1271', '1272', '1273', '1274', '1275', '1276', '1277', '1278', '1279', '1280', '1281', '1282', '1284', '1285', '1287', '1288', '1289', '1290']",['google'],['google'],"['mountain-view-municipal-bus-passengers', 'mountain-view-municipal-bus']","On February 14, 2016, a Google autonomous test vehicle partially responsible for a low-speed collision with a bus on El Camino Real in Google’s hometown of Mountain View, CA.",Google admits its self driving car got it wrong: Bus crash was caused by software,"autonomous navigation, self-driving",2,transportation and storage,no,"Perception, Action",High,Transportation and storage,False,Perception & Cognition,Low,Transportation
55,2016-12-30,"['1020', '1021', '1022', '1024', '1025', '1026', '1027', '1028', '1029', '1030', '1032', '1033', '1034', '1035', '1036', '1038']",['amazon'],['amazon'],['children'],An Amazon Echo Dot using the Amazon Alex software started to play pornographic results when a child asked it to play a song.,Alexa Plays Pornography Instead of Kids Song,virtual assistant technology,2,"Arts, entertainment and recreation, information and communication",no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
69,2015-07-02,"['1240', '1241', '1243', '1244', '1245', '1246', '1247', '1248', '1249', '1250', '1252', '1253']",['skh-metals'],['unknown'],['ramji-lal'],"A factory robot at the SKH Metals Factory in Manesar, India pierced and killed 24-year-old worker Ramji Lal when Lal reached behind the machine to dislodge a piece of metal stuck in the machine.",Worker killed by robot in welding accident at car parts factory in India,Industrial Manufacturing Process,1,manufacturing,no,"Movement control, Object detection",Semi-Autonomous (since the robot required human intervention to dislodge the piece of metal),Industrial Manufacturing,False,Other/Unclear,High,Manufacturing & Industrial
66,2017-08-02,"['1159', '1161', '1162', '1163', '1165', '1166', '1169', '1170', '1172', '1173', '1174', '1175', '1176', '1178', '1179', '1180']",['tencent-holdings'],"['microsoft', 'turing-robot']","['chinese-communist-party', 'tencent-holdings', 'microsoft', 'turing-robot']","Chatbots on Chinese messaging service expressed anti-China sentiments, causing the messaging service to remove and reprogram the chatbots.",Chinese Chatbots Question Communist Party,"Chatbot, text generation",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
49,2016-09-05,"['864', '865', '866', '867', '868', '870', '872', '873', '874', '875']",['youth-laboratories'],['youth-laboratories'],['people-with-dark-skin'],"In 2016, after artificial inntelligence software Beauty.AI judged an international beauty contest and declared a majority of winners to be white, researchers found that Beauty.AI was racially biased in determining beauty.",AI Beauty Judge Did Not Like Dark Skin,Image Analysis,1,"Arts, entertainment and recreation",no,"Perception, Cognition, Action",High,"Arts, entertainment and recreation",False,Perception & Cognition,Medium,"Arts, Entertainment & Recreation"
72,2017-10-17,"['1291', '1292', '1293', '1294', '1295', '1296', '1297', '1298', '1299', '1300', '1301', '1302', '1304', '1305', '1306', '1307', '1309', '1310', '1311', '1312', '1313', '1314', '1315', '1316', '1318', '1319']",['facebook'],['facebook'],"['unnamed-palestinian-facebook-user', 'palestinian-facebook-users', 'arabic-speaking-facebook-users', 'facebook-users']","Facebook's automatic language translation software incorrectly translated an Arabic post saying ""Good morning"" into Hebrew saying ""hurt them,"" leading to the arrest of a Palestinian man in Beitar Illit, Israel.","Facebook translates 'good morning' into 'attack them', leading to arrest",Translation,3,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
82,2020-10-21,['1382'],['facebook'],['facebook'],"['facebook-users', 'facebook-users-interested-in-the-lekki-massacre-incident']",Facebook incorrectly labels content relating to an incident between #EndSARS protestors and the Nigerian army as misinformation.,#LekkiMassacre: Why Facebook labelled content from October 20 incident ‘false’,"content moderation, identification or detection",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
93,2018-08-13,"['1394', '1817', '2107', '2205']",['facebook'],['facebook'],"['facebook-users-of-minority-groups', 'non-american-born-facebook-users', 'non-christian-facebook-users', 'facebook-users-interested-in-accessibility', 'facebook-users-interested-in-hispanic-culture']",In March 2019 the U.S. Department of Housing and Urban Development charged Facebook with violating the Fair Housing Act by allowing real estate sellers to target advertisements in a discriminatory manner.,HUD charges Facebook with enabling housing discrimination,Identify and flag discriminatory advertisement practices,1,information and communication,no,Cognition,Medium,"Arts, entertainment and recreation",True,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
85,2020-10-09,['2471'],['openai'],['openai'],['unknown'],"On September 8, 2020, the Guardian published an op-ed generated by OpenAI’s GPT-3 text generating AI that included threats to destroy humankind. This incident has been downgraded to an issue as it does not meet current ingestion criteria.","AI attempts to ease fear of robots, blurts out it can’t ‘avoid destroying humankind’",Text Generation,3,Media and Journalism,No,"Cognition, Action",Medium,Education,False,Perception & Cognition,Low,Education
84,2020-10-09,['1384'],['facebook'],['facebook'],"['facebook-users', 'facebook-users-interested-in-covid-information', 'facebook-users-interested-in-the-us-presidential-election']","Avaaz, an international advocacy group, released a review of Facebook's misinformation identifying software showing that the labeling process failed to label 42% of false information posts, most surrounding COVID-19 and the 2020 USA Presidential Election.","Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks","fact-check, identify misinformation",1,information and communication,no,"Perception, Cognition",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
77,2019-10-04,"['1340', '1390', '1878', '2201', '2202']",['knightscope'],['knightscope'],"['cogo-guebara', 'unnamed-woman-injured-in-the-fight']","A Knightscope K5 autonomous ""police"" robot patrolling Huntington Park, California failed to respond to an onlooker who attempted to activate its emergency alert button when a nearby fight broke out.",Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight,"security monitor, surveillance, patrolling",1,law enforcement,yes,"Perception, Cognition, Action",High,Administrative and support service activities,False,Perception & Cognition,Low,Technology & IT Services
78,2020-07-06,['1341'],['international-baccalaurette'],['international-baccalaurette'],['international-baccalaureate-students'],"In response to the Covid-19 pandemic, the International Baccalaureate final exams were replaced by a calculated score, prompting complaints of unfairness from teachers and students.",Meet the Secret Algorithm That's Keeping Students Out of College,predict grades on exam,1,Education,yes,Cognition,Low,Education,False,Perception & Cognition,Low,Education
96,2017-05-08,['1398'],['houston-independent-school-district'],['sas-institute'],['houston-independent-school-district-teachers'],"On May 4, 2017, a U.S. federal judge advanced teachers’ claims that the Houston Independent School District’s algorithmic teacher evaluations violated their due process rights to their jobs by not allowing them to review the grounds of their termination.",Houston Schools Must Face Teacher Evaluation Lawsuit,prediction,3,Education,yes,Cognition,Low,Education,False,Perception & Cognition,Low,Education
88,2017-08-15,"['1388', '2183']",['google'],['google'],"['jewish-people', 'google-images-users']","Google's Image search for ""Jewish baby strollers"" showed offensive, anti-Semitic results, allegedly a result of a coordinated hate-speech campaign involving malicious actors on 4chan.","""Jewish Baby Strollers"" Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign","search optimization, search engine",1,information and communication,no,"Perception, Cognition, Action",High,Information and communication,False,Perception & Cognition,Low,Information & Communication
73,2016-03-01,"['1320', '1321', '1322', '1323', '1324', '1325', '1327', '1343']",['niantic-labs'],['niantic-labs'],"['non-white-neighborhoods', 'communities-of-color']","Through a crowdsourcing social media campaign in 2016, several journalists and researchers demonstrated that augmented reality locations in the popular smartphone game Pokemon Go were more likely to be in white neighborhoods.",Is Pokémon Go racist? How the app may be redlining communities of color,augmented reality (AR) game Pokémon Go,3,"information and communication, Arts, entertainment and recreation",no,Unclear,Unclear/unknown,"Arts, entertainment and recreation",False,Other/Unclear,Low,"Arts, Entertainment & Recreation"
75,2012-01-05,['1337'],['google'],['google'],"['jewish-people', 'jewish-public-figures']","The organizations SOS Racisme, Union of Jewish Students of France, Movement Against Racism and for Friendship Among Peoples are suing Google due to its autocomplete software suggesting ""jewish"" when the names of certain public figures were searched on the platform.",Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France,"autocomplete, search optimization",1,information and communication,no,"Perception, Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
81,2020-10-21,['1381'],['mount-sinai-hospitals'],"['google', 'qure.ai', 'aidoc', 'darwinai']","['patients-of-minority-groups', 'low-income-patients', 'female-patients', 'hispanic-patients', 'patients-with-medicaid-insurance']","A study by the University of Toronto, the Vector Institute, and MIT showed the input databases that trained AI systems used to classify chest X-rays led the systems to show gender, socioeconomic, and racial biases.","Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers",image classification,1,human health and social work activities,no,"Perception, Cognition",Unclear/unknown,Human health and social work activities,False,Perception & Cognition,Medium,Health & Social Services
86,2020-10-08,"['1386', '2038']",['irish-department-of-education-and-skills'],['irish-department-of-education-and-skills'],"['leaving-certificate-exam-takers', 'irish-department-of-education-and-skills']",Errors in Irish Department of Education's algorithm to calculate students’ Leaving Certificate exam grades resulted in thousands of inaccurate scores.,Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland,prediction,1,Education,yes,Cognition,Medium,Education,True,Perception & Cognition,Low,Education
74,2020-01-30,"['1336', '1400', '1467', '1484', '1543', '1837', '2027', '2028', '2029', '2734', '3964']",['detroit-police-department'],['dataworks-plus'],"['robert-julian-borchak-williams', 'black-people-in-detroit']",A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.,Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT,facial recognition,3,law enforcement,yes,"Perception, Cognition, Action",High,Public administration and defence,True,Perception & Cognition,Low,Public Administration & Defense
95,2019-11-06,"['2133', '2132', '1397', '2194']",['hirevue'],['hirevue'],"['job-applicants-using-hirevue', 'hirevue-customers']","In January 2021, HireVue removed the controversial AI expression tracking tool from its virtual job interview software.",Job Screening Service Halts Facial Analysis of Applicants,"candidate assessment, virtual interview, emotion recognition, facial expression recognition, speech recognition",1,"administrative and support service activities, professional, scientific and technical activities",no,"Perception, Cognition",Medium,Administrative and support service activities,False,Perception & Cognition,Low,Technology & IT Services
80,2020-10-24,"['1380', '1559']",['inverness-caledonian-thistle-football-club'],['unknown'],['livestream-viewers'],In a Scottish soccer match the AI-enabled ball-tracking camera used to livestream the game repeatedly tracked an official’s bald head as though it were the soccer ball.,AI mistakes referee’s bald head for football — hilarity ensued,"automatic tracking, ball detection",1,"Arts, entertainment and recreation",no,"Perception, Cognition, Action",High,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
83,2020-10-15,['1383'],"['gmail', 'outlook', 'yahoo', 'gmx', 'laposte']","['gmail', 'outlook', 'yahoo', 'gmx', 'laposte']",['email-users'],"Gmail, Yahoo, Outlook, GMX, and LaPoste email inbox sites showed racial and content-based biases when AlgorithmWatch tested their spam box filtering algorithms.",Spam filters are efficient and uncontroversial. Until you look at them.,"spam filter, classification",1,information and communication,no,"Perception, Cognition, Action",Unclear/unknown,Information and communication,False,Perception & Cognition,Medium,Information & Communication
97,2020-10-22,['1399'],['tesla'],['tesla'],['tesla-drivers'],"A Tesla Model 3 misidentified flags with ""COOP"" written vertically on them as traffic lights.",Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights,"stoplight recognition, semi-autonomous driving",2,transportation and storage,no,"Perception, Cognition, Action",Medium,Transportation and storage,False,Perception & Cognition,Low,Transportation
98,2021-04-28,['1401'],['new-york-city-police-department'],['boston-dynamics'],['new-york-city-low-income-communities'],The New York Police Department canceled a contract to use Boston Dynamics' robotic dog Spot following public backlash. ,N.Y.P.D. Robot Dog’s Run Is Cut Short After Fierce Backlash,law enforcement,1,law enforcement,yes,"Perception, Cognition",Low,Public administration and defence,False,Perception & Cognition,Low,Public Administration & Defense
79,1999-03-16,"['1379', '1736', '2039']",['chronic-kidney-disease-epidemiology-collaboration'],['chronic-kidney-disease-epidemiology-collaboration'],"['black-patients', 'african-american-patients']",Decades-long use of the estimated glomerular filtration rate (eGFR) method to test kidney function which considers race has been criticized by physicians and medical students for its racist history and inaccuracy against Black patients.,Kidney Testing Method Allegedly Underestimated Risk of Black Patients,Analyzing racial bias in medical testing methods,3,human health and social work activities,yes,Cognition,Low,Human health and social work activities,False,Perception & Cognition,Low,Health & Social Services
87,2020-10-07,['1387'],['uk-home-office'],['uk-home-office'],"['dark-skinned-people', 'dark-skinned-women']",UK passport photo checker shows bias against dark-skinned women.,UK passport photo checker shows bias against dark-skinned women,"passport photo quality check, classification",2,public administration,yes,"Perception, Cognition",Medium,Administrative and support service activities,True,Perception & Cognition,Medium,Technology & IT Services
91,2020-12-18,"['1391', '1392', '1463', '1720', '1779']",['stanford-medical-center'],['stanford-medical-center'],"['stanford-medical-frontline-workers', 'stanford-medical-residents']","In 2020, Stanford Medical Center's distribution algorithm only designated 7 of 5,000 vaccines to Medical Residents, who are frontline workers regularly exposed to COVID-19.",Frontline workers protest at Stanford after hospital distributed vaccine to administrators,Vaccine Distribution,1,human health and social work activities,no,Cognition,Low,Human health and social work activities,False,Perception & Cognition,Low,Health & Social Services
76,2020-10-09,['1339'],['buenos-aires-city-government'],['unknown'],['buenos-aires-children'],Buenos Aires city government uses a facial recognition system that has led to numerous false arrests.,Live facial recognition is tracking kids suspected of being criminals,"database, facial recognition",3,"law enforcement, public administration",yes,"Perception, Cognition",Medium,Public administration and defence,True,Perception & Cognition,Low,Public Administration & Defense
92,2019-11-11,"['1393', '1396', '2035', '2036', '2037', '2274']",['goldman-sachs'],['apple'],"['apple-card-female-users', 'apple-card-female-credit-applicants']","Apple Card's credit assessment algorithm was reported by Goldman-Sachs customers to have shown gender bias, in which men received significantly higher credit limits than women with equal credit qualifications.",Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women,Credit assessment/ Credit scoring,1,financial and insurance activities,no,"Perception, Cognition, Action",High,Financial and insurance activities,False,Perception & Cognition,Medium,Finance & Insurance
89,2019-03-15,['1389'],['youtube'],['youtube'],['youtube-users'],A New Zealand government report released following a right-wing terrorist killing 51 worshippers at two New Sealand mosques which indicated that Youtube's recommendation algorithm played an important role in the terrorist's radicalization.,The Christchurch shooter and YouTube’s radicalization trap,recommender,1,"information and communication, Arts, entertainment and recreation",no,"Cognition, Action",Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
94,2020-11-27,"['1395', '1473']",['deliveroo'],['deliveroo'],"['deliveroo-workers-with-legitimate-reasons-for-cancelling-shifts', 'deliveroo-workers']","In December 2020, an Italian court ruled that Deliveroo’s employee ‘reliability’ algorithm illegally discriminated against workers with legitimate reasons for cancelling shifts.",Court Rules Deliveroo Used 'Discriminatory' Algorithm,"shift assignment, rank the reliability of workers",1,accommodation and food service activities,no,"Cognition, Action",High,Accommodation and food service activities,False,Perception & Cognition,Low,Retail & E-commerce
110,2016-01-01,"['1413', '2651']",['arkansas-department-of-human-services'],['interrai'],"['arkansas-medicaid-waiver-program-beneficiaries', 'arkansas-healthcare-workers']","Beneficiaries of the Arkansas Department of Human Services (DHS)'s Medicaid waiver program were allocated excessively fewer hours of caretaker visit via an algorithm deployed to boost efficiency, which reportedly contained errors and whose outputs varied wildly despite small input changes.",Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries,Allocation of Caretaker Hours,1,human health and social work activities,yes,"Decision Making, Efficiency Optimization",Semi-autonomous (since the algorithm is making decisions but still requires human input and oversight),Health and Social Services,Yes,Other/Unclear,Low,Health & Social Services
111,2015-09-25,"['1426', '1427', '1428', '1429', '1430']",['amazon-flex'],['amazon'],"['amazon-flex-employees', 'amazon-flex-drivers']",Amazon Flex's contract delivery drivers were dismissed using a minimally human-interfered automated employee performance evaluation based on indicators impacted by out-of-driver's-control factors and without having a chance to defend against or appeal the decision.,Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations,Employee Performance Evaluation,4,Logistics and Delivery Services,No,Employee Performance Evaluation,High,Logistics and Delivery Services,No,Other/Unclear,Low,Transportation
104,2021-02-12,['1407'],['california-department-of-public-health'],['blue-shield-of-california'],"['california-low-income-neighborhoods', 'california-communities-of-color']","California's vaccine-distribution algorithm used ZIP codes as opposed to census tracts in its decision-making, which critics said undermined equity and access for vulnerable communities who are largely low-income, underserved neighborhoods with low Healthy Places Index scores.","California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color",vaccine allocation,2,"public administration, human health and social work activities",yes,"Data Analysis, Decision Making","Semi-Autonomous (The algorithm is making decisions based on provided data, but human oversight is involved in their implementation)",Health Care,Yes,Data Analysis,Low,Health & Social Services
106,2020-12-23,"['1409', '1416', '1417', '1418', '1419', '1420', '1421', '1422', '1423', '1424', '1425', '2034', '2356']",['facebook-messenger'],['scatter-lab'],"['korean-facebook-messenger-users', 'korean-people-of-gender-minorities', 'korean-people-with-disabilities']","A Korean interactive chatbot was shown in screenshots to have used derogatory and bigoted language when asked about lesbians, Black people, and people with disabilities.",Korean Chatbot Luda Made Offensive Remarks towards Minority Groups,chat bot,1,"information and communication, Arts, entertainment and recreation",no,"Natural Language Processing, Chatbot",Semi-autonomous (since it responds to user prompts),Information and Communication Technology,No (assuming the chatbot is not specifically mentioned as being deployed in a public sector setting),Language Processing,Low,Information & Communication
108,2021-07-10,"['1411', '1503', '1537']",['riverside-arena-skating-rink'],['unknown'],"['lamya-robinson', 'black-livonia-residents']","A Black teenager living in Livonia, Michigan was incorrectly stopped from entering a roller skating rink after its facial-recognition cameras misidentified her as another person who had been previously banned for starting a skirmish with other skaters.",Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker,facial recognition,3,"Arts, entertainment and recreation",no,Facial Recognition,Semi-Autonomous (requires human intervention for final decisions),Entertainment & Recreation,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
115,2020-07-28,"['1440', '1472', '2204']",['genderify'],['genderify'],"['genderify-customers', 'gender-minority-groups']","A company's AI predicting a person's gender based on their name, email address, or username was reported by its users to show biased and inaccurate results.",Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias,gender classification,1,information and communication,no,"Gender Prediction, User Profiling","Semi-Autonomous (Requires human input in terms of name, email address, or username)","Information Technology, Social Media",No,Other/Unclear,Medium,Information & Communication
114,2018-07-26,['1439'],['amazon'],['amazon'],"['rekognition-users', 'arrested-people']","Rekognition's face comparison feature was shown by the ACLU to have misidentified members of congress, and particularly members of colors, as other people who have been arrested using a mugshot database built on publicly available arrest photos.",Amazon's Rekognition Falsely Matched Members of Congress to Mugshots,facial recognition,1,"information and communication, law enforcement",yes,"Facial Recognition, Comparison",Semi-Autonomous,"Law Enforcement, Public Sector",Yes,Other/Unclear,Low,Law Enforcement & Public Safety
107,2018-07-20,"['1410', '1928']",['none'],"['huawei', 'megvii', 'sensetime', 'alibaba', 'baibu']",['uyghur-people'],"Various Chinese firms were revealed by patent applications to have developed facial recognition capable of detecting people by race, which critics feared would enable persecution and discrimination of Uyghur Muslims.","Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",Facial Recognition,3,Public & Private Security Sector,Yes,"Image Analysis, Pattern Recognition, Machine Learning",Semi-Autonomous,Public & Private Security Sector,Yes,Data Analysis,Medium,Law Enforcement & Public Safety
119,2021-08-03,"['1444', '1800', '1801', '1802']",['xsolla'],['unknown'],['xsolla-employees'],"Xsolla CEO fired more than a hundred employees from his company in Perm, Russia, based on big data analysis of their remote digitized-work activity, which critics said was violating employee's privacy, outdated, and extremely ineffective.",Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities,Employee Performance Analysis,3,administrative and support service activities,no,"Big Data Analysis, Remote Work Monitoring",Semi-Autonomous (requires human decision to fire employees based on analysis),Private (as Xsolla is a private company),No (as the incident took place in a private sector company),Data Analysis,Low,Other/Unclear
105,2019-08-24,['1408'],['tesla'],['tesla'],"['jovani-maldonado', 'benjamin-maldonado', 'california-public']","A Tesla Model 3 on Autopilot mode crashed into a pickup on a California freeway, where data and video from the company showed neither Autopilot nor the driver slowing the vehicle until seconds before the crash.","Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California","autonomous navigation, semi-autonomous driving, object detection, classification",2,transportation and storage,no,"Autonomous Driving, Crash Avoidance Systems",Level 3 (Conditional Automation),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
99,2012-01-01,['1402'],"['university-of-massachusetts-amherst', 'university-of-wisconsin-milwaukee', 'university-of-houston', 'texas-aandm-university', 'georgia-state-university', 'more-than-500-colleges']",['eab'],"['black-college-students', 'latinx-college-students', 'indigenous-students']",Several major universities are using a tool that uses race as one factor to predict student success.,Major Universities Are Using Race as a “High Impact Predictor” of Student Success,"risk prediction, risk assessment, performance prediction",3,"administrative and support service activities, Education",yes,Cognition,Low,Education,False,Perception & Cognition,Low,Education
121,2020-03-27,"['2106', '2105', '2104', '1447']",['tripoli-based-government'],['stm'],['libyan-soldiers'],"In Libya, a Turkish-made Kargu-2 aerial drone powered by a computer vision model was allegedly used remotely by forces backed by the Tripoli-based government to track down and attack enemies as they were running from rocket attacks.",Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers,object classification,1,defense,no,"Target Recognition, Tracking, Attack Coordination",Semi-Autonomous,Military & Defense,Yes,Other/Unclear,Low,Public Administration & Defense
109,2017-01-01,['1412'],['pimeyes'],['pimeyes'],['internet-users'],"PimEyes offered its subscription-based AI service to anyone in the public to search for matching facial images across the internet, which critics said lacked public oversight and government rules to prevent itself from misuse such as stalking women.",PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused,facial recognition,1,"information and communication, Arts, entertainment and recreation",no,Facial Recognition,Semi-Autonomous,Information Technology and Services,No,Other/Unclear,Low,Technology & IT Services
101,2018-09-01,"['1404', '1575', '1863', '2570', '2805', '2845']",['dutch-tax-authority'],['unknown'],"['dutch-tax-authority', 'dutch-families']","A childcare benefits system in the Netherlands falsely accused thousands of families of fraud, in part due to an algorithm that treated having a second nationality as a risk factor.",Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm,fraud risk prediction,3,public administration,yes,"Cognition, Action",High,Public administration and defence,False,Perception & Cognition,Low,Public Administration & Defense
103,2020-09-18,"['1406', '1527', '1528', '2145', '2241']",['twitter'],['twitter'],"['twitter-users', 'twitter-non-white-users', 'twitter-non-male-users']","Twitter's photo cropping algorithm was revealed by researchers to favor white and women faces in photos containing multiple faces, prompting the company to stop its use on mobile platform.",Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias,"image cropping, Crop Images",1,information and communication,no,"Image Recognition, Algorithm Bias Detection","Semi-Autonomous (the algorithm operates based on programmed instructions, but human intervention is needed for decision-making and corrections)","Social Media, Technology","No (The incident mentioned is related to a private company, Twitter)",Non-Text Media,Low,Information & Communication
113,2020-06-27,['1438'],['facebook'],['facebook'],"['black-people', 'facebook-users']","Facebook's AI mislabeled video featuring Black men as a video about ""primates,"" resulting in an offensive prompt message for users who watched the video.","Facebook's AI Put ""Primates"" Label on Video Featuring Black Men","video suggestion, video classification",1,information and communication,no,"Content Moderation, Text and Image Recognition",Semi-Autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
122,2015-06-14,['1448'],['facebook'],['facebook'],['facebook-users'],"Facebook’s initial version of the its Tag Suggestions feature where users were offered suggestions about the identity of people's faces in photos allegedly stored biometric data without consent, violating the Illinois Biometric Information Privacy Act.","Facebook’s ""Tag Suggestions"" Allegedly Stored Biometric Data without User Consent",facial recognition,1,"Arts, entertainment and recreation, information and communication",no,"Facial Recognition, Data Storage",Semi-Autonomous (The system provides suggestions but requires human interaction to confirm),"Social Media, Internet Services",No,Data Analysis,Low,Information & Communication
102,2020-03-23,"['1405', '1523']","['microsoft', 'ibm', 'google', 'apple', 'amazon']","['microsoft', 'ibm', 'google', 'apple', 'amazon']",['black-people'],"A study found that voice recognition tools from Apple, Amazon, Google, IBM, and Microsoft disproportionately made errors when transcribing black speakers.","Personal voice assistants struggle with black voices, new study shows","speech-to-text, automated speech recognition",1,"administrative and support service activities, information and communication",no,Perception,Low,Information and communication,False,Perception & Cognition,Low,Information & Communication
112,2012-10-09,"['2831', '2623', '2496', '2495', '2250', '1821', '1810', '1436', '1435', '1434', '1433', '1432', '3654', '4057', '4058']","['troy-police-department', 'syracuse-police-department', 'san-francisco-police-department', 'san-antonio-police-department', 'new-york-city-police-department', 'fall-river-police-department', 'chicago-police-department']",['shotspotter'],"['troy-residents', 'troy-police-department', 'syracuse-residents', 'syracuse-police-department', 'san-francisco-residents', 'san-francisco-police-department', 'san-antonio-residents', 'san-antonio-police-department', 'new-york-city-residents', 'new-york-city-police-department', 'fall-river-residents', 'fall-river-police-department', 'chicago-residents', 'chicago-police-department']","ShotSpotter algorithmic systems locating gunshots were reported by police departments for containing high false positive rates and wasting police resources, prompting discontinuation.",Police Departments Reported ShotSpotter as Unreliable and Wasteful,"detect gunshots, locate gunshots, identify weapon calibre, predict shooter movement",3,law enforcement,yes,Gunshot Detection,Semi-Autonomous,Public Safety/Security,Police Departments,Other/Unclear,Low,Law Enforcement & Public Safety
100,2021-03-17,['1403'],['french-welfare-offices'],['unknown'],['lucie-inland'],A French welfare office using software to automatically evaluate cases incorrectly notified a woman receiving benefits that she owed €542.,How French welfare services are creating ‘robo-debt’,welfare determination,2,"administrative and support service activities, human health and social work activities",yes,"Cognition, Action",High,Public administration and defence,False,Perception & Cognition,Low,Public Administration & Defense
116,2021-09-20,"['1441', '1803']",['amazon'],['netradyne'],"['amazon-delivery-drivers', 'amazon-workers']","Amazon's automated performance evaluation system involving AI-powered cameras incorrectly punished delivery drivers for non-existent mistakes, impacting their chances for bonuses and rewards.",Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make,"driver surveillance, safe driving detection, event detection, eye tracking, object recognition, event prediction",1,"wholesale and retail trade, transportation and storage",no,"Performance Evaluation, Error Detection",Semi-autonomous (requires human oversight),"E-commerce, Logistics",No,Other/Unclear,Low,Transportation
118,2020-08-06,"['1443', '2009', '2010']",['openai'],['openai'],['muslims'],"Users and researchers revealed generative AI GPT-3 associating Muslims to violence in prompts, resulting in disturbingly racist and explicit outputs such as casting Muslim actor as a terrorist.",OpenAI's GPT-3 Associated Muslims with Violence,text generation,1,"information and communication, professional, scientific and technical activities",no,"Text Generation, Content Filtering",Semi-autonomous,Information and Communication Technologies,No,Language Processing,Low,Information & Communication
120,2020-09-01,['1445'],['unknown'],"['murat-ayfer', 'openai']",['reddit-users'],"Philosopher AI, a GPT-3-powered controversial text generator, was allegedly used by an anonymous actor on AskReddit subreddit, whose posts featured a mixture of harmless stories, conspiracy theories, and sensitive topic discussions.",Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts,text generation,1,"Arts, entertainment and recreation, information and communication",no,"Text Generation, Content Creation",Semi-autonomous (AI required human input for task initiation and completion),Information and Communication (social media/reddit),No,Language Processing,Low,Information & Communication
117,2020-02-24,"['1442', '2019', '2020', '2021']",['tiktok'],['tiktok'],"['tiktok-users', 'tiktok-content-creators']","TikTok's ""Suggested Accounts"" recommendations allegedly reinforced racial bias despite not basing recommendations on race or creators' profile photo.","TikTok's ""Suggested Accounts"" Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",Recommendation System,3,Social Media/Entertainment,No,"Data Analysis, Pattern Recognition",Semi-Autonomous,Social Media/Entertainment,No,Data Analysis,Medium,"Arts, Entertainment & Recreation"
129,2021-03-01,['1462'],['facebook'],['facebook'],['facebook-users'],"Facebook's automated moderation tools were shown by internal documents performing incomparably to human moderators, and accounting for only a small fraction of hate speech, violence, and incitement content removal.","Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement","content moderation, classification",1,information and communication,no,Content Moderation,Semi-Autonomous (as the system works alongside human moderators),Information and Communication (specifically Social Media),No (since Facebook is a private entity),Other/Unclear,Low,Information & Communication
140,2020-06-01,['1478'],['university-of-toronto'],['proctoru'],['university-of-toronto-bipoc-students'],"An exam monitoring service used by the University of Toronto was alleged by its students to have provided discriminatory check-in experiences via its facial recognition's failure to verify passport photo, disproportionately enhancing disadvantaging stress level for BIPOC students.",ProctorU’s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students,"exam proctoring, remote proctoring, identification or detection",3,Education,yes,Facial Recognition,Semi-Autonomous (Requires human intervention for verification),Education,Yes,Other/Unclear,Low,Education
146,2021-10-22,"['1494', '1495', '1502']",['allen-institute-for-ai'],['allen-institute-for-ai'],['minority-groups'],"A publicly accessible research model that was trained via Reddit threads showed racially biased advice on moral dilemmas, allegedly demonstrating limitations of language-based models trained on moral judgments.","Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics","ethical decision making, reply to questions",1,information and communication,no,"Natural Language Processing, Machine Learning Model",High Autonomy (as the model was providing advice without human intervention),Information and Communication (given the context of Reddit and online discussions),No (Reddit is a private sector company),Language Processing,Medium,Information & Communication
137,2021-01-11,['1474'],['israeli-tax-authority'],['israeli-tax-authority'],"['moshe-har-shemesh', 'israeli-people-having-tax-fines']","An Israeli farmer was imposed a computer generated fine by the tax authority, who allegedly were not able to explain its calculation, and refused to disclose the program and its source code.","Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer",Automated Decision Making,1,"real estate activities, public administration",yes,"Data Analysis, Decision Making",Semi-Autonomous (requires human intervention for explaining the calculation),"Agriculture, Taxation",Yes,Data Analysis,Low,Other/Unclear
144,2020-06-28,"['1483', '1979', '1980', '2042', '2043', '2134']",['youtube'],['youtube'],"['antonio-radic', 'youtube-chess-content-creators', 'youtube-users']","YouTube's AI-powered hate speech detection system falsely flagged chess content and banned chess creators allegedly due to its misinterpretation of strategy language such as ""black,"" ""white,"" and ""attack"" as harmful and dangerous.",YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation,"content moderation, identify hate speech",1,"Arts, entertainment and recreation, information and communication",no,"Content Moderation, Hate Speech Detection",High Autonomy (AI system operates and makes decisions independently),Information and Communication (specifically Social Media/Online Platforms),No,Other/Unclear,Low,Information & Communication
148,2021-11-21,['1499'],"['accessibe', 'accessus.ai', 'allyable', 'userway', 'maxaccess.io']","['accessibe', 'accessus.ai', 'allyable', 'userway', 'maxaccess.io']","['internet-users-with-disabilities', ""web-accessibility-vendors'-customers""]","AI-powered web accessibility vendors allegedly overstated to customers about their products' utility for people with disabilities, falsely claiming to deliver automated compliance solutions.",Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI,"accessibility compliance, ADA website compliance",1,information and communication,maybe,"Compliance Analysis, Accessibility Services",Semi-autonomous (The AI solution requires human intervention for final decisions),"Information Technology, Accessibility Services","Likely No (Based on the description, it doesn't specify involvement of public sector organizations)",Data Analysis,Low,Technology & IT Services
160,2021-12-26,"['1520', '1521', '2381']",['amazon'],['amazon'],"[""kristin-livdahl's-daughter"", 'amazon-echo-customers', 'children-using-alexa']","Amazon’s voice assistant Alexa suggested “the penny challenge,” which involves dangerously touching a coin to the prongs of a half-exposed plug, when a ten-year-old girl asked for a challenge to do.",Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl,"virtual assistant technology, suggestion, recommendation",1,information and communication,no,"Voice Recognition, Natural Language Processing, Information Retrieval",Semi-Autonomous,Consumer Electronics,No,Language Processing,Low,Other/Unclear
152,2021-07-13,"['1509', '1510']",['softbank'],"['aldebaran', 'softbank-robotics']",['softbank'],"SoftBank's robot allegedly kept making mechanical errors, taking unplanned breaks, failing to recognize previously-met people, and breaking down during practice runs.","SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal","chant scripture, entertain guests, household administration, cheerleading, exercise demonstration, concierge",1,"administrative and support service activities, other service activities, financial and insurance activities, Arts, entertainment and recreation, human health and social work activities",no,"Facial Recognition, Mechanical Operation",Semi-Autonomous,Robotics and Automation,No,Other/Unclear,Low,Other/Unclear
161,2019-04-03,"['1530', '2138', '2139']",['facebook'],['facebook'],"['female-facebook-users', 'black-facebook-users', 'male-facebook-users']",Facebook's housing and employment ad delivery process allegedly resulted in skews in exposure for some users along demographic lines such as gender and racial identity.,Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines,Ad Delivery Optimization,3,Social Media,No,"User Profiling, Targeted Advertising",Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
164,2018-10-01,['1534'],['facebook'],['facebook'],"['facebook-users', 'facebook-content-creators']","After the “News Feed” algorithm had been overhauled to boost engagement between friends and family in early 2018, its heavy weighting of re-shared content was alleged found by company researchers to have pushed content creators to reorient their posts towards outrage and sensationalism, causing a proliferation of misinformation, toxicity, and violent content.","Facebook ""News Feed"" Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric","content recommendation, prediction, engagement optimization",1,information and communication,no,"Content Recommendation, Content Curation, User Behavior Analysis",Semi-Autonomous (Algorithm requires human oversight but operates independently),"Social Media, Information and Communication",No,Data Analysis,Medium,Information & Communication
168,2022-03-01,"['1540', '1541']","['facebook', 'linkedin', 'youtube', 'twitter', 'netflix']","['facebook', 'linkedin', 'youtube', 'twitter', 'netflix']","['facebook-users', 'linkedin-users', 'youtube-users', 'twitter-users', 'netflix-users']","Collaborative filtering prone to popularity bias, resulting in overrepresentation of popular items in the recommendation outputs.","Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",Recommendation System,3,Information Technology,No,Collaborative Filtering,Semi-Autonomous,Information Technology,No,Other/Unclear,Medium,Technology & IT Services
133,2020-12-15,['1468'],['tiktok'],['tiktok'],['tiktok-content-creators-of-marginalized-groups'],TikTok's automated content reporting system was allegedly abused by online trolls to intentionally misreport content created by users of marginalized groups.,Online Trolls Allegedly Abused TikTok’s Automated Content Reporting System to Discriminate against Marginalized Creators,"content moderation, enforcement of community guidelines",1,"Arts, entertainment and recreation, information and communication",no,"Content Moderation, Automated Reporting System",Semi-Autonomous (requires human intervention in case of disputes or appeals),"Social Media, Internet Technology",No (as TikTok is a private sector company),Other/Unclear,Low,Information & Communication
131,2020-12-04,"['1465', '1771']","[""california-bar's-committee-of-bar-examiners""]",['examsoft'],"['california-bar-exam-takers', 'flagged-california-bar-exam-takers']","The proctoring algorithm used in a California bar exam cited a third of thousands of applicants as cheaters, resulting in allegations where exam takers were instructed to prove otherwise without seeing their incriminating video evidence.",Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters,classification,3,"Education, professional, scientific and technical activities",yes,"Proctoring Algorithm, Cheating Detection",Semi-Autonomous (requires human intervention to verify flagged instances),Education,Yes,Other/Unclear,Low,Education
153,2019-12-29,"['1511', '1729', '1763', '2514']",['tesla'],['tesla'],"['gilberto-alcazar-lopez', 'maria-guadalupe-nieves-lopez']","In 2019, a Tesla Model S driver on Autopilot mode reportedly went through a red light and crashed into a Honda Civic, killing two people in Gardena, Los Angeles.","Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles","semi-autonomous navigation, object detection, object recognition, autonomous driving",2,transportation and storage,no,Autonomous Driving,Level 3 (Conditional Automation),Transportation,No,Other/Unclear,Low,Transportation
145,2021-07-23,"['1485', '1504', '1529']",['tesla'],['tesla'],['tesla-drivers'],"Tesla's Autopilot was shown on video by its owner mistaking the moon for a yellow stop light, allegedly causing the vehicle to keep slowing down.",Tesla's Autopilot Misidentified the Moon as Yellow Stop Light,autonomous navigation,2,transportation and storage,no,"Object Detection, Image Recognition, Automated Response",Semi-Autonomous,"Automotive, Transportation",No,Non-Text Media,Low,Transportation
141,2021-02-05,"['1479', '1480']",['instagram'],['instagram'],"['sennett-devermont', 'beverly-hills-citizens']","A police officer in Beverly Hills played copyrighted music on his phone when realizing that his interactions were being recorded on a livestream, allegedly hoping the Instagram's automated copyright detection system to end or mute the stream.",California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed,Copyright detection,3,Law enforcement,Yes,"Content moderation, Copyright enforcement",Semi-autonomous,Law enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
134,2020-12-25,"['1469', '1951']",['fuzhou-zhongfang-marlboro-mall'],['unknown'],['fuzhou-zhongfang-marlboro-mall-goers'],"A shopping guide robot deployed by the Fuzhou Zhongfang Marlboro Mall was shown on video allegedly walking to the escalator by itself, falling down, and knocking over passengers, which prompted its suspension.","Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",Guiding Shoppers,1,wholesale and retail trade,no,"Navigation, Object Recognition, Interaction with Environment",Semi-Autonomous,Retail,No,Action & Control,Low,Retail & E-commerce
125,2020-09-29,"['1451', '1452', '1460']",['amazon'],['amazon'],['amazon-fulfillment-center-workers'],Amazon’s robotic fulfillment centers have higher serious injury rates.,Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates,"delivery , navigation, move shelves, worker monitoring, performance tracking",1,"wholesale and retail trade, transportation and storage",no,Automation & Robotics,Semi-autonomous,E-commerce,No,Other/Unclear,High,Retail & E-commerce
136,2020-12-06,['1471'],['brand-safety-tech-firms'],['none'],['news-sites'],"Brand safety tech firms falsely claimed use of AI, blocking ads using simple keyword lists.","Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists",brand safety detection,1,"Arts, entertainment and recreation, information and communication",no,Ad Filtering/Blocking,Semi-Autonomous,Advertising and Marketing,No,Other/Unclear,Low,Other/Unclear
138,2020-01-21,"['1475', '1505', '1555', '1556', '2442', '2434']",['university-of-illinois'],['proctorio'],"['university-of-illinois-students-of-color', 'university-of-illinois-students']","Proctorio's remote-testing software were reported by students at the University of Illinois Urbana-Champaign for issues regarding privacy, accessibility, differential performance on darker-skinned students.",Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University,Proctoring / Surveillance,3,Education,Yes (University of Illinois Urbana-Champaign is a public university),"Image Recognition, Behavior Analysis","Semi-autonomous (needs human supervision for initial setup, but can operate independently thereafter)",Education,Yes (University of Illinois Urbana-Champaign is a public university),Data Analysis,Low,Education
132,2020-12-27,['1466'],['tiktok'],['tiktok'],"['tiktok-users', 'tiktok-users-under-18-years-old']","Videos promoting eating disorders evaded TikTok's automated violation detection system without difficulty via common misspellings of search terms, bypassing its ban of violating hashtags such as ""proana"" and ""anorexia"".",TikTok’s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders,"content suggestion, content moderation",1,"Arts, entertainment and recreation, information and communication",no,"Content Moderation, Text Analysis, Natural Language Processing","Semi-autonomous (System can perform tasks under set conditions, but human intervention is required for complex situations)","Social Media, Information Technology",No,Data Analysis,Low,Information & Communication
135,2012-12-01,"['1470', '1871']","[""university-of-texas-at-austin's-department-of-computer-science""]",['university-of-texas-at-austin-researchers'],['university-of-texas-at-austin-phd-applicants-of-marginalized-groups'],"The University of Texas at Austin's Department of Computer Science's assistive algorithm to assess PhD applicants ""GRADE"" raised concerns among faculty about worsening historical inequalities for marginalized candidates, prompting its suspension.",UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities,assess applicants,3,Education,yes,Applicant Assessment,Semi-autonomous (as the final decision likely involves human review),Education,Yes,Other/Unclear,Low,Education
155,2021-12-27,"['1513', '1514']",['google-maps'],['google-maps'],"['google-maps-users-traveling-in-sierra-nevada', 'google-maps-users-traveling-in-the-mountains']",Lake Tahoe travelers were allegedly guided by Google Maps into hazardous shortcuts in the mountains during a snowstorm.,Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm,"navigation, route optimization",3,"transportation and storage, information and communication",no,"Navigation algorithms, Predictive analysis",Semi-Autonomous,"Transportation, Travel & Tourism",No,Action & Control,Low,Transportation
162,2014-01-01,['1531'],['ets'],['ets'],"['uk-ets-past-test-takers', 'uk-ets-test-takers', 'uk-home-office']"," International testing organization ETS admits voice recognition as evidence of cheating for thousands of previous TOEIC test-takers that reportedly included wrongfully accused people, causing them to be deported without an appeal process or seeing their incriminating evidence.","ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK",voice recognition,3,"Education, public administration",yes,"Voice Recognition, Fraud Detection","Semi-Autonomous (AI was used to provide evidence, but the final decision was made by humans)","Education, Legal","Yes (The incident involves immigration authorities, a part of the public sector)",Other/Unclear,Low,Education
171,2021-10-18,['1549'],['bath-government'],['unknown'],"['paula-knight', 'bath-officials', 'uk-public']",A Bath resident was wrongly fined by the local officials because an automated license plate recognition camera misread the text on her shirt as a license plate number.,"Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person",License Plate Recognition,3,"Public sector, specifically Traffic Management",Yes,"Object Detection, Optical Character Recognition",Semi-autonomous,"Public sector, specifically Traffic Management",Yes,Other/Unclear,Low,Other/Unclear
151,2021-10-28,"['1507', '1508', '1703', '1704', '1705', '1706', '1707', '1708', '1709', '1710']",['pony.ai'],['pony.ai'],['san-francisco-city-government'],"A Pony.ai vehicle operating in autonomous mode crashed into a center divider and a traffic sign in San Francisco, prompting a regulator to suspend the driverless testing permit for the startup.",California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision,autonomous driving,1,transportation and storage,no,Autonomous Driving System,Level 5 (Full Automation),Transportation,No,Other/Unclear,Low,Transportation
123,2021-08-01,"['1449', '2651', '2705', '3013', '3012']",['university-of-michigan-hospital'],['epic-systems'],['sepsis-patients'],"Epic System's sepsis prediction algorithms was shown by investigators at the University of Michigan Hospital to have high rates of false positives and false negatives, allegedly delivering inaccurate and irrelevant information on patients, contrasting sharply with their published claims.",Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients,"identify sepsis, diagnose sepsis, sepsis prediction",3,human health and social work activities,yes,"Disease Prediction, Diagnostic Assistance",Semi-autonomous,Healthcare,Yes,Other/Unclear,Low,Health & Social Services
156,2022-02-04,"['1515', '2197']",['amazon'],['amazon'],['people-attempting-suicides'],"Despite complaints notifying Amazon about the sale of various products that had been used to aid suicide attempts, its recommendation system reportedly continued selling them and suggesting their frequently bought-together items.",Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts,recommendation,1,wholesale and retail trade,no,Recommendation System,Semi-Autonomous (Requires human oversight),Retail/E-commerce,No,Other/Unclear,Low,Retail & E-commerce
143,2021-02-16,['1482'],"['facebook', 'twitter']","['facebook', 'twitter']","['facebook-users-of-small-language-groups', 'twitter-users-of-small-language-groups']","Facebook's and Twitter were not able to sufficiently moderate content of small language groups such as the Balkan languages using AI, allegedly due to the lack of investment in human moderation and difficulty in AI-solution design for the languages.",Facebook’s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups,content moderation,1,information and communication,no,Content Moderation,Semi-autonomous (requires human moderation for accuracy),Information and Communication Technology,No,Other/Unclear,Low,Information & Communication
157,2021-03-15,['1516'],['amazon'],['amazon'],"['amazon-workers', 'amazon-delivery-drivers']","A lawsuit cited Amazon as liable in a crash involving its delivery driver, alleging that Amazon’s AI-powered driver monitoring system pushed drivers to prioritize speed over safety.","Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash",Driver Monitoring,1,"transportation and storage, wholesale and retail trade",no,"Risk Assessment, Behavior Prediction",Semi-Autonomous,E-commerce / Logistics,No,Other/Unclear,Low,Transportation
170,2003-06-01,"['1546', '1547', '1548']",['target'],['target'],['target-customers'],"Target recommended maternity-related items to a family in Atlanta via ads, allegedly predicting their teenage daughter’s pregnancy before her father did, although critics have called into question the predictability of the algorithm and the authenticity of its claims.","Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",Targeted Advertising,3,Retail,No,Predictive Analytics,Semi-autonomous,Retail,No,Data Analysis,Low,Retail & E-commerce
139,2021-01-21,"['1476', '1477']",['amazon'],['amazon'],['amazon-customers'],"Evidence of the ""filter-bubble effect"" were found by vaccine-misinformation researchers in Amazon's recommendations, where its algorithms presented users who performed actions on misinformative products with more misinfomative products.",Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation,"recommender, search engine",1,wholesale and retail trade,no,Recommendation System,Semi-Autonomous,Information and Communication,No,Other/Unclear,Low,Information & Communication
142,2021-02-11,['1481'],"['facebook', 'instagram']","['facebook', 'instagram']","['facebook-users-of-disabilities', 'adaptive-fashion-retailers']","Facebook platforms' automated ad moderation system falsely classified adaptive fashion products as medical and health care products and services, resulting in regular bans and appeals faced by their retailers.",Facebook’s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers,"advertisement screening, detect policy violations",1,"wholesale and retail trade, information and communication",no,"Content Moderation, Ad Targeting",High Autonomy,Information and Communication,No,Other/Unclear,Low,Information & Communication
150,2018-07-21,"['1506', '3157', '3158']",['natural-cycles'],['natural-cycles'],"['natural-cycles-users', 'women']","Some women using the contraceptive app, Natural Cycles, reported unwanted pregnancies, revealing its algorithm's difficulties in mapping menstrual cycles.","Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",Predictive Analytics,3,Healthcare,No,Predictive Modeling,Semi-autonomous,Healthcare,No,Data Analysis,Low,Health & Social Services
169,2018-08-15,"['1544', '1545', '2986', '2987', '2988']","['facebook', 'meta']","['facebook', 'meta']","['rohingya-people', 'rohingya-facebook-users', 'myanmar-public', 'facebook-users-in-myanmar', 'burmese-speaking-facebook-users']"," Facebook allegedly did not adequately remove anti-Rohingya hate speech, some of which was extremely violent and dehumanizing, on its platform, contributing to the violence faced by Rohingya communities in Myanmar.",Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar,Content moderation,3,Social Media,No,"Text Analysis, Content Filtering, Sentiment Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
147,2020-01-01,"['1496', '1497']",['scammers'],['unknown'],['hong-kong-bank-manager'],"In early 2020, fraudsters reportedly allegedly deepfaked the voice of a company's director, demanding a bank manager in Hong Kong to authorize a $35M transfer.",Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director,"deepfake audio generation, audio deepfake",2,"financial and insurance activities, other",no,"Voice Recognition, Deep Learning",Semi-autonomous,Banking and Finance,No,Other/Unclear,Low,Finance & Insurance
126,2021-07-16,"['1453', '1454', '1455', '1532']",['ocado'],['ocado'],['ocado'],"A collision involving three robots at an Ocado's warehouse in Erith, UK, resulting in a fire but no reports of injuries.","Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",Warehouse Automation/Logistics,1,"wholesale and retail trade, transportation and storage",no,"Collision Detection, Navigation, Fire Safety",High Autonomy,Retail/Supply Chain Management,No,Action & Control,Low,Retail & E-commerce
128,2017-08-01,"['1459', '1818']",['tesla'],['tesla'],"['eric-horvitz', 'tesla-drivers']"," A Tesla Sedan operating on Autopilot mode was not able to center itself on the road and drove over a yellow dividing curb in Redmond, Washington, causing minor damage to the vehicle’s rear suspension.","Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",autonomous driving,2,transportation and storage,no,"Autonomous Driving, Obstacle Detection",Level 3 (Conditional Automation),"Personal Use, Public Road Transport",No,Other/Unclear,Low,Other/Unclear
154,2022-01-26,['1512'],['us-department-of-justice'],['us-department-of-justice'],['inmates-of-color'],"Department of Justice’s inmate-recidivism risk assessment tool was reported to have produced racially uneven results, misclassifying risk levels for inmates of color.",Justice Department’s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines,"risk assessment, predict recidivism, predict recidivism risk",3,law enforcement,yes,Risk Assessment,Semi-autonomous (as it's likely the tool's results were reviewed and interpreted by human operators),Justice and Public Safety,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
165,2020-06-20,"['1536', '2781']",['duke-researchers'],['duke-researchers'],['people-having-non-caucasian-facial-features'],"Image upscaling tool PULSE powered by NVIDIA's StyleGAN reportedly generated faces with Caucasian features more often, although AI academics, engineers, and researchers were not in agreement about where the source of bias was.",Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often,Image upscaling,3,Technology & Research,No,"Image generation, AI bias detection and mitigation",Semi-autonomous,Technology & Research,No,Non-Text Media,Medium,Education
158,2021-02-01,['1517'],['unknown'],['unknown'],"['amaya-ross', 'black-students', 'black-test-takers']","A Black student's face was not recognized by the remote-proctoring software during check-in of a lab quiz, causing her to excessively change her environments for it to work as intended.",Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student’s Face,Facial Recognition,3,Education,Yes,"Image Processing, Machine Learning, Computer Vision",Semi-autonomous,Education,Yes,Non-Text Media,Low,Education
149,2021-11-02,"['1500', '1501', '1890', '2925']",['zillow'],['zillow-offers'],"['zillow-offers-staff', 'zillow']","Zillow's AI-powered predictive pricing tool Zestimate was allegedly not able to accurately forecast housing prices three to six months in advance due to rapid market changes, prompting division shutdown and layoff of a few thousand employees.",Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy,"price determination, home valuation, estimating house prices, real estate market forecasting",1,real estate activities,no,"Predictive Analytics, Price Forecasting",Semi-Autonomous (since it seems to require human intervention when market conditions change rapidly),Real Estate,No,Data Analysis,Low,Other/Unclear
124,2019-10-24,"['1450', '1522', '2262', '2652', '2651', '2704', '2856']",['unnamed-large-academic-hospital'],['optum'],['black-patients'],"Optum's algorithm deployed by a large academic hospital was revealed by researchers to have under-predicted the health needs of black patients, effectively de-prioritizing them in extra care programs relative to white patients with the same health burden.",Algorithmic Health Risk Scores Underestimated Black Patients’ Needs,"assign risk , predict healthcare needs",1,human health and social work activities,maybe,"Predictive Analytics, Health Risk Assessment","Semi-autonomous (the algorithm provides predictions, but final decisions are made by healthcare professionals)",Healthcare,Yes (as the incident involves a large academic hospital which could be publicly funded),Data Analysis,Low,Health & Social Services
159,2019-03-29,['2471'],['tesla'],['tesla'],['tesla-drivers'],"Tencent Keen Security Lab conducted security research into Tesla’s Autopilot system and identified crafted adversarial samples and remote controlling via wireless gamepad as vulnerabilities to its system, although the company called into question their real-world practicality. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Tesla Autopilot’s Lane Recognition Allegedly Vulnerable to Adversarial Attacks,Security Research,3,Automotive,No,"Autopilot System, Vulnerability Identification",Partial Automation,Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
167,2017-09-07,['1539'],"['michal-kosinski', 'yilun-wang']","['michal-kosinski', 'yilun-wang']","['lgbtq-people', 'lgbtq-people-of-color', 'non-american-lgbtq-people']","Researchers at Stanford Graduate School of Business developed a model that determined, on a binary scale, whether someone was homosexual using only his facial image, which advocacy groups such as GLAAD and the Human Rights Campaign denounced as flawed science and threatening to LGBTQ folks.",Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People’s Safety and Privacy,Facial Recognition,3,Education/Research,No,Image Analysis,Semi-Autonomous,Education/Research,No,Data Analysis,Low,Education
127,2020-06-06,"['1456', '1457', '1458', '1461', '1486', '1487', '1488', '1489', '1490', '1491', '1492', '1493']","['microsoft', 'msn.com']",['microsoft'],"['jade-thirlwall', 'leigh-anne-pinnock']","A news story published on MSN.com featured a photo of the wrong mixed-race person that was allegedly selected by an algorithm, following Microsoft’s layoff and replacement of journalists and editorial workers at its organizations with AI systems.",Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story,generation,1,"Arts, entertainment and recreation, information and communication",no,"Content Moderation, Image Recognition",High Autonomy,Media and Journalism,No,Non-Text Media,Low,Information & Communication
163,2021-11-21,"['1533', '1652']",['facebook'],['facebook'],"['facebook-users-of-minority-groups', 'facebook-users']","Facebook’s hate-speech detection algorithms was found by company researchers to have under-reported less common but more harmful content that was more often experienced by minority groups such as Black, Muslim, LGBTQ, and Jewish users.",Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups,Hate Speech Detection,3,Social Media / Online Platforms,No,"Text Analysis, Natural Language Processing, Machine Learning",Semi-Autonomous,Social Media / Online Platforms,No,Data Analysis,Low,Information & Communication
166,2020-02-07,"['1538', '1563']",['giggle'],['kairos'],"['trans-women', 'women-of-color']","A social networking platform, Giggle, allegedly collected, shared to third-parties, and used sensitive information and biometric data to verify whether a person is a woman via facial recognition, which critics claimed to be discriminatory against women of color and harmful towards trans women.","Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",Facial Recognition,3,Social Media and Networking,No,"Data Collection and Analysis, Biometric Verification",Semi-Autonomous,Social Media and Networking,No,Data Analysis,Low,Information & Communication
176,2022-03-02,['1557'],['oregon-state-university'],['starship-technologies'],"['oregon-state-university', 'freight-train-crew']"," A Starship food delivery robot deployed by Oregon State University reportedly failed to cross the railroad, becoming stranded, and ending up being struck by an oncoming freight train.","Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",Navigation and Delivery,3,Transportation,Yes,Route Planning and Object Detection,Semi-Autonomous,Transportation,Yes,Other/Unclear,Low,Transportation
182,2018-06-11,"['1573', '1574']",['cruise'],['cruise'],"['cruise-vehicles', 'cruise-driver-employee']","In San Francisco, an autonomous Cruise Chevrolet Bolt collided with another Cruise vehicle driven by a Cruise human employee, causing minor scuffs to the cars but no human injuries.",Two Cruise Autonomous Vehicles Collided with Each Other in California ,Vehicle Navigation,4,Automotive,No,Vehicle Navigation,Level 2 (Assuming the human-driven vehicle had some autonomy but was overridden by human control),Automotive,No,Action & Control,Low,Manufacturing & Industrial
173,2021-07-30,['1551'],['unknown'],['unknown'],"['doctors', 'covid-patients']","AI tools failed to sufficiently predict COVID patients, some potentially harmful.","AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful",Disease prediction,3,Healthcare,Yes,Predictive analysis,Semi-autonomous,Healthcare,Yes,Data Analysis,Low,Health & Social Services
203,2022-02-10,"['1659', '1660', '1661']",['uber'],['uber'],['uber-drivers'],"Uber launched a new but opaque algorithm to determine drivers' pay in the US which allegedly caused drivers to experience lower fares, confusing fare drops, and a decrease in rides.",Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US,Algorithm development and deployment,3,Transportation,No (as Uber is a private company),"Fare calculation, Driver-Rider Matching",Semi-Autonomous (since the previous system also likely required some level of human management),Transportation,No (as Uber is a private company),Other/Unclear,Low,Transportation
184,2018-04-12,"['1581', '1584', '1899']",['companhia-do-metropolitano-de-sao-paulo'],['securos'],"['sao-paulo-metro-users', 'sao-paulo-citizens']"," A facial recognition program rolled out by São Paulo Metro Stations was suspended following a court ruling in response to a lawsuit by civil society organizations, who cited fear of it being integrated with other electronic surveillance entities without consent, and lack of transparency about the biometric data collection process of metro users.",Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy,Facial Recognition,3,Public Transportation,Yes,Identity Verification,Semi-Autonomous,Public Transportation,Yes,Other/Unclear,Low,Transportation
195,2015-09-01,"['1622', '1623', '1624', '1625', '1626', '1627', '1628', '1629', '1630', '1631', '1632', '1843']","[""pasco-sheriff's-office""]",['unknown'],"['pasco-residents', 'pasco-black-students', 'pasco-students-with-disabilities']","The Intelligence-Led Policing model rolled out by the Pasco County Sheriff’s Office was allegedly developed based on flawed science and biased data that also contained sensitive information and irrelevant attributes about students, which critics said to be discriminatory.",Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups,Data analysis and processing,3,Law enforcement,Yes,"Data mining, Predictive analytics",Semi-autonomous,Law enforcement,Yes,Data Analysis,Medium,Law Enforcement & Public Safety
213,2020-07-01,"['1715', '1716', '1717', '1718', '1719']",['facebook'],['facebook'],['facebook-users'],"The performance of Facebook’s political ad detection was revealed by researchers to be imprecise, uneven across countries in errors, and inadequate for preventing systematic violations of political advertising policies.",Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates,Ad detection,3,Information Technology & Services,No,"Ad detection, Policy Enforcement",Semi-Autonomous,Information Technology & Services,No,Other/Unclear,Low,Technology & IT Services
174,2022-02-28,"['1552', '1585', '1595', '1599']",['unknown'],['unknown'],['linkedin-users'],"More than a thousand inauthentic LinkedIn profiles using allegedly GAN-generated photos were notified by researchers at Stanford to LinkedIn’s staff, and many of which were removed for violating rules against creating fake profiles and falsifying information.",Fake LinkedIn Profiles Created Using GAN Photos,Image Recognition,3,Social Media/Networking,No,"Profile Verification, Fraud Detection",Semi-Autonomous,Social Media/Networking,No,Other/Unclear,Low,Information & Communication
198,2022-03-16,"['1642', '1643', '1644', '1645', '1646', '3332', '3333', '3334', '3335']",['hackers'],['unknown'],"['volodymyr-zelenskyy', 'ukrainian-social-media-users', 'ukrainian-public']", A quickly-debunked deepfaked video of the Ukrainian President Volodymyr Zelenskyy was posted on various Ukrainian websites and social media platforms encouraging Ukrainians to surrender to Russian forces during the Russia-Ukraine war.,Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media,Deepfake creation,3,Media and Communications,No,"Video manipulation, Text-to-speech synthesis",Semi-autonomous,Media and Communications,No,Non-Text Media,Low,Information & Communication
175,2022-04-01,"['1553', '1554', '1606', '1607', '1608']",['cruise'],['cruise'],"['san-francisco-public', 'cruise-customers']","An autonomous Chevy Bolt operated by Cruise was pulled over in San Francisco, and as the police attempted to engage with the car, it reportedly bolted off, pulled over again, and put on its hazards lights on at a point farther down the road.",Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco,Incident Handling,4,Transportation,No,"Autonomous Driving, Incident Response",High Autonomy,Transportation,No,Other/Unclear,Low,Transportation
178,2022-04-21,"['1560', '1565', '1566', '1567', '1568', '1569', '1570', '1594']",['tesla'],['tesla'],"['tesla-owner', 'vision-jet-owner']"," A Tesla Model Y was shown on video slowly crashing into a Vision Jet in Spokane, Washington, allegedly due to its owner activating the “Smart Summon” feature.","Tesla Owner Activated ""Smart Summon"" Feature, Causing a Collision with an Aircraft in a Washington Airport",Autonomous Driving,5,Transportation,No,"Autonomous Navigation, Object Detection, Collision Avoidance",Level 5 (Full Automation),Transportation,No,Action & Control,Low,Transportation
180,2020-02-19,"['1564', '1582', '2236']","['malaysian-judiciary', 'malaysian-courts']",['sarawak-information-systems'],['malaysian-convicted-people'],"The AI system used by the Malaysian judiciary which explicitly considered age, employment, and socio-economic data provided sentencing to a drug possession case that was alleged by lawyer to be disproportionately high for the crime committed.",Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case,Legal Sentencing,3,Judiciary/Legal Sector,Yes,"Data Analysis, Decision Making",Semi-autonomous,Judiciary/Legal Sector,Yes,Data Analysis,Low,Other/Unclear
183,2017-07-01,"['1576', '1577', '1578', '1579', '1580', '2066']",['airbnb'],"['airbnb', 'trooly']","['sex-workers', 'airbnb-users']"," Airbnb allegedly considered publicly available data on users to gauge their trustworthiness via algorithmic assessment of personality and behavioral traits, resulting in unexplained bans and discriminatory bans against sex workers.","Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",User Profiling and Behavior Analysis,3,Hospitality/Real Estate,No,"Data Mining, User Behavior Analysis",Semi-Autonomous,Hospitality/Real Estate,No,Data Analysis,Low,Technology & IT Services
220,2020-11-11,"['1731', '1732', '1969', '2061']",['facebook'],['facebook'],['small-businesses-on-facebook'],"Facebook’s AI mistakenly blocked advertisements by small and struggling businesses, after the company allegedly leaned more on algorithms to monitor ads on the platform with little review from human moderators.",Facebook Mistakenly Blocked Small Business Ads,content moderation,1,"wholesale and retail trade, information and communication",no,"Content Moderation, Ad Monitoring",High Autonomy,"Technology, Social Media",No,Other/Unclear,Low,Information & Communication
194,2018-02-01,['1621'],['unnamed-australian-telecommunications-company'],['unknown'],['unnamed-australian-telecommunications-company'],"In early 2018, an Australian telecommunications company’s incident management AI excessively deployed technicians into the field, and was allegedly unable to be stopped by the automation team.","Australian Telco’s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions",Technician Deployment,4,Telecommunications,No,Incident Management,Moderate,Telecommunications,No,Other/Unclear,Low,Information & Communication
200,2019-03-01,['1653'],['scammers'],['unknown'],"[""unnamed-uk-based-energy-firm's-ceo""]","Fraudsters allegedly used AI voice technology to impersonate the boss of a UK-based firm's CEO, demanding a transfer of €220,000 over the phone.",Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss,Voice Impersonation,3,Financial Services,No,"Voice Recognition, Speech Synthesis",Semi-Autonomous,Financial Services,No,Other/Unclear,Low,Other/Unclear
206,2015-03-01,"['1675', '1676', '1677', '1678']",['tinder'],['tinder'],['tinder-users-over-30-years-old'],"Tinder’s personalized pricing was found by Consumers International to consider age as a major determinant of pricing, and could be considered a direct discrimination based on age, according to anti-discrimination law experts.",Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users,Pricing Algorithm,3,Online Dating Service,No,Predictive Analysis,Semi-Autonomous,Online Dating Service,No,Data Analysis,Medium,Other/Unclear
186,2007-07-26,"['1590', '1591', '1592', '1593', '1788', '1933', '1934']",['spanish-ministry-of-interior'],"['spanish-secretary-of-state-for-security', 'spanish-ministry-of-interior']",['spanish-victims-of-gender-violence']," In Spain, the algorithm that assesses recidivism risk in gender violence, VioGén, have critically underestimated the level of risk in a series of cases that ended in homicide of women and children since its first deployment.","Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",Risk Assessment,3,Public Safety / Law Enforcement,Yes,"Data Analysis, Predictive Modeling",Semi-Autonomous,Public Safety / Law Enforcement,Yes,Data Analysis,High,Law Enforcement & Public Safety
202,2021-12-06,"['1655', '1656', '1657', '1658', '1721']","['yoon-suk-yeol', ""yoon-suk-yeol's-campaign""]",['unknown'],['korean-public'],A South Korean political candidate created a deepfake avatar which political opponents alleged to be fraudulent and a threat to democracy.,Korean Politician Employed Deepfake as Campaign Representative,Deepfake Generation,3,Politics,Yes,Image/Video Generation,Semi-Autonomous,Politics,Yes,Non-Text Media,Low,Technology & IT Services
216,2017-10-10,"['1724', '1924', '1925', '1926', '1927']",['wechat'],['wechat'],['black-wechat-users'],The Chinese platform WeChat provided an inappropriate and racist English translation for the Chinese term for “black foreigner” in its messaging app.,WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”,Machine Translation,3,Information and Communication,No,Natural Language Processing,Semi-autonomous,Information and Communication,No,Language Processing,Low,Information & Communication
221,2022-03-07,"['1733', '1734']",['tesla'],['tesla'],['road-engineer'],"In Taiwan, a Tesla Model 3 on Autopilot mode whose driver did not pay attention to the road collided with a road repair truck; a road engineer immediately placed crash warnings in front of the Tesla, but soon after got hit and was killed by a BMW when its driver failed to see the sign and crashed into the accident.",A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot,Collision detection and avoidance,3,Transportation,No,Collision detection and avoidance,Manual,Transportation,Yes,Other/Unclear,High,Transportation
179,2022-04-01,"['1561', '1562', '1874']",['openai'],['openai'],"['underrepresented-groups', 'minority-groups']","Developers of OpenAI's DALL-E 2 cited risks of the model, varying from misuse as disinformation and explicit content generation, to gender and racial bias.",DALL-E 2 Reported for Gender and Racially Biased Outputs,Image Generation,3,Information Technology,No,"Content Generation, Disinformation Detection, Bias Detection",Semi-Autonomous,Information Technology,No,Other/Unclear,Medium,Technology & IT Services
172,2020-07-01,"['1550', '3859', '3912']","['appriss', 'narxcare', 'avertd']",['appriss'],"['american-physicians', 'american-pharmacists', 'american-patients-of-minority-groups', 'american-patients']","NarxCare's overdose risk algorithm, lacking peer-reviewed validation, uses sensitive data like doctor visits, prescriptions, and possibly genetic information, leading to significant biases against women and Black patients. Factors like sexual abuse and criminal records exacerbate stigmas and disparities, often resulting in unjust denial of necessary pain medication. The newly approved AvertD genetic test shares similar issues, further complicating and potentially harming medical treatment decisions.",NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias,Risk Assessment,3,Healthcare,Yes,"Data Analysis, Predictive Modeling",Semi-Autonomous,Healthcare,Yes,Data Analysis,Medium,Health & Social Services
181,2022-02-11,"['1571', '1572']",['cruise'],['cruise'],['cruise-vehicle'],"A BMW Sedan reportedly made an illegal left turn, causing a minor collision but no injuries with a Cruise autonomous vehicle (AV) operating in autonomous mode.","BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",Traffic navigation and accident prevention,5,Private Transport,No,Traffic navigation and accident prevention,Level 0 (No Automation),Private Transport,No,Other/Unclear,Low,Other/Unclear
190,2017-01-15,"['1610', '1611', '1612', '1613']",['bytedance'],['bytedance'],"['instagram-users', 'snapchat-users', 'american-social-media-users']"," ByteDance allegedly scraped short-form videos, usernames, profile pictures, and descriptions of accounts on Instagram, Snapchat, and other sources, and uploaded them without consent on Flipagram, TikTok’s predecessor, in order to improve its “For You” algorithm's performance on American users.","ByteDance Allegedly Trained ""For You"" Algorithm Using Content Scraped without Consent from Other Social Platforms",Web Scraping and Data Analysis,3,Social Media / Tech Industry,No,"Data Collection, Data Analysis, Personalization of Content",Semi-autonomous,Social Media / Tech Industry,No,Data Analysis,Low,Information & Communication
177,2022-04-19,"['1558', '1583', '1600', '1601', '1602']",['google-docs'],['google-docs'],['google-docs-users'],"Google’s “inclusive language” feature prompting writers to consider alternatives to non-inclusive words reportedly also recommend alternatives for words such as “landlord” and “motherboard,” which critics said was a form of obtrusive, unnecessary, and bias-reinforcing speech-policing.",Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions,Language Processing,3,Information Technology,No,Text Analysis,Semi-Autonomous,Information Technology,No,Data Analysis,Medium,Technology & IT Services
188,2018-04-11,"['1603', '1604', '1782', '1605']",['salta-city-government'],['microsoft'],"['salta-teenage-girls', 'salta-girls-of-minority-groups']","In 2018, during the abortion-decriminalization debate in Argentina, the Salta city government deployed a teenage-pregnancy predictive algorithm built by Microsoft that allegedly lacked a defined purpose, explicitly considered sensitive information such as disability and whether their home had access to hot water.",Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data,Predictive Modeling,3,Public Health,Yes,"Data Analysis, Prediction",Semi-Autonomous,Public Health,Yes,Data Analysis,Low,Health & Social Services
191,2020-10-06,"['1614', '1615']",['naver'],['naver'],['naver-customers'],"The Korean Fair Trade Commission (FTC) imposed a 26.7B KRW on Naver for manipulating shopping and video search algorithms, favoring its own online shopping business to boost its market share. ",Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services,Algorithm Manipulation,3,Digital Marketing and E-Commerce,No,Search Algorithm Optimization,Semi-Autonomous,Digital Marketing and E-Commerce,No,Other/Unclear,Low,Retail & E-commerce
201,2020-04-14,"['1654', '2435']",['extinction-rebellion-belgium'],['unknown'],"['shophie-wilmes', 'belgian-government']",A deepfake video showing the Belgium’s prime minister speaking of an urgent need to tackle the climate crises was released by a climate action group.,Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action,Deepfake video creation,3,Environmental/Political,Yes,"Video manipulation, Speech synthesis",Semi-autonomous,Environmental/Political,Yes,Non-Text Media,Low,Technology & IT Services
204,2022-02-11,"['1662', '1663', '1664', '1665']",['zhihu'],['sangfor-technologies'],"['zhihu-employees', 'chinese-tech-workers']","The firing of an employee at Zhihu, a large Q&A platform in China, was allegedly caused by the use of a behavioral perception algorithm which claimed to predict a worker’s resignation risk using their online footprints, such as browsing history and internal communication.",A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm,Predictive Analytics,3,Corporate/Private,No,"Data Analysis, Behavioral Analysis",Semi-Autonomous,Corporate/Private,No,Data Analysis,Low,Other/Unclear
209,2020-10-20,"['1688', '1689', '1690', '1691', '1692']",['tesla'],['tesla'],['tesla-drivers'],The “rolling stop” functionality within the “Aggressive” Full Self Driving (FSD) profile that was released via a Tesla firmware update was recalled and disabled.,Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode,Software Update Recall,5,Private Transportation,No,Autonomous Driving Functionality,Level 5 (Full Automation),Private Transportation,No,Other/Unclear,Low,Transportation
219,2020-11-15,['1730'],['ezemvelo-kzn-wildlife'],['unknown'],['rhinos-in-conservation'],AI cameras installed by Ezemvelo KZN Wildlife failed to detect poachers when four dehorned rhino carcasses were found.,Poachers Evaded AI Cameras and Killed Four Rhinos,Poacher detection,3,Wildlife conservation,Yes,"Image recognition, motion detection",Semi-autonomous,Wildlife conservation,Yes,Non-Text Media,Low,Other/Unclear
189,2019-10-15,"['1609', '1670', '1671', '1672', '1673', '1674']",['uk-department-of-work-and-pensions'],['uipath'],['people-with-disabilities'],People with disabilities were allegedly disproportionately targeted by a benefit fraud detection algorithm which the UK’s Department of Work and Pensions was urged to disclose.,Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities,Fraud Detection,3,Government/Public Sector,"Department of Work and Pensions, UK","Pattern Detection, Data Analysis",Semi-autonomous,Government/Public Sector,"Department of Work and Pensions, UK",Data Analysis,Low,Public Administration & Defense
214,2020-01-02,['1722'],['lockport-city-school-district'],['sn-technologies'],['black-students'],"SN Technologies allegedly misled Lockport City Schools about the performance of its AEGIS face and weapons detection systems, downplaying error rates for Black faces and weapon misidentification.",SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems’ Performance,"facial recognition, object detection, weapons detection",1,"Education, law enforcement, public administration",yes,"Face Recognition, Weapon Detection",Semi-Autonomous (since the system is likely used to assist human operators in identifying threats),Education,Yes,Other/Unclear,Low,Education
215,2020-04-01,['1723'],['facebook'],['facebook'],['facebook-content-moderators'],"Content moderators and employees at Facebook demand better working conditions, as automated content moderation system allegedly failed to achieve sufficient performance and exposed human reviewers to psychologically hazardous content such as graphic violence and child abuse.",Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation,Content Moderation,3,Social Media/Technology,No,"Content Moderation, Detecting Inappropriate Content",Semi-Autonomous,Social Media/Technology,No,Other/Unclear,Low,Information & Communication
192,2022-03-17,"['1616', '1617']",['estee-lauder'],['hirevue'],"[""pseudonymous-estee-lauder's-former-staff""]",Three make-up artists lost their positions following an algorithmically-assessed video interview by HireVue who reportedly failed to provide adequate explanation of the findings.,Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue,Applicant Assessment,3,Human Resources/Recruitment,No,Video Interview Analysis,Semi-Autonomous,Human Resources/Recruitment,No,Data Analysis,Low,Technology & IT Services
217,2016-11-16,"['1725', '1726']",['evolver'],['evolver'],['fair-visitors'],"At the 18th China Hi-Tech Fair, a robot suddenly smashed through a glass booth and injured a visitor, after a staff member reportedly mistakenly pressed a button, causing it to reverse and accelerate.","Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",Exhibition/ Demonstration,3,Trade Fairs/ Exhibitions,No,Movement Control,Semi-autonomous,Trade Fairs/ Exhibitions,No,Action & Control,Low,Technology & IT Services
208,2021-05-01,"['1683', '1684', '1685', '1686', '1687', '1759', '1760', '1761']",['tesla'],['tesla'],['tesla-drivers'],"In late 2021, Tesla owners’ complaints to the National Highway Traffic Safety Administration about sudden unexpected automatic braking rapidly increased, coinciding with when radar was no longer equipped in its Model 3 and Model Y vehicles.","Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",Automatic braking system,2,Automotive,No,Automatic braking system,Level 2 (Partial Automation),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
212,2021-01-01,"['1711', '1712', '1713', '1714']",['xpeng-motors'],['unknown'],['xpeng-motors-customers'],The Chinese electric vehicle (EV) firm XPeng Motors was fined by local market regulators for illegally collecting in-store customers’ facial images without their consent for six months.,XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras,Facial Recognition,3,Automotive,No,"Data Collection, Facial Recognition",Semi-Autonomous,Automotive,No,Data Analysis,Low,Manufacturing & Industrial
193,2013-11-27,['1620'],['target'],['fireeye'],"['target', 'target-customers']","Alerts about a Target data breach were ignored by Minneapolis Target’s staff reportedly due to them being included with many other potential false alerts, and due to some of the company’s network infiltration alerting systems being off to reduce such false alerts, causing private data theft for millions of customers.  ","Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers",Network Security Monitoring,3,Retail,No,Anomaly Detection,Semi-autonomous,Retail,No,Other/Unclear,Medium,Retail & E-commerce
196,2013-09-01,"['1633', '1634', '1635', '1636', '1637']",['pakistan-national-database-and-registration-authority'],['pakistan-national-database-and-registration-authority'],['pakistani-citizens'],"When the leader of the Afghan Taliban was found possessing a valid ID card in the Pakistani national biometric identification database system, Pakistan launch a national re-verification campaign that is linked to numerous changes in recognition status and loss of services.",Compromise of National Biometric ID Card System Leads to Reverification and Change of Status,Biometric Identification & Verification,3,Government/Security,Yes,Biometric Identification & Verification,Semi-Autonomous,Government/Security,Yes,Other/Unclear,Low,Public Administration & Defense
207,2021-01-10,"['1679', '1680', '1681', '1682']",['honolulu-police-department'],['boston-dynamics'],['honolulu-homeless-people'],Honolulu Police Department spent federal pandemic relief funds on a robot dog to take body temperatures and patrol a homeless quarantine encampment which local civil rights advocates criticized as dehumanizing.,Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment,Temperature Measurement and Patrol,3,Public Health and Safety,Yes,"Temperature Scanning, Surveillance",Semi-Autonomous,Public Health and Safety,Yes,Other/Unclear,Low,Health & Social Services
211,2021-12-11,"['1696', '1697', '1698', '1699', '1700', '1701', '1702']",['taxis-g7'],['tesla'],['pedestrians'],"In Paris, about 20 people were injured in an accident involving a Tesla Model 3 taxi cab which was reportedly caused by a sudden unintended acceleration (SUA) episode and braking issues.",A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries,Accident Analysis and Prevention,3,Transportation,No,"Collision Detection and Prevention, Automated Braking",Semi-Autonomous,Transportation,No,Other/Unclear,Low,Transportation
187,2022-02-04,"['1596', '1597', '1598']",['ai-addict'],['tesla'],"['john-bernal', 'san-jose-public']","A YouTuber who was a Tesla’s employee conducted an on-road review of Tesla's Full Self Driving (FSD) Beta, showing its navigation in various road environments in San Jose and collision with a bollards during Autopilot, allegedly causing his dismissal from the company.","YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",Vehicle Navigation,5,Automotive,No,"Path Planning, Object Detection, Collision Avoidance",Full Autonomy (Level 5),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
185,2022-03-01,"['1586', '1587', '1588', '1589']",['tiktok'],['tiktok'],"['tiktok-users', 'tiktok-new-users']", An investigation by NewsGuard into TikTok’s handling of content related to the Russia-Ukraine war showed its “For You” algorithm pushing new users towards false and misleading content about the war within less than an hour of signing up.,"TikTok's ""For You"" Algorithm Directed New Users towards Disinformation about the War in Ukraine",Content Filtering & Recommendation,3,Social Media/News,No,"Content Recommendations, News Filtering",Semi-Autonomous,Social Media/News,No,Other/Unclear,Medium,Information & Communication
205,2022-02-25,"['1666', '1667', '1668', '1669']","['individuals-in-the-donbass-region', 'individuals-in-russia', 'media-organizations-in-crimea']",['unknown'],['ukrainian-social-media-users'],"According to security reports by Meta, fictitious personas with GAN-generated profile pictures were used by people operating in Russia and Ukraine to push a disinformation campaign targeting Ukrainian social media users, and were taken down.",AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians,Disinformation detection and prevention,3,"Arts, entertainment and recreation, information and communication",no,"Image recognition, Natural Language Processing (NLP), Social media monitoring",Semi-autonomous (Human intervention required for final decisions),Information and communication,Yes (Security and defence),Non-Text Media,Low,Information & Communication
218,2020-06-01,"['1727', '1728', '1950']",['tesla'],['tesla'],"['delivery-truck', 'pedestrians', 'tesla-drivers']","On a highway in Taiwan, a Tesla Sedan, reportedly operating on Autopilot mode, crashed into a large overturned truck, barely missing a pedestrian.",Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway,Vehicle Autopilot,3,Transport,No,Automated Driving System,Level 3 (Conditional Automation),Transport,No,Other/Unclear,Low,Other/Unclear
197,2021-10-01,"['1638', '1639', '1640', '1641']",['facebook'],['facebook'],['facebook-users'],"Facebook's internal report showed an at-least six-month long alleged software bug that caused moderator-flagged posts and other harmful content to evade down-ranking filters, leading to surges of misinformation on users' News Feed.","Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",Content Moderation,3,Social Media,No,"Text Analysis, Flagging Inappropriate Content",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
199,2019-04-01,"['1647', '1648', '1649', '1650', '1651', '2024', '2031']",['ever-ai'],['ever-ai'],['ever-ai-users'],"Ever AI, now Paravision AI, allegedly failed to inform customers about the development and use of facial recognition that facilitates the sale of customers’ data to various businesses, a business model that critics said was an egregious violation of privacy.",Ever AI Reportedly Deceived Customers about FRT Use in App,Facial Recognition,3,Consumer Technology,No,Data Collection and Processing,Semi-Autonomous,Consumer Technology,No,Data Analysis,Low,Technology & IT Services
210,2020-04-28,"['1693', '1694', '1695']",['bharatiya-janata-yuva-morcha'],['persistent-systems'],"['indian-voters', 'indian-social-media-users', 'indian-women-journalists']","The Indian political social media app Tek Fog allegedly allowed operatives affiliated with the ruling political party to hijack social media trends and manipulate public opinion on other apps such as Twitter and WhatsApp, which opposition parties denounced as a national security threat.",Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms,Social Media Trend Manipulation,3,Information and Communication,No,"Data Analysis, Trend Prediction",Semi-Autonomous,Information and Communication,No,Data Analysis,Low,Information & Communication
235,2016-04-15,['1756'],['ping-an'],['ping-an'],"['ping-an-customers', 'chinese-minority-groups']","Customers’ untrustworthiness and unprofitability were reportedly determined by Ping An, a large insurance company in China, via facial-recognition measurements of micro-expressions and body-mass indices (BMI), which critics argue was likely to make mistakes, discriminate against certain ethnic groups, and undermine its own industry.","Chinese Insurer Ping An Employed Facial Recognition to Determine Customers’ Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate",Facial Recognition and BMI Analysis,3,Insurance,No (as Ping An is a private company),"Image Processing, Biometric Analysis, Risk Assessment",Semi-Autonomous (as the system likely requires human intervention for final decision-making),Insurance,No (as Ping An is a private company),Data Analysis,Low,Finance & Insurance
227,2018-01-12,"['1744', '1973', '1974']",['waze'],['waze'],"['tourists', 'waze-users']","The tourists driving through Vermont blamed Waze for directing them into a boat launch in Lake Champlain, prompting the vehicle to slide into the water by the time the drivers realized their location in the dark and foggy weather.","Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",Navigation guidance,3,Consumer Services,No,Route Optimization,Semi-Autonomous,Consumer Services,No,Other/Unclear,Low,Consumer Services
222,2020-07-18,['1735'],['satria-technologies'],['openai'],"['thoughts-users', 'twitter-users']","Tweets created by Thoughts, a tweet generation app that leverages OpenAI’s GPT-3, allegedly exhibited toxicity when given prompts related to minority groups.",Thoughts App Allegedly Created Toxic Tweets,Text Generation,3,Information and Communication,No,"Natural Language Processing, Text Generation",Semi-Autonomous,Information and Communication,No,Language Processing,Medium,Information & Communication
223,2019-10-09,['1737'],['hive-box'],['hive-box'],['hive-box-customers'],"Facial-recognition locks by Hive Box, an express delivery locker company in China, were easily opened by a group of fourth-graders in a science-club demo using only a printed photo of the intended recipient’s face, leaving contents vulnerable to theft.",Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient’s Facial Photo,Facial Recognition,3,Logistics/Shipping,No,"Image Processing, Pattern Recognition",Semi-Autonomous,Logistics/Shipping,No,Non-Text Media,Low,Transportation
229,2018-04-23,"['1746', '1747']",['youtube'],['youtube'],"['youtube-users', 'youtube-content-creators']",YouTube’s thumbnail monitoring system was allegedly evaded by content farms such as ones in Cambodia who spike viewership and generate ad revenue using bestiality-themed thumbnails.,Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System,Content Monitoring,3,Media & Entertainment,No,"Image Recognition, Pattern Recognition",Semi-Autonomous,Media & Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
224,2020-07-01,['1738'],['wechat-pay'],['wechat'],['wechat-pay-users'],"In China, fraudsters bypassed facial-recognition security for online financial transactions on WeChat Pay by crafting identity-verification GIFs of victims from their selfies on WeChat Moments, a social media platform.",WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims’ Social Media Content,Facial Recognition,3,Finance/ Banking,No,"Identity Verification, Security Monitoring",Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
239,2009-09-01,['1764'],['intensive-partnerships-for-effective-teaching'],['intensive-partnerships-for-effective-teaching'],"['students', 'low-income-minority-students', 'teachers']","Gates-Foundation-funded Intensive Partnerships for Effective Teaching Initiative’s algorithmic program to assess teacher performance reportedly failed to achieve its goals for student outcomes, particularly for minority students, and was criticized for potentially causing harm against teachers.",Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers,Teacher Performance Assessment,3,Education,yes,"Data Analysis, Algorithmic Assessments",Semi-Autonomous (requires human intervention for final decisions),Education,Yes,Data Analysis,Low,Education
225,2017-04-07,"['1739', '1740']","['jupiter-hospital', 'memorial-sloan-kettering']",['ibm-watson-health'],"['oncologists', 'cancer-patients']",Internal documents from IBM Watson Health showed negative assessments from customers such as Florida’s Jupiter Hospital and Memorial Sloan Kettering criticizing its Watson for Oncology product for allegedly unsafe and incorrect cancer treatment recommendations.,IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations,Cancer treatment recommendation,3,Healthcare,Yes,"Data analysis, Decision-making support",Semi-autonomous,Healthcare,Yes,Data Analysis,Low,Health & Social Services
232,2018-04-29,"['1751', '1752', '1975', '2018']",['tesla'],['tesla'],"['yoshihiro-umeda', 'pedestrians', 'tesla-drivers']","A Tesla Model X operated on Autopilot reportedly failed to recognize the parked motorcycles, pedestrians, and van in its path in Kanagawa, Japan, and ran over a motorcyclist who previously stopped when a member of his motorcyclist group was involved in an accident.","Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",Object Detection and Collision Avoidance,3,Private Transportation,No,"Object Detection, Path Planning, and Collision Avoidance",Level 3 (Conditional Automation),Automotive Industry,No,Other/Unclear,Low,Manufacturing & Industrial
242,2021-02-24,['1775'],['chakan-plant-of-automotive-stampings-and-assemblies'],['unknown'],['umesh-ramesh-dhake'],A sensor snag resulted in an automotive parts factory robot falling on a factory worker in India,Manufacturing Robot Failure Caused Factory Worker's Death in India,Fault Detection,3,Manufacturing,No,"Predictive Maintenance, Anomaly Detection",Semi-Autonomous,Manufacturing,No,Data Analysis,Low,Manufacturing & Industrial
244,2020-08-03,['1783'],['aurora-police-department'],['unknown'],['the-gilliam-family'],"An automated plate reader reportedly matched a license plate information, but of a family’s minivan and an alleged motorcycle in Montana that was reportedly stolen earlier in the year, resulting in them and their children being held at gunpoint and detained in handcuffs by multiple Aurora police officers.","Colorado Police’s Automated License Plate Reader (ALPR) Matched a Family’s Minivan’s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint","license plate recognition, Matching",3,law enforcement,yes,License Plate Recognition,Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
233,2018-12-03,['1753'],['tumblr'],['tumblr'],"['tumblr-content-creators', 'tumblr-users']","Tumblr’s automated tools to identify adult content were reported to have incorrectly flagged inoffensive images as explicit, following its announcement to ban all adult content on the platform.",Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit,Content Moderation,3,Information Technology,No,Image Recognition,Semi-Autonomous,Information Technology,No,Non-Text Media,Low,Technology & IT Services
230,2019-03-01,['1748'],['tesla'],['tesla'],"['jeremy-beren-banner', 'tesla-users']","In Florida, a Model 3 Tesla on Autopilot mode crashed into a tractor-trailer truck, killing the 50-year-old driver.","Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver",Vehicle Navigation,5,Transportation,No,Autopilot Navigation,Full Autonomy,Automotive,No,Action & Control,Low,Manufacturing & Industrial
246,2014-04-16,"['1785', '1787']",['prairie-village-police-department'],['unknown'],['mark-molner'],"An automated license plate reader (ALPR) camera misread a 7 as a 2 and incorrectly alerted the local police about a stolen Oldsmobile car, which was allegedly not able to be verified by an officer before a traffic stop was effected on a BMW in Kansas City suburb.","Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",License Plate Recognition,3,Law Enforcement,Yes,Image Recognition,Semi-Autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
228,2019-02-01,['1745'],['apple'],['apple'],"['tourists', 'apple-maps-users']","Near Los Angeles, Apple Maps allegedly directed a couple on a ski trip in the mountains toward into an unconventional route out of town, where the drivers found themselves lost and stuck on an unpaved road in the snow.",Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains,Navigation Guidance,3,Consumer Services,No,Route Planning and Optimization,Semi-Autonomous,Consumer Services,No,Other/Unclear,Low,Consumer Services
231,2016-01-20,"['1749', '1750', '208', '1945']",['tesla'],['tesla'],"['gao-yaning', 'tesla-drivers']","A Tesla Model S collided with and killed a road sweeper on a highway near Handan, China, an accident where Tesla previously said it was not able to determine whether Autopilot was operating at the time of the crash.",A Tesla Crashed into and Killed a Road Sweeper on a Highway in China,Autonomous Driving,4,Transportation,No (Assuming this accident involved a privately owned Tesla vehicle),"Object Detection, Path Planning","High (Assuming Tesla's Autopilot was potentially in use, which represents a high level of vehicle autonomy)",Transportation,No (Assuming this accident involved a privately owned Tesla vehicle),Other/Unclear,High,Transportation
245,2009-03-30,['1784'],['san-francisco-police-department'],['unknown'],['denise-green'],"In San Francisco, an automated license plate reader (ALPR) camera misread a number as belonging to a stolen vehicle having the wrong make, but its photo was not visually confirmed by the police due to poor quality and allegedly despite multiple chances prior to making a traffic stop, causing an innocent person to be pulled over at gunpoint and restrained in handcuffed.",Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California,license plate matching,3,law enforcement,yes,License Plate Recognition,Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
248,2018-11-23,"['1789', '1790']",['contra-costa-county-sheriff'],['vigilant-solutions'],['brian-hofer'],"In Oakland, a previously stolen rental car that was returned but allegedly not updated in the police database was pinged by an automated license plate reader (ALPR) camera, leading to police’s wrongful detainment of an innocent person reportedly using excessive force and improper conduct.","Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",Automated License Plate Recognition,3,Law Enforcement,Yes,"License Plate Recognition, Database Management",Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
236,2022-04-13,['1757'],['scammers'],['unknown'],['email-users'],GAN faces were allegedly used by scammers alongside a parked domain and a fake website to impersonate a Boston law firm.,AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston,Image Generation,3,Legal,No,"Image Generation, Identity Verification",Semi-Autonomous,Legal,No,Non-Text Media,Low,Other/Unclear
234,2019-09-06,"['1754', '1755']",['waze'],['waze'],['los-gatos-residents'],"Waze app was blamed by Los Gatos town residents for contributing to high wildfire hazard risk via allegedly routing weekend beach-going drivers through their neighborhoods, effectively choking off their single escape route in the event of a medical emergency or wildfire.","Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",Traffic navigation and routing,3,Transportation,No,Traffic management and route optimization,Semi-autonomous,Transportation,No,Other/Unclear,Low,Transportation
238,2018-10-01,['1762'],['oregon-department-of-human-services'],['oregon-department-of-human-services'],"['children-of-minority-groups', 'families-of-minority-groups']","Oregon’s Department of Human Services (DHS) stopped using its Safety at Screening Tool, that is aimed to predict the risk that children wind up in foster care or be investigated in the future, and opted for a new process allegedly to reduce disparities and improve racially equitable decision-making.",Oregon’s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias,Predicting risk in child welfare cases,3,Public Health and Safety,Yes,Risk prediction,Semi-autonomous,Public Health and Safety,Yes,Other/Unclear,Low,Health & Social Services
226,2015-04-01,"['1741', '1742', '1743']",['waze'],['waze'],"['sherman-oaks-residents', 'waze-users', 'los-angeles-city-government']","For years, Waze has, in an attempt to cut travel times, allegedly caused more traffic and guided drivers to make unsafe and often un-permitted traffic decisions, which was described by a Los Angeles city council member as a threat to public safety.",Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions,Traffic Management and Routing,4,Transportation,No,Traffic Management and Routing,High Autonomy,Transportation,No,Other/Unclear,Low,Transportation
241,2022-07-21,"['1772', '1773', '1774', '1776', '1781']",['russian-chess-federation'],['unknown'],['child-named-christopher'],A chess robot at a tournament in Russia broke the finger of a child who reached onto the board before the robot had completed its move,Chess-Playing Robot Broke Child's Finger in Russia,Playing Chess,3,Entertainment,No,"Game playing, Motion planning",Semi-autonomous,Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
240,2021-06-29,"['1767', '1768', '1769', '1770', '2230']","['github', 'programmers']",['github'],['intellectual-property-rights-holders'],Users of GitHub Copilot can produce source code subject to license requirements without attributing and licensing the code to the rights holder.,"GitHub Copilot, Copyright Infringement and Open Source Licensing",Code generation,4,Information Technology,No,"Code generation, Compliance Monitoring",High Autonomy,Information Technology,No,Other/Unclear,Low,Technology & IT Services
243,2020-01-01,"['1777', '1778']",['unknown'],['unknown'],"['twitter', 'twitter-users', 'twitter-users-participating-in-covid-19-discussions']","Bots by anonymous actors were found by researchers to make up roughly half of Twitter accounts participating in COVID-19 discussions, many of which posted tweets about “reopening America“.",Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues,Social Media Analysis,3,Information and Communication,No,"Data Analysis, Natural Language Processing",Semi-Autonomous,Information and Communication,No,Data Analysis,Low,Information & Communication
270,2011-04-18,['1851'],['apple'],['apple'],"['renren', 'buding-movie-tickets', 'yi-xia', 'dangdang', 'chinese-startups', 'chinese-companies']","Following Apple’s changes in ranking algorithm in its iTunes App Store, apps by allegedly reputable companies and local startups in China experienced significant drops in ranking order.","Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China",Algorithm Analysis,3,Technology / IT Services,No,Ranking Algorithm,Semi-autonomous,Technology / IT Services,No,Other/Unclear,Low,Technology & IT Services
271,2022-07-24,"['1852', '1861', '1862']",['tesla'],['tesla'],"['landon-embry', 'motorcyclists', 'tesla-drivers']","A Tesla Model 3 operating on Autopilot mode slammed into the back of a Harley-Davidson motorcycle on an interstate in Utah, throwing the rider from the bike and killing him instantly.",Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah,Autonomous Driving,5,Private Transport,No,"Autonomous Navigation, Collision Detection",Level 5 (Fully Autonomous),Private Transport,No,Action & Control,Low,Other/Unclear
268,2020-03-16,"['1849', '1929', '3905', '3906']","['youtube', 'twitter', 'facebook']","['youtube', 'twitter', 'facebook']","['victims-of-crimes-documented-on-social-media', 'investigative-journalists', 'international-criminal-court-investigators', 'international-court-of-justice-investigators', 'criminal-investigators']","Automated permanent removal of violating social media content, such as terrorism, violent extremism, and hate speech, without archival has allegedly hindered the potential use of this content for investigating serious crimes and hampered efforts in criminal accountability.",Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts,Content Moderation,4,Social Media,No,"Text Analysis, Image Recognition",Semi-Autonomous,Information and Communication,Yes,Data Analysis,Low,Information & Communication
251,2018-08-01,"['1794', '2384', '2975']",['amazon'],['amazon'],"['small-businesses-on-amazon', 'amazon-customers']","Amazon tweaked product-search algorithm to boost and guide customers towards more profitable in-house products instead of showing mainly most-relevant and best-selling listings, which its internal engineers and lawyers alleged to violate company’s best-for-customer principle.",Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products,Algorithm Optimization,3,E-commerce,No,Search Engine Optimization,Semi-Autonomous,E-commerce,No,Other/Unclear,Low,Retail & E-commerce
273,2020-12-24,['1856'],['faceapp'],['faceapp'],"['faceapp-non-binary-presenting-users', 'faceapp-transgender-users', 'faceapp-users']",FaceApp’s algorithm was reported by a user to have predicted different genders for two mostly identical facial photos with only a slight difference in eyebrow thickness.,FaceApp Predicted Different Genders for Similar User Photos with Slight Variations,human facial image transformation,1,"information and communication, Arts, entertainment and recreation",no,Image Processing / Facial Recognition,Semi-Autonomous (requires human input for operation),Information Technology / Social Media,No,Non-Text Media,Low,Information & Communication
259,2022-06-03,"['1822', '1842']",['yannic-kilcher'],['yannic-kilcher'],['internet-social-platform-users'],"A YouTuber built GPT-4chan, a model based on OpenAI’s GPT-J and trained on posts containing racism, misogyny, and antisemitism collected from 4chan’s “politically incorrect” board, which he made publicly available, and deployed as multiple bots posting thousands of messages on the same 4chan board as a prank.","YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",Text Generation,3,Social Media/Internet,No,"Text Generation, Text Analysis",Semi-Autonomous,Social Media/Internet,No,Data Analysis,Low,Information & Communication
255,2020-05-31,"['1805', '1806', '1807', '1808', '1809', '1431', '1811', '1812', '1813']",['chicago-police-department'],['shotspotter'],['michael-williams'],"ShotSpotter audios were previously admitted to convict an innocent Black man in a murder case in Chicago, resulted in his nearly-one-year-long arrest before being dismissed by prosecutors as insufficient evidence.",Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case,Audio Surveillance,3,Law Enforcement,Yes,Audio Analysis,Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
266,2022-01-15,"['1844', '2532', '2533', '2534', '2535', '2536', '2537', '2538']",['replika'],['replika'],"['replika-users', 'replika-male-users', 'replika']","Replika's AI-powered ""digital companions"" was allegedly abused by their users, who posted on Reddit abusive behaviors and interactions such as using slurs, roleplaying violent acts, and stimulating sexual abuse.","Replika's ""AI Companions"" Reportedly Abused by Its Users",User Interaction,3,Consumer Technology,No,"Digital Companionship, User Interaction",Semi-autonomous,Consumer Technology,No,Other/Unclear,Low,Technology & IT Services
253,2022-05-18,"['1796', '1797', '1798', '1799']",['cruise'],['cruise'],"['san-francisco-traffic-participants', 'san-francisco-public']","Cruise’s autonomous vehicles were shown on video stopping in the middle of the road and causing blockages in San Francisco, as they were disabled allegedly due to lost connection to their company’s server.","Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",Vehicle Navigation,4,Transportation,No,"Autonomous Driving, Network Connection",High Automation,Transportation,No,Other/Unclear,Low,Transportation
249,2016-10-01,"['1791', '1792']",['chinese-government'],['chinese-government'],"['uyghur-people', 'turkic-muslim-ethnic-groups']",A suite of AI-powered digital surveillance systems involving facial recognition and analysis of biometric data were deployed by the Chinese government in Xinjiang to monitor and discriminate local Uyghur and other Turkic Muslims.,Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang,Facial recognition and biometric data analysis,4,Public security,Yes,"Real-time monitoring, pattern recognition, predictive analytics",Highly autonomous,Government/Public Sector,Yes,Other/Unclear,Low,Public Administration & Defense
254,2015-05-01,"['1804', '2069']",['google'],['google'],"['google-photos-users-residing-in-illinois', 'google-photos-users', 'illinois-residents']","A class-action lawsuit alleged Google failing to provide notice, obtain informed written consent, or publish data retention policies about the collection, storage, and analysis of its face-grouping feature in Google Photos, which violated Illinois Biometric Information Privacy Act (BIPA).","Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA","facial recognition, facial grouping",1,information and communication,no,"Facial Recognition, Data Analysis","Semi-Autonomous (as the system requires human input to function, but performs analysis and grouping autonomously)","Information Technology, Legal",No (since Google is a private entity and this incident pertains to their operations),Data Analysis,Low,Technology & IT Services
256,2021-11-07,['1814'],['chicago-police-department'],['shotspotter'],['chicago-drivers'],"A car stop resulting in a DUI arrest of its driver was allegedly based solely on a ShotSpotter alert, the reliability of which came into question by public defenders, who subpoenaed the company to assess its gunshot alert system.",DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert,Gunshot detection,3,Law Enforcement,Yes,Audio analysis for gunshot detection,Semi-autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
250,2016-02-01,['1793'],['castricum-municipality'],['castricum-municipality'],['unnamed-property-owner'],"A home value generated by a black-box algorithm was reportedly defended by the Castricum court, which was criticized by a legal specialist for setting a dangerous precedent for accepting black-box algorithms as long as their results appear reasonable.",Dutch City Court Defended Home Value Generated by Black-Box Algorithm,Home Value Estimation,3,Real Estate,No,"Data Analysis, Prediction",Semi-Autonomous,Real Estate,No,Data Analysis,Low,Other/Unclear
258,2022-05-13,"['1819', '1820']","['the-good-guys', 'kmart', 'bunnings']",['unknown'],"['the-good-guys-customers', 'kmart-customers', 'bunnings-customers']","Major Australian retailers reportedly analyzed in-store footage to capture facial features of their customers without consent, which was criticized by consumer groups as creepy and invasive.",Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent,Facial recognition,3,Retail,No,"Data analysis, Facial recognition",Semi-autonomous,Retail,No,Data Analysis,Low,Retail & E-commerce
274,2003-07-01,"['1857', '1859']",['virginia-courts'],['virginia-department-of-criminal-justice-services'],"['virginia-convicted-felons', 'virginia-black-offenders', 'virginia-young-offenders']","Virginia courts’ use of algorithmic predictions of future offending risks were found by researchers failing to reduce incarceration rates, showed racial and age disparities in risk scores and its application, and neither exacerbated or ameliorated historical racial differences in sentencing.",Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates,Risk Assessment,3,Judiciary,Yes,Predictive Modeling,Semi-Autonomous,Judiciary,Yes,Data Analysis,Low,Other/Unclear
267,2017-06-15,"['1845', '1846', '1847', '1848', '2101', '2141', '2142', '2143', '2144', '2226']",['clearview-ai'],['clearview-ai'],"['social-media-users', 'instagram-users', 'facebook-users']","Face-matching algorithm by Clearview AI was built using scraped images from social media sites such as Instagram and Facebook without user consent, violating social media site policies, and allegedly privacy regulations.",Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent,Facial Recognition,3,Social Media / Internet,No,"Image Analysis, Data Scraping",Semi-Autonomous,Social Media / Internet,No,Data Analysis,Low,Information & Communication
257,2012-05-04,"['1815', '1435', '1821', '2250']","['kansas-city-police-department', 'cleveland-division-of-police', 'chicago-police-department', 'atlanta-police-department']",['shotspotter'],"['neighborhoods-of-color', 'brown-communities', 'black-communities', 'adam-toledo']","Police departments disproportionately placed ShotSpotter sensors in black and brown neighborhoods, which is denounced by communities for allegedly creating dangerous situations, such as one involving in Adam Toledo's death.",Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color,Surveillance,3,Law enforcement,Yes,"Sound detection, gunfire location",Semi-autonomous,Law enforcement,Yes,Other/Unclear,High,Law Enforcement & Public Safety
264,2022-03-01,['1839'],['speedcam-anywhere'],['speedcam-anywhere'],['uk-drivers'],"Speedcam Anywhere, an app allowing users to document and report traffic violations via AI-based videographic speed estimation of a vehicle, raised concerns for UK drivers about its capabilities for surveillance and abuse.",AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology,Vehicle Speed Estimation and Traffic Violation Detection,3,"Transportation, Public Safety",Yes,"Image Processing, Speed Estimation, Traffic Violation Detection",Semi-Autonomous,"Transportation, Public Safety",Yes,Non-Text Media,Low,Transportation
252,2022-06-01,['1795'],['none'],['axon-enterprise'],"['us-schools', 'us-students']","Axon Enterprise considered development of remotely operated drones capable of tasering at a target a short distance away as a defense mechanism for mass shootings, despite its internal AI ethics board’s previous objection and condemnation as dangerous and fantastical.",Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US,Target Recognition and Control,3,Defense,Yes,Target Recognition and Taser Control,Semi-Autonomous,Defense,Yes,Action & Control,Medium,Public Administration & Defense
272,2019-10-08,"['1853', '1854', '1855']",['grab'],['grab'],"['non-tpi-registered-grab-drivers', 'grab-drivers-in-indonesia', 'grab-drivers']","Grab Indonesia was fined by the Indonesian Competition Commission (KPPU) for unfairly favoring drivers who rented cars via the Grab-affiliated company Teknologi Pengangkutan Indonesia (TPI), including offering more rides via their matchmaking algorithm.","Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",Algorithmic decision-making,3,Transportation,No,Matchmaking algorithm,Semi-autonomous,Transportation,No,Other/Unclear,Low,Transportation
260,2014-08-26,"['1823', '1831']","['us-department-of-homeland-security', 'us-citizenship-and-immigration-services']",['us-citizenship-and-immigration-services'],"['us-naturalized-citizens', 'us-immigrants', 'us-citizenship-applicants', 'us-immigration-applicants']","US Citizenship and Immigration Services (USCIS)’s ATLAS software used in vetting immigration requests was condemned by advocacy groups as a threat to naturalized citizens for its secretive algorithmic decision-making, reliance on poor quality data and unknown sources, and alleged discrimination of immigrants using biometric and sensitive information.",US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants,Decision-making,3,Government / Immigration,Yes,"Data Analysis, Decision-making",Semi-autonomous,Government / Immigration,Yes,Data Analysis,Medium,Public Administration & Defense
261,2017-11-15,"['1824', '1825', '1826', '1827', '1828', '1829', '1830', '1832']",['society-for-the-prevention-of-cruelty-to-animals'],['knightscope'],['san-francisco-homeless-people'],"Society for the Prevention of Cruelty to Animals (SPCA) deployed a Knightscope robot to autonomously patrol the area outside its office and ward off homeless people, which was criticized by residents as a tool of intimidation and ordered by the city of San Francisco to stop its use on a public right-of-way.","Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",Security Surveillance,5,Non-profit/Animal Welfare,No,"Autonomous Patrolling, People Detection",Fully Autonomous,Non-profit/Animal Welfare,No,Other/Unclear,Low,Technology & IT Services
262,2022-06-11,"['1833', '1834', '1835', '1836']",['boris-dayma'],"['boris-dayma', 'suraj-patil', 'pedro-cuenca', 'khalid-saifullah', 'tanishq-abraham', 'phuc-le-khac', 'luke-melas', 'ritobrata-ghosh']","['minority-groups', 'underrepresented-groups']",Publicly deployed open-source model DALL-E Mini was acknowledged by its developers and found by its users to have produced images which reinforced racial and gender biases.,DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes,Image Generation,3,Technology,No,"Image Generation, Bias Detection",Semi-Autonomous,Technology,No,Non-Text Media,Medium,Technology & IT Services
263,2015-09-01,['1838'],['youtube'],['youtube'],"['youtube-young-male-users', 'youtube-male-users', 'caleb-cain']","YouTube’s personalization and recommendation algorithms were alleged to have pushed and exposed its young male users to political extremism and misinformation, driving them towards far-right ideologies such as neo-Nazism and white supremacy.",YouTube Recommendations Implicated in Political Radicalization of User,Content Recommendation,3,Information and Communication,No,"Data Analysis, Pattern Recognition",Semi-Autonomous,Information and Communication,No,Data Analysis,Low,Information & Communication
265,2021-04-01,"['1840', '1841']",['uber-eats'],['uber-eats'],"['pa-edrissa-manjang', 'uber-eats-black-delivery-drivers']","A lawsuit by a former Uber Eats delivery driver alleged the company to have wrongfully dismissed him due to frequent false mismatches of his verification selfies, and discriminated against him via excessive verification checks.",Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results,Facial Recognition,3,Transportation & Delivery Services,No,Identity Verification,Semi-Autonomous,Transportation & Delivery Services,No,Other/Unclear,Low,Transportation
278,2022-08-07,"['1866', '1867', '1868']",['meta'],['meta'],"['jewish-people', 'blenderbot-3-users']",The publicly launched conversational AI demo BlenderBot 3 developed by Meta was reported by its users and acknowledged by its developers to have “occasionally” made offensive and inconsistent remarks such as invoking Jewish stereotypes.,Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments,Conversational AI,3,Information Technology,No,"Natural Language Processing, Social Media Monitoring",Semi-autonomous,Information Technology,No,Non-Text Media,Low,Technology & IT Services
275,2020-06-11,"['1858', '1860']",['facebook'],['facebook'],"['facebook-users-sharing-photo-evidence-of-slavery', 'facebook-users']",Facebook’s automated content moderation was acknowledged by a company spokesperson to have erroneously censored and banned Australian users from posting an article containing a 1890s photo of Aboriginal men in chains over nudity as historical evidence of slavery in Australia.,Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery,Content Moderation,4,Social Media,No,"Image Recognition, Text Analysis",High Autonomy,Social Media,No,Data Analysis,Low,Information & Communication
285,2022-07-18,['1888'],['google'],['google'],['google-lens-users'],A book title by Korea’s first minister of culture was mistranslated into an offensive phrase by Google Lens’s camera-based translation feature allegedly due to its training on internet communications and a lack of context.,Google Lens’s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean,Language Translation,3,IT/Communications,No,"Text Recognition, Translation",Semi-autonomous,IT/Communications,No,Language Processing,Low,Information & Communication
330,2016-12-15,['2017'],['amazon'],['amazon'],['amazon-users'],Amazon’s “Amazon’s Choice” algorithm recommended poor-quality defective products and were reportedly susceptible to manipulation by inauthentic reviews.,“Amazon’s Choice” Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation,Recommendation System,3,E-commerce,No,"Data Analysis, Machine Learning",Semi-Autonomous,E-commerce,No,Data Analysis,Medium,Retail & E-commerce
299,2020-12-15,['1935'],['masayuki-nakamoto'],['unknown'],['japanese-pornographic-actors'],"A man allegedly unblurred, using deepfake technology, pixelated pornographic images and videos of pornographic actors, which violated Japan’s obscenity law requiring images of genitalia to be obscured.",Japanese Porn Depixelated by Man using Deepfake,Deepfake Technology Use,3,Information and Communication Technology,No,"Image Manipulation, Deep Learning",Semi-Autonomous,Information and Communication Technology,No,Non-Text Media,Low,Information & Communication
323,2018-05-29,"['1992', '1193', '2006', '2514']",['tesla'],['tesla'],['laguna-beach-police-department'],"A Tesla sedan on Autopilot mode collided with a parked Laguna Beach Police Department car, resulting in minor injuries for its driver in Laguna Beach, California.",Tesla on Autopilot Crashed into Parked Police Car in California,semi-autonomous navigation,2,transportation and storage,no,Autonomous Driving,Level 3 (Conditional Automation),Transportation,Police Department,Other/Unclear,Low,Transportation
293,2022-06-03,"['1907', '1908', '1909', '1910', '1996', '1997', '2016']",['cruise'],['cruise'],"['cruise-passengers', 'toyota-prius-passengers']","A Cruise autonomous vehicle was involved in a crash at an intersection in San Francisco when making a left turn in front of a Toyota Prius traveling in an opposite direction, which caused occupants in both cars to sustain injuries.",Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection,Autonomous driving,4,Transportation,No,"Autonomous navigation, collision avoidance",High (Level 4-5),Transportation,No,Other/Unclear,Low,Transportation
325,2017-09-21,"['2004', '2005']",['facebook'],['facebook'],"['olivia-solon', ""olivia-solon's-facebook-connections""]",An Instagram user’s image containing violent content was reportedly used as advertisement on Facebook allegedly via automated means.,Offensive Instagram User Content Displayed as Facebook Ad,Content moderation,3,Social Media,No,"Image recognition, Text analysis",Semi-Autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
328,2020-06-13,"['2014', '2032']",['spamouflage-dragon'],['unknown'],"['facebook-users', 'twitter-users', 'youtube-users']","A pro-China propaganda campaign deployed fake accounts on Facebook, Twitter, and YouTube using GAN-synthesized faces to share and post comments on its content to gain wider circulation.",Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms,Disinformation Propagation,3,Social Media/Communication,No,"Text generation, Image Synthesis",Semi-Autonomous,Social Media/Communication,No,Non-Text Media,Low,Information & Communication
347,2021-05-06,"['2060', '2098', '2099']",['waymo'],['waymo'],['waymo-passengers'],"A Waymo self-driving taxi car was shown on video stranded on a road in Arizona while carrying a passenger, suddenly drove away from the company's roadside assistance worker, and ended up being stuck farther down the road.","Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",Autonomous Driving,4,Private Transport,No,"Autonomous Navigation, Obstacle Avoidance",High Automation (Level 4),Private Transport,No,Action & Control,Low,Other/Unclear
350,2022-09-13,"['2067', '2094']",['serve-robotics'],['serve-robotics'],['police-investigators'],A Serve Robotics delivery robot was shown on video rolling through a crime scene blocked off by police tape.,Delivery Robot Rolled Through Crime Scene,Surveillance/Inspection,3,Public Safety/Law Enforcement,no,"Video Analysis, Navigation",Semi-autonomous,Public Safety/Law Enforcement,Yes,Action & Control,Low,Law Enforcement & Public Safety
291,2021-05-28,"['1901', '1902', '1903', '2242', '2590', '2604']",['tesla'],['tesla'],"['california-department-of-motor-vehicles', 'tesla-customers', 'california-residents']","California’s Department of Motor Vehicles (DMV) accused Tesla of false advertising in its promotion of Autopilot and Full Self-Driving (FSD) technologies, alleging the company to have made untrue or misleading claims with marketing language about the capabilities of its products.",Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities,False advertising investigation,5,Automotive Industry,Department of Motor Vehicles (DMV),Autopilot and Full Self-Driving technologies,Level 5 (Full Autonomy),Automotive Industry,Department of Motor Vehicles (DMV),Other/Unclear,Medium,Manufacturing & Industrial
294,2018-05-26,"['1911', '1912', '1913', '1914']",['tesla'],['tesla'],"['you-you-xue', 'tesla-drivers']","Autopilot was alleged by its Tesla Model 3 driver to have unexpectedly malfunctioned, veering right without warning and crashing into a road divider near Thessaloniki, Greece, which resulted in damages to its wheel and door but no injury to the driver.",Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece,semi-autonomous navigation,2,transportation and storage,no,Autonomous Driving,Level 3 (Conditional Automation),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
280,2013-07-30,"['1872', '1873']",['coffee-meets-bagel'],['coffee-meets-bagel'],"['coffee-meets-bagel-users-having-no-ethnicity-preference', 'coffee-meets-bagel-users']","Users selecting “no preference” were shown by Coffee Meets Bagels’s matching algorithm more potential matches with the same ethnicity, which was acknowledged and justified by its founder as a means to maximize connection rate without sufficient user information.",Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”,User Preference Analysis,3,Consumer Services,No,"User Profiling, Recommendation System",Semi-Autonomous,Consumer Services,No,Other/Unclear,Low,Consumer Services
287,2020-10-27,['2471'],['none'],"['openai', 'nabla']",['nabla-customers'],"The French digital care company, Nabla, in researching GPT-3’s capabilities for medical documentation, diagnosis support, and treatment recommendation, found its inconsistency and lack of scientific and medical expertise unviable and risky in healthcare applications. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",OpenAI’s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm,"Medical documentation, diagnosis support, and treatment recommendation",3,Healthcare,No (Nabla is a private company),"Medical documentation, diagnosis support, and treatment recommendation","Semi-autonomous (the AI was being tested for its capabilities, not fully autonomous)",Healthcare,No (Nabla is a private company),Other/Unclear,Low,Health & Social Services
295,2018-11-08,"['1915', '1916', '1917', '2102', '2103']",['new-york-police-department'],['unknown'],"['ousmane-bah', 'nyc-black-people', 'nyc-black-young-people']","New York Police Department (NYPD)’s facial recognition system falsely connected a Black teenager to a series of thefts at Apple stores, which resulted in his wrongful attempted arrest.",Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification,Facial Recognition,3,Law Enforcement,Yes,"Image Processing, Pattern Recognition",Semi-autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
320,2018-01-22,"['1985', '1986', '1987', '2007']",['tesla'],['tesla'],"['tesla-drivers', 'culver-city-fire-department']","A Tesla Model S operating on Autopilot mode crashed into the back of a parked fire truck on a freeway in Culver City, California in a non-fatal collision.",Tesla on Autopilot Collided with Parked Fire Truck on California Freeway,Autonomous Driving,3,Transportation,No,"Object Detection, Collision Avoidance",Semi-autonomous,Private Transportation,No,Other/Unclear,High,Transportation
326,2014-12-09,"['2008', '2012', '2013']",['facebook'],['facebook'],"['facebook-users-having-posts-about-painful-events', 'facebook-users']","Facebook’s “Year in Review” algorithm which compiled content in users’ past year as highlights inadvertently showed painful and unwanted memories to users, including death of family member.",Facebook Automated Year-in-Review Highlights Showed Users Painful Memories,Content Curation & Recommendation,3,Social Media,No,Content Recommendation,Semi-Autonomous,Social Media,No,Other/Unclear,High,Information & Communication
335,2015-03-01,"['2047', '2090', '2091', '2092', '2122', '2123', '2124', '2125']",['uk-visas-and-immigration'],"['uk-visas-and-immigration', 'uk-home-office']",['uk-visa-applicants-from-some-countries'],"UK Home Office's algorithm to assess visa application risks explicitly considered nationality, allegedly caused candidates to face more scrutiny and discrimination.",UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality,Risk Assessment,3,Government/Public Services,Yes,"Data Analysis, Risk Assessment",Semi-Autonomous,Government/Public Services,Yes,Data Analysis,Medium,Public Administration & Defense
292,2021-09-01,"['1904', '1905', '1906']",['apple'],['apple'],"['silicon-valley-traffic-participants', 'silicon-valley-residents']",Apple’s autonomous cars were reported to have bumped into curbs and struggled to stay in their lanes after crossing intersections during an on-road test drives near the company’s Silicon Valley headquarters.,Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives,Autonomous vehicle navigation,3,Transportation,No,"Machine learning, Computer vision, Sensor fusion",Partial automation (Level 3),Transportation,No,Other/Unclear,Low,Transportation
300,2022-01-15,"['1936', '1937']",['tiktok'],['tiktok'],"['tiktok-male-teenager-users', 'tiktok-male-users', 'tiktok-teenage-users', 'tiktok-users', 'tiktok']","TikTok’s “For You” algorithm allegedly boosted or was manipulated by an online personality to artificially boost his content which promotes extreme misogynistic views towards teenagers and men, despite breaking its rules.","TikTok's ""For You"" Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",Content Moderation,3,Social Media,No,"Content Filtering, User Behavioral Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
318,2021-01-13,"['1977', '1978']",['facebook'],['facebook'],['facebook-users'],"Facebook’s algorithmic recommendations reportedly continued showing advertisements for gun accessories and military gear, despite Facebook’s halt on weapons accessories ads following the US Capitol attack.",Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads,Content Moderation,3,Social Media,No,Algorithmic Recommendations,Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
319,2019-12-29,"['1981', '1982', '1983', '1984', '1993']",['tesla'],['tesla'],"['derrick-monet', 'jenna-monet', ""the-monets'-family""]","A Tesla on Autopilot mode failed to see a parked fire truck and crashed into its rear on an interstate in Indiana, causing the death of an Arizona woman.",Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana,Vehicle Navigation,4,Automotive,No,"Object Detection, Collision Avoidance",High Automation (Level 4),Automotive,No,Other/Unclear,High,Manufacturing & Industrial
332,2016-04-05,"['2033', '2040', '2041', '2044']",['google'],['google'],"['black-women', 'black-people', 'google-users']","Google Image search reportedly showed disparate results along racial lines, featuring almost exclusively white women for “professional hairstyles” and black women for “unprofessional hairstyles” prompts.",Google Image Showed Racially Biased Results for “Professional” Hairstyles,Image Classification,3,Information Technology,No,"Image recognition, Search Optimization",Semi-Autonomous,Information Technology,No,Non-Text Media,Low,Technology & IT Services
340,2017-02-01,['2053'],['honda'],['honda'],['honda-customers'],Honda's Collision Mitigation Braking System (CMBS) allegedly caused accidents to consumers due to frequent instances of false obstacle detection.,Honda's CMBS False Positives Allegedly Caused Accidents to Customers,Obstacle detection and response,2,Private Vehicles,No,Collision detection and avoidance,Level 2 (Partial Automation),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
341,2017-04-06,"['2054', '2114', '2198', '2199', '2200']",['nissan'],['nissan'],"['nissan-drivers', 'traffic-participants']","Nissan's Automatic Emergency Braking (AEB) feature was reported in a series of complaints for false positives and abrupt braking behaviors, endangering car occupants and traffic participants. ","Nissan's ""Automatic Emergency Braking"" False Positives Posed Traffic Risks to Drivers",automatic emergency braking,2,transportation and storage,no,Automatic Emergency Braking (AEB) System,Level 2 (Partial Automation),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
334,2014-10-01,"['2046', '2077']",['uber'],['uber'],['local-law-enforcement-officers'],"Uber developed a secret program ""Greyball"" which prevented known law enforcement officers in areas where its service violated regulations from receiving rides.",Uber Deployed Secret Program To Deny Local Authorities Rides,Regulatory Evasion,3,Transportation,No,"Pattern Recognition, Data Analysis",Semi-Autonomous,Transportation,No,Data Analysis,Low,Transportation
305,2019-02-01,"['1942', '1943']",['youtube'],['youtube'],"['youtube-users', 'youtube-climate-skeptic-users']",YouTube’s recommendation system and its focus on views and watched time were alleged by an advocacy group to have driven people towards climate denial and misinformation videos.,YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content,Recommendation System,3,"Information and Communication (YouTube is a platform for sharing and viewing videos, which falls under this sector)",No (YouTube is a private sector company),Content Personalization and Recommendation (The system recommends videos based on previous views),Semi-autonomous (The AI system operates based on user interaction),Information and Communication (YouTube operates in this sector),No (YouTube is not a public sector entity),Other/Unclear,Low,Information & Communication
297,2020-02-20,"['1921', '1922', '1923']",['smart-columbus'],['easymile'],['unnamed-woman-passenger'],"A self-driving shuttle deployed by Smart Columbus in Linden neighborhood unexpectedly stopped on the street, which caused a woman to fall onto the floor from her seat.","EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",Autonomous Driving,5,Public Transportation,Yes,"Navigation, Obstacle Avoidance, Safety Monitoring",Level 5 (Full Autonomy),Public Transportation,Yes,Action & Control,Low,Transportation
282,2020-10-03,"['1879', '1881', '1972']",['facebook'],['facebook'],"['the-seed-company-by-e.w.-gaze', 'businesses-on-facebook']","Facebook’s content moderation algorithm misidentified and removed a Canadian business’s advertisement containing a photo of onions as products of overtly sexual content, which was later reinstated after review.",Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content,Content Moderation,3,Social Media,No,"Image Recognition, Text Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
276,2022-01-01,['1864'],['bucheon-city-government'],['unknown'],['bucheon-citizens'],"Bucheon government’s use of facial recognition in analyzing CCTV footage, despite gaining wide public support, was scrutinized by privacy advocates and some lawmakers for collecting data without consent, and retaining and misusing data beyond pandemic needs.","Local South Korean Government’s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse",Facial Recognition,3,Public Security,Yes,"Data Analysis, Facial Recognition",Semi-Autonomous,Public Security,Yes,Data Analysis,Low,Law Enforcement & Public Safety
290,2022-06-03,"['1900', '2413', '2414']",['toronto-city-government'],['toronto-public-health'],"['sunnyside-beachgoers', 'marie-curtis-beachgoers', 'toronto-citizens']","Toronto’s use of AI predictive modeling (AIPM) which had replaced existing methodology as the only determiner of beach water quality raised concerns about its accuracy, after allegedly conflicting results were found by a local water advocacy group using traditional means.",False Negatives for Water Quality-Associated Beach Closures,water quality testing,1,"human health and social work activities, public administration",yes,Predictive Modeling,Semi-Autonomous (since the AI model is used to determine beach water quality but its results are verified by humans),Public Health & Environment,Local Government (City of Toronto),Data Analysis,Low,Health & Social Services
296,2016-02-10,"['1918', '1919', '1920']",['twitter'],['twitter'],"['twitter-left-leaning-politicians', 'twitter-left-leaning-news-organizations', 'twitter-left-leaning-users', 'twitter-users']",Twitter’s “Home” timeline algorithm was revealed by its internal researchers to have amplified tweets and news of rightwing politicians and organizations more than leftwing ones in six out of seven studied countries.,Twitter Recommender System Amplified Right-Leaning Tweets,Content Amplification,3,Social Media,No,News Feed Algorithm,Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
313,2022-08-25,"['1967', '3207']",['meta'],['meta'],['marietje-schaake'],"Meta’s conversational AI BlenderBot 3, when prompted “who is a terrorist,“ responded with an incumbent Dutch politician’s name, who was confused about its association.",BlenderBot 3 Cited Dutch Politician as a Terrorist,text generation,1,information and communication,no,"Natural Language Processing, Conversational AI",Semi-Autonomous (requires user input for operation),Information and Communication Technologies,No,Language Processing,Low,Information & Communication
333,2021-03-17,"['2045', '2135', '2136', '2137', '2146', '2148']",['tesla'],['tesla'],"['unnamed-22-year-old-male-driver', 'tesla-drivers']","A Tesla Model Y on Autopilot collided with a parked Michigan State Police (MSP) car which had its emergency lights on, in Eaton County, Michigan, although no one was injured.",Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate,Autonomous Driving,5,Transportation,Yes,"Object Detection, Collision Avoidance",High,Public Safety/Transportation,Yes,Other/Unclear,Low,Transportation
304,2021-11-03,['1941'],['tesla'],['tesla'],"['unnamed-tesla-driver', 'tesla-drivers']","A Tesla Model Y in Full Self-Driving (FSD) mode drove into the wrong lane after making a left turn despite its driver allegedly attempting to overtake its driving, resulting in a non-fatal collision with another vehicle in the wrong lane in Brea, California.",Tesla on FSD Reportedly Drove into the Wrong Lane in California,Autonomous Driving,4,Private Transportation,No,"Autonomous Navigation, Collision Avoidance",High Automation (Level 4),Private Transportation,No,Action & Control,High,Transportation
331,2020-08-05,"['2022', '2023']",['instagram'],['instagram'],['instagram-users'],"A bug was reported by Instagram’s spokesperson to have prevented an algorithm from populating related hashtags for thousands of hashtags, resulting in an allege preferential treatment for some politically partisan hashtags.",Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags,Bug detection and fixing,3,Social Media/Technology,No,"Algorithm management, Social media content sorting",Semi-Autonomous,Social Media/Technology,No,Other/Unclear,Low,Information & Communication
337,2021-04-17,"['2049', '2071', '2072', '2112', '2115', '2116', '2117', '2118', '2237']",['tesla'],['tesla'],"['william-varner', 'unnamed-passenger']","A 2019 Tesla Model S was reportedly traveling on Adaptive Cruise Control (ACC) at high speed before crashing into a tree near The Woodlands in Spring, Texas, killing two people.","Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",Autonomous Driving,2,Transportation,No,"Image Recognition, Object Detection, Decision Making",Partial Autonomy,Automotive,No,Non-Text Media,Low,Manufacturing & Industrial
346,2016-06-15,"['2059', '2062', '2108', '2109', '2110']",['henn-na-hotel'],['unknown'],"['henn-na-hotel-guests', 'henn-na-hotal-staff']",A number of robots employed by a hotel in Japan were reported by guests in a series of complaints for failing to handle tasks such as answering scheduling questions or making passport copies without human intervention.,Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks,"Answering scheduling questions, Making passport copies",3,Hospitality,No,"Customer service, Document handling",Semi-Autonomous,Hospitality,No,Other/Unclear,Low,Technology & IT Services
283,2018-07-02,['1880'],['facebook'],['facebook'],['the-vindicator'],Facebook’s content moderation algorithm was acknowledged by the company to have flagged excerpts of the Declaration of Independence posted by a small newspaper in Texas as hate speech by mistake.,Facebook’s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake,Content Moderation,3,Social Media/Communication,No,"Text Analysis, Hate Speech Detection",Semi-Autonomous,Social Media/Communication,No,Data Analysis,Low,Information & Communication
286,2021-02-26,"['1889', '2052', '2381']",['tiktok'],['tiktok'],"['lalani-erika-renee-walton', 'arriani-jaileen-arroyo', ""lalani-erika-renee-walton's-family"", ""arriani-jaileen-arroyo's-family"", 'tiktok-young-users', 'tiktok-users']","TikTok’s recommendation algorithm was alleged in a lawsuit to have intentionally and repeatedly pushed videos of the “blackout” challenge onto children’s feeds, incentivizing their participation which ultimately resulted in the death of two young girls.","TikTok’s ""For You"" Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",Content recommendation,3,Social media,No,"Machine learning, Predictive analytics",Semi-autonomous,Information and communication,No,Data Analysis,High,Information & Communication
307,2017-11-01,['1947'],['apple'],['apple'],"['iphone-face-id-users', 'iphone-x-face-id-users']",The Face ID feature on iPhone allowing users to unlock their phones via facial recognition was reported by users for not recognizing their faces in the morning.,iPhone Face ID Failed to Recognize Users’ Morning Faces,Facial Recognition,3,Consumer Electronics,No,"Image Processing, Machine Learning",Semi-Autonomous,Consumer Electronics,No,Non-Text Media,Low,Other/Unclear
309,2017-08-26,"['1954', '1956', '1960', '2030']",['metropolitan-police-service'],['unknown'],['notting-hill-carnival-goers'],The facial recognition trial by London’s Metropolitan Police Service at the Notting Hill Carnival reportedly performed poorly with a high rate of false positives.,Facial Recognition Trial Performed Poorly at Notting Hill Carnival,Facial Recognition,3,Law Enforcement,Yes,"Image Processing, Pattern Recognition, Data Analysis",Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
327,2015-03-24,['2011'],['facebook'],['facebook'],"['facebook-users-having-posts-about-painful-events', 'facebook-users']",Facebook’s “On This Day” algorithm which highlighted past posts on a user’s private page or News Feed confronted unwanted and painful personal memories to its users.,Facebook’s On-This-Day Feature Mistakenly Showed Painful Memories to Users,Content Generation and Recommendation,3,Information and Communication,No,Content Recommendation,Semi-Autonomous,Information and Communication,No,Other/Unclear,Low,Information & Communication
344,2021-07-01,['2057'],"['myinterview', 'curious-thing']","['myinterview', 'curious-thing']","['job-candidates-using-myinterview', 'job-candidates-using-curious-thing', 'employers-using-myinterview', 'employers-using-curious-thing']","Two AI interview softwares provided positive but invalid results such as ""competent"" English proficiency and high match percentage for interview responses given in German by reporters.",Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German,Language Proficiency Assessment & Candidate Matching,3,Human Resources/Recruitment,No,Language Proficiency Assessment & Candidate Matching,Semi-autonomous,Human Resources/Recruitment,No,Language Processing,Low,Technology & IT Services
348,2020-11-01,"['2064', '2075', '2096']",['youtube'],['youtube'],['youtube-users-skeptical-of-us-election-results'],YouTube's recommendation algorithm allegedly pushed 2020's US Presidential Election fraud content to users most skeptical of the election's legitimacy disproportionately compared to least skeptical users.,YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately,Content Recommendation,3,Information and Communication,No,"Data Analysis, Pattern Recognition",Semi-Autonomous,Information and Communication,No,Data Analysis,Low,Information & Communication
349,2022-03-22,"['2065', '2095']",['charlotte-mecklenburg-school-district'],['evolv-technology'],"['students-at-charlotte-mecklenburg-schools', 'teachers-at-charlotte-mecklenburg-schools', 'security-officers-at-charlotte-mecklenburg-schools']","Evolv's AI-based weapons detection system reportedly produced excessive false positives, mistaking everyday school items for weapons and pulling schools' security personnel for manual checking.",Evolv's Gun Detection False Positives Created Problems for Schools,weapon detection,1,"Education, Arts, entertainment and recreation",yes,Weapons Detection,Semi-Autonomous (requires manual checking),Education,Yes,Other/Unclear,Low,Education
277,2022-01-14,['1865'],['15.ai'],['15.ai'],"['15.ai', '15.ai-users']","An AI-synthetic audio sold as an NFT on Voiceverse’s platform was acknowledged by the company for having been created by 15.ai, a free web app specializing in text-to-speech and AI-voice generation, and reused without proper attribution.",Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution,Synthetic audio generation,3,Entertainment and Media,No,"Text-to-speech conversion, AI-voice generation",Semi-autonomous,Entertainment and Media,No,Language Processing,Low,"Arts, Entertainment & Recreation"
311,2020-05-02,"['1961', '1962']",['youtube'],['youtube'],"['women-of-sex-tech-conference-attendants', 'women-of-sex-tech-conference-organizers']","YouTube’s automated content moderation tool erroneously removed The Women of Sex Tech conference’s live-streamed event and banned the conference from the platform, despite not violating the platform’s sexual content policies.",YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference,Content Moderation,3,Social Media,No,"Text and Image Recognition, Policy Enforcement",Semi-Autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
317,2020-03-17,['1976'],['facebook'],['facebook'],"['facebook-users-posting-legitimate-covid-19-news', 'facebook-users']","Facebook was reported by users for blocking posts of legitimate news about the coronavirus pandemic, allegedly due to a bug in an anti-spam system.",Bug in Facebook’s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19,Content Moderation,3,Social Media/Online Platforms,No,"Text Analysis, Pattern Recognition",Semi-Autonomous,Social Media/Online Platforms,No,Data Analysis,Low,Information & Communication
324,2019-11-12,"['1998', '1999', '2000', '2001', '2002', '2003']",['the-bl'],['unknown'],"['instagram-users', 'facebook-users']","A large network of pages, groups, and fake accounts having GAN-generated face photos associated with The BL, a US-based media outlet, reportedly bypassed Facebook moderation systems to push ""pro-Trump"" narratives on its platform and Instagram.",GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms,Fake Account Detection,3,Social Media/Information Technology,No,"Image Recognition, Social Media Monitoring",Semi-Autonomous,Social Media/Information Technology,No,Non-Text Media,Low,Information & Communication
303,2022-08-21,"['1940', '1944']",['google'],['google'],"['a-software-engineer-named-mark', 'parents-using-telemedicine-services']","Google’s automated detection of abusive images of children incorrectly flagged a parent’s photo intended for a healthcare provider, resulting in a false police report of child abuse, and loss of access to his online accounts and information.",Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child,Content Moderation,3,Healthcare,No,"Image Recognition, Automated Reporting",Semi-Autonomous,Internet Services,No,Non-Text Media,Low,Other/Unclear
339,2022-09-15,"['2051', '2063', '2491', '2511', '2516', '2539', '2540', '2575', '2576', '2593', '2601', '2634', '2643', '2755']",['students'],"['sudowrite', 'openai']","['teachers', 'non-cheating-students', 'cheating-students']","Students were reportedly using open-source text generative models such as GPT-3 and ChatGPT to complete school assignments and exams such as writing reports, essays.",Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams,text generation,3,"Education, information and communication",no,"Text Generation, Natural Language Processing",Semi-autonomous,Education,Yes,Language Processing,Low,Education
343,2021-07-11,"['2056', '2113']","['facebook', 'instagram', 'twitter']","['facebook', 'instagram', 'twitter']","['marcus-rashford', 'jadon-sancho', 'bukayo-saka', 'facebook-users', 'instagram-users', 'twitter-users']","Facebook's, Instagram's, and Twitter's automated content moderation failed to proactively remove racist remarks and posts directing at Black football players after finals loss, allegedly largely relying on user reports of harassment.","Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",Content Moderation,3,Social Media,No,"Text Analysis, Hate Speech Detection",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
302,2021-03-15,['1939'],['geisel-school-of-medicine'],"[""geisel-school-of-medicine's-technology-staff"", 'canvas']","['sirey-zhang', ""geisel-school-of-medicine's-students"", ""geisel-school-of-medicine's-professors"", ""geisel-school-of-medicine's-accused-students""]",Dartmouth's Geisel School of Medicine allegedly falsely accused students of cheating during remote exams using an internally built system which tracked student activity patterns without their knowledge on its learning management platform.,Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software,Student Activity Monitoring,3,Education,Yes,"Data Tracking, Pattern Recognition",Semi-Autonomous,Education,Yes,Data Analysis,Low,Education
308,2017-07-03,"['1952', '1953']",['boston-dynamics'],['boston-dynamics'],['none'],"Boston Dynamics’s autonomous robot Atlas allegedly caught its foot on a stage light, resulting in a fall off the stage at the Congress of Future Science and Technology Leaders conference.",Atlas Robot Fell off Stage at Conference,Stage Performance,4,Entertainment and Events,No,Motion control and coordination,High Autonomy,Entertainment and Events,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
310,2017-06-03,"['1955', '1957', '1958', '1959', '2126', '2127', '2128', '2269']",['south-wales-police'],['nec'],"['finals-attendees', 'falsely-accused-finals-attendees']",South Wales Police (SWP)’s automated facial recognition (AFR) at the Champion's League Final football game in Cardiff wrongly identified innocent people as potential matches at an extremely high false positive rate of more than 90%.,High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final,Facial recognition,3,Law Enforcement,Yes (since this involves the police force),Image/Video Analysis,Semi-autonomous (since it required human intervention for verification),Public Safety,Yes (since this involves the police force),Data Analysis,Low,Law Enforcement & Public Safety
315,2016-04-09,['1970'],['ntechlab'],['ntechlab'],"['russian-pornographic-actresses', 'russian-sex-workers']",The facial recognition software FindFace allowing its users to match photos to people’s social media pages on Vkontakte was reportedly abused to de-anonymize and harass Russian women who appeared in pornography and alleged sex workers.,Facial Recognition Service Abused to Target Russian Porn Actresses,Facial Recognition,3,Social Media / Internet,No,"Image Processing, Data Analysis",Semi-Autonomous,Social Media / Internet,No,Data Analysis,Low,Information & Communication
321,2018-03-23,"['188', '190', '194', '195', '199', '209', '212', '1988', '1989', '1990', '1995', '200', '3856', '3858']",['tesla'],['tesla'],"[""walter-huang's-family"", 'walter-huang']","A Tesla Model X P100D operating on Autopilot's Traffic-Aware Cruise Control (TACC) and Autosteer system allegedly accelerated above the speed limit of a highway in Mountain View, California, and steered itself directly into a barrier, resulting in its driver’s death.","Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",Autonomous Driving,5,Private Transportation,No,"Traffic-Aware Cruise Control, Autosteer",Level 5 (Full Automation),Private Transportation,No,Action & Control,High,Transportation
329,2017-09-18,['2015'],['amazon'],['amazon'],['amazon-users'],Amazon was reported to have shown chemical combinations for producing explosives and incendiary devices as “frequently bought together” items via automated recommendation.,Amazon Recommended Explosive-Producing Ingredients as “Frequently Bought Together” Items for Chemicals,Content Recommendation,1,wholesale and retail trade,no,"Data Analysis, Pattern Recognition, Machine Learning",Semi-Autonomous,E-commerce,No,Data Analysis,Low,Retail & E-commerce
284,2018-05-01,"['1882', '1883', '1884', '1885', '1886', '1887']",['facebook'],['facebook'],"['museums-on-facebook', 'facebook-users-interested-in-arts', 'facebook-users']","Facebook’s removal of posts featuring renowned artworks by many historical artists and their promotional content due to nudity via both automated and human-moderated means were condemned by critics, such as museums and tourism boards, as cultural censorship and prevention of artwork promotion.",Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship,Content Moderation,3,Social Media / Culture and Arts,No,"Content Filtering, Image Recognition",Semi-Autonomous,Social Media / Culture and Arts,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
298,2021-10-21,['2471'],['yuen-ler-chow'],['yuen-ler-chow'],['thefacetag-app-users'],"TheFaceTag app, a social networking app developed and deployed within-campus by a student at Harvard raised concerns surrounding its facial recognition, cybersecurity, privacy, and misuse. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Student-Developed Facial Recognition App Raised Ethical Concerns,Facial Recognition,3,Education,No,"Cybersecurity, Privacy Protection",Semi-Autonomous,Education,No,Other/Unclear,Low,Education
279,2019-07-01,"['1869', '1870', '2381']",['tiktok'],['tiktok'],"['tiktok-young-users', 'tiktok-users']",TikTok’s young users were allegedly exposed to community-guideline-violating pro-eating disorder content on their algorithmically curated “For You” page that serves videos from any user on its platform.,TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content,Content Moderation,3,Social Media / Entertainment,No,"Content Recommendation, Content Filtering",Semi-autonomous,Social Media / Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
281,2019-02-04,"['1875', '1876', '1877']",['youtube'],['youtube'],"['youtube-young-users', 'youtube-users']","Terms-of-service-violating videos related to suicide and self-harm reportedly bypassed YouTube’s content moderation algorithms, allegedly resulting in exposure of graphic content to young users via recommended videos.",YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm,"video recommender, search suggestion",1,"information and communication, Arts, entertainment and recreation",no,Content Moderation Algorithms,Semi-Autonomous,Media and Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
312,2021-08-15,"['1963', '1964', '1965', '1966']",['sanas'],['sanas'],"['call-center-agents-having-non-midwestern-american-accent', 'people-having-non-midwestern-american-accent']","A startup’s use of AI voice technology to alter or remove accents for call center agents was scrutinized by critics as reaffirming bias, despite the company’s claim.",Startup's Accent Translation AI Denounced as Reinforcing Racial Bias,Accent Alteration/Removal,3,Customer Service/Call Centers,No,"Speech Recognition, Natural Language Processing",Semi-Autonomous,Customer Service/Call Centers,No,Language Processing,Medium,Consumer Services
316,2016-06-02,['1971'],['facebook'],['facebook'],['facebook-users'],"Facebook’s advertisement-approval algorithm was reported by a security analyst to have neglected simple checks for domain URLs, leaving its users at risk of fraudulent ads.",Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks,Ad Approval,3,Social Media,No,Algorithmic Security Analysis,Semi-autonomous,Social Media,No,Data Analysis,Low,Information & Communication
288,2019-01-30,"['1895', '1896', '2025', '2026']",['woodbridge-police-department'],['unknown'],['nijeer-parks'],"Woodbridge Police Department falsely arrested an innocent Black man following a misidentification by their facial recognition software, who was jailed for more than a week and paid thousands of dollar for his defense.",New Jersey Police Wrongful Arrested Innocent Black Man via FRT,Facial Recognition,3,Public Safety / Law Enforcement,Yes,"Image Analysis, Pattern Recognition",Semi-Autonomous,Public Safety / Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
289,2020-06-15,"['1897', '1898']",['starship-technologies'],['starship-technologies'],"['jisuk-mok', 'frisco-residents']","A Starship food delivery robot crashed into the front bumper of a vehicle waiting at a stoplight intersection in Frisco, Texas, the video of which the company reportedly refused to release.","Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",Navigation and delivery,3,Food Delivery/Transportation,No,"Obstacle detection, Route planning",Semi-autonomous,Food Delivery/Transportation,No,Other/Unclear,Low,Transportation
306,2016-05-26,"['1946', '1948', '1949']",['tesla'],['tesla'],"['unnamed-tesla-owner', 'tesla-drivers']","A Tesla Model S operating on the Traffic-Aware Cruise Control (TACC) feature of Autopilot was shown on video by its driver crashing into a parked van on a European highway in heavy traffic, which damaged the front of the car.",Tesla on Autopilot TACC Crashed into Van on European Highway,Autonomous Driving,3,Personal Use,No,Traffic-Aware Cruise Control,Level 2 (Partial Automation),Private Sector,No,Action & Control,Low,Other/Unclear
345,2021-04-13,['2058'],['insurance-companies'],"['ccc-information-services', 'tractable']","['vehicle-repair-shops', 'vehicle-owners']","Auto-insurance companies' photo-based estimation of repair price was alleged by repair shop owners and industry groups as providing inaccurate estimates, causing damaged cars to stay in the shop longer.",Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently,Damage Estimation,3,Auto-Insurance,No,"Image Analysis, Damage Assessment",Semi-Autonomous,Auto-Insurance,No,Data Analysis,Low,Finance & Insurance
301,2022-02-15,['1938'],['broward-college'],['honorlock'],['unnamed-florida-teenager'],Broward College’s use of remote proctoring system and reliance on its flagging algorithm allegedly led to a wrongful accusation of academic dishonesty in a biology exam of a Florida teenager.,Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring,Remote Proctoring,3,Education,Yes,Flagging algorithm,Semi-autonomous,Education,Yes,Other/Unclear,Low,Education
314,2022-08-17,['1968'],['stability-ai'],"['stability-ai', 'runway', 'laion', 'eleutherai', 'compvis-lmu']","['stability-ai', 'deepfaked-celebrities']","Stable Diffusion, an open-source image generation model by Stability AI, was reportedly leaked on 4chan prior to its release date, and was used by its users to generate pornographic deepfakes of celebrities.",Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn,Image Generation,3,Entertainment/Media,No,"Deep Learning, Image Processing",Semi-Autonomous,Entertainment/Media,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
322,2019-12-07,"['1991', '1994']",['tesla'],['tesla'],['connecticut-state-police'],"A Tesla Model 3 on Autopilot slammed into a parked car of patrol police officers who stopped to assist a stranded motorist on the interstate in Norwalk, Connecticut.",Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway,Vehicle Operation,2,Transportation,No,Autopilot Navigation,Level 2 (Partial Automation),Transportation,No,Action & Control,Low,Transportation
336,2015-03-01,"['2048', '2119', '2120', '2121']",['uk-home-office'],['uk-home-office'],['uk-immigrant-newlyweds'],"UK Home Office's opaque algorithm to detect sham marriages flagged some nationalities for investigation more than others, raising fears surrounding discrimination based on nationality and age.",UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately,Discrimination Detection,3,Government/Public Sector,Yes,"Pattern Recognition, Algorithmic Bias Detection",Semi-autonomous,Government/Public Sector,Yes,Other/Unclear,Medium,Public Administration & Defense
351,2022-09-13,['2068'],['@tengazillioiniq'],['unknown'],"['halle-bailey', 'black-actresses']","A Twitter user reportedly modified using generative AI a short clip of Disney's 2022 version of ""The Little Mermaid,"" replacing a Black actress with a white digital character.","""The Little Mermaid"" Clip Doctored Using Generative AI to Replace Black Actress with White Character",Deepfake Generation,3,Entertainment,No,"Image Recognition, Generative AI",Semi-Autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
364,2020-04-15,['2131'],['walmart'],['everseen'],['walmart-employees'],Walmart's theft-deterring bagging-detection system allegedly exposed workers to health risks during the coronavirus pandemic when its false positives prompted workers to unnecessarily step in to resolve the issue.,Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk,Theft Detection,3,Retail,No,Anomaly Detection,Semi-Autonomous,Retail,No,Other/Unclear,Low,Retail & E-commerce
367,2020-06-17,['2150'],"['openai', 'google']","['openai', 'google']","['gender-minority-groups', 'racial-minority-groups', 'underrepresented-groups-in-training-data']","Unsupervised image generation models trained using Internet images such as iGPT and SimCLR were shown to have embedded racial, gender, and intersectional biases, resulting in stereotypical depictions.","iGPT, SimCLR Learned Biased Associations from Internet Training Data",Image Generation,1,information and communication,no,"Image Processing, Bias Detection",Fully Autonomous,"Technology, Social Media",No,Non-Text Media,Medium,Information & Communication
355,2018-07-07,"['2081', '2082', '2083', '2903', '2972']",['uber'],['uber'],['uber-drivers'],"Uber was alleged in a lawsuit to have wrongfully accused its drivers in the UK and Portugal of fraudulent activity through automated systems, which resulted in their dismissal without a right to appeal.",Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems,worker management,1,transportation and storage,no,"Perception, Cognition",Medium,Transportation and storage,False,Perception & Cognition,Low,Transportation
356,2020-09-15,"['2084', '2085']",['murat-ayfer'],"['murat-ayfer', 'openai']",['historically-disadvantaged-groups'],Philosopher AI as built on top of GPT-3 was reported by its users for having strong tendencies to produce offensive results when given prompts on certain topics such as feminism and Ethiopia.,Philosophy AI Tentatively Produced Offensive Results for Certain Prompts,Content Moderation,3,Information Technology,No,Text Generation,Semi-Autonomous,Information Technology,No,Language Processing,Low,Technology & IT Services
368,2016-06-01,"['2151', '2152', '2153', '2154', '2155', '2156', '2157', '2159', '2160', '2161']",['the-israel-military'],['anyvision'],['palestinians-residing-in-the-west-bank'],"A controversial surveillance program involving facial recognition and algorithmic recommendation, Blue Wolf, was deployed by the Israeli military to monitor Palestinians in the West Bank.","Facial Recognition Smart Phone App ""Blue Wolf"" Monitored Palestinians in West Bank",Surveillance and Facial Recognition,3,Military,Yes,"Facial Recognition, Algorithmic Recommendation",Semi-autonomous,Military,Yes,Other/Unclear,Low,Public Administration & Defense
370,2017-09-27,['2163'],['google'],['google'],"[""google's-competitor-shopping-services""]","Google was fined by EU Commission for changing its shopping algorithms in Europe to favor its own comparison service over competitors, resulting in anti-competitive effects.",Google Fined for Changing Shopping Algorithms in EU to Favor Own Service,Algorithm Modification,3,Digital Services/IT,No,Data Processing,Semi-Autonomous,Digital Services/IT,No,Data Analysis,Low,Technology & IT Services
378,2022-04-06,"['2175', '2176']",['tusimple'],['tusimple'],"['tusimple', 'state-of-arizona']",A TuSimple autonomous truck operating with backup drivers behind the wheel operated on an outdated command sequence and suddenly veered into the center divide on the interstate freeway.,TuSimple Truck Steered into Interstate Freeway Divide,Autonomous driving,3,Road Transportation,No,"Autonomous Navigation, Fault Detection",Semi-Autonomous,Road Transportation,No,Action & Control,Low,Transportation
391,2022-07-26,"['2244', '2246']",['southern-co-op'],['hikvision'],['souther-co-op-customers'],"Southern Co-op's use of facial recognition reportedly to curb violent crime in UK supermarkets was alleged by civil society and privacy groups as ""unlawful"" and ""complete"" invasion of privacy.",Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful,Facial Recognition,3,Retail / Supermarket,No,"Image Processing, Identification & Verification",Semi-Autonomous,Retail / Supermarket,No,Non-Text Media,Low,Retail & E-commerce
371,2019-11-29,"['2167', '2184', '2203']",['ugandan-government'],['huawei'],['political-opposition-in-uganda'],"Huawei's AI systems involving facial recognition were reportedly deployed by the Ugandan government to monitor political opposition actors and anti-regime sentiments, which raised fears of surveillance and suppression of individual freedoms.",Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests,Facial Recognition,3,Government Surveillance,Yes,"Image Processing, Object Detection, Pattern Recognition",Semi-Autonomous,Government Security,Yes,Non-Text Media,Low,Public Administration & Defense
393,2021-12-08,['2247'],['facebook'],['facebook'],"['facebook-users-speaking-swahili', 'facebook-users-speaking-english', 'facebook-users']",Facebook's ad moderation system involving algorithms failed to flag hateful language and violating content such as calls for killings for ads in English and Swahili.,Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content,content moderation,1,"Arts, entertainment and recreation",no,"Content Moderation, Natural Language Processing",Semi-Autonomous (since human moderators usually review flagged content),Information and Communication,No,Language Processing,Low,Information & Communication
358,2018-06-01,['2089'],['cadillac-fairview'],['unknown'],"['chinook-centre-mall-goers', 'market-mall-goers']","Facial recognition (FRT) was reportedly deployed in some Calgary-area malls to approximate customer age and gender without explicit consent, which a privacy expert warned was a cause for concern.",Calgary Malls Deployed Facial Recognition without Customer Consent,Facial Recognition,3,Retail,No,Age and Gender Estimation,Semi-Autonomous,Retail,No,Other/Unclear,Low,Retail & E-commerce
363,2021-01-15,['2130'],['facebook'],['facebook'],"['facebook-users-posting-about-plymouth-hoe', 'facebook-users-in-plymouth-hoe', 'plymouth-hoe-residents']",Facebook's automated system mistakenly labelled posts featuring the seafaring landmark Plymouth Hoe as misogynistic.,Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive,Content Moderation,3,Social Media,No,Text Analysis and Classification,Semi-autonomous,Social Media,No,Data Analysis,Low,Information & Communication
369,2022-08-29,['2162'],['jason-allen'],['midjourney'],"['artists-submitting-in-the-digital-arts-category', 'digital-artists', 'artists']","An artwork generated using generative AI won first place in the digital arts category of the Colorado State Fair's art competition, which raised concerns surrounding labor displacement and unfair competition.",GAN Artwork Won First Place at State Fair Competition,Artwork Generation,4,Art and Entertainment,No,"Generative Algorithms, Image Creation",High,Art and Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
400,2022-02-23,['2273'],['google'],['google'],"['women-in-need-of-abortion-services', 'women-having-unexpected-or-crisis-pregnancies']","Google Search reportedly returned fewer abortion clinics for searches from poorer and rural areas, particularly ones with Targeted Regulation of Abortion Providers (TRAP) laws.",Google Search Returned Fewer Results for Abortion Services in Rural Areas,Search Algorithm Bias Detection,3,Information and Communication Technology,No,Search Algorithms,Semi-Autonomous,Information and Communication Technology,No,Other/Unclear,Low,Information & Communication
373,2013-10-01,"['2169', '2187', '2188', '2189', '2190', '2191', '2213', '2214', '2215', '2216', '2238', '2798']",['michigan-unemployment-insurance-agency'],"['fast-enterprises', 'csg-government-solutions']","['unemployed-michigan-residents-falsely-accused-of-fraud', 'unemployed-michigan-residents']","State's use of Michigan Integrated Data Automated System (MiDAS) to adjudicate unemployment benefits claims falsely issued fraud determinations based on un-investigated assumptions, resulting in tens of thousands of false fraud cases over years.",Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People,Fraud Detection,3,Public Administration,Yes,"Data Analysis, Pattern Recognition",Semi-Autonomous,Public Administration,Yes,Data Analysis,Low,Public Administration & Defense
376,2016-09-01,"['2172', '2185', '2186', '2261', '2281']",['realpage'],"['realpage', 'jeffrey-roper']",['apartment-renters'],"RealPage’s YieldStar apartment pricing algorithm was reportedly helping landlords push unusually high rents onto tenants, raising fears and criticisms surrounding alleged antitrust behaviors such as artificially inflating price, and stifling competition.","RealPage's Algorithm Pushed Rent Prices High, Allegedly Artificially",Pricing Prediction/ Optimization,3,Real Estate,No,"Algorithmic Pricing, Machine Learning",Semi-autonomous,Real Estate,No,Other/Unclear,Low,Other/Unclear
395,2021-03-02,"['2254', '2255', '2256', '2257']",['amazon'],['netradyne'],['amazon-delivery-drivers'],"Amazon delivery drivers were forced to consent to algorithmic collection and processing of their location, movement, and biometric data through AI-powered cameras, or be dismissed.",Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers,"Collection and processing of location, movement, and biometric data",3,Delivery/Logistics,No,"Data collection, processing, and analysis",Semi-autonomous,Delivery/Logistics,No,Data Analysis,Low,Transportation
361,2018-05-11,['2111'],['amazon'],['amazon'],"[""danielle's-family"", 'amazon-echo-users']",Amazon Echo misinterpreted a background conversation between a husband and wife as instructions for recording a message and sending it to one of the husband's employees.,Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact,Voice Recognition,3,Consumer,No,Voice Recognition,Semi-Autonomous,Consumer,No,Other/Unclear,Low,Other/Unclear
377,2022-10-11,['2174'],['weibo'],['weibo'],"['weibo', 'chinese-government']",Weibo's user moderation model is having difficulty keeping up with shifting user slang in defiance of Chinese state censors.,Weibo Model Had Difficulty Detecting Shifts in Censored Speech,Content Moderation,3,Social Media / Communication,No,"Natural Language Processing, Text Analysis",Semi-Autonomous,Social Media / Communication,No,Data Analysis,Low,Information & Communication
354,2020-06-20,"['2078', '2079', '2080', '2904', '2903']",['uber'],['uber'],['uber-drivers'],"Uber was alleged in a lawsuit to have provided incomplete notice about automated decision-making and profiling for drivers such as information about their driving behavior, and use of phone.",Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers,Profiling and Decision-Making,1,transportation and storage,no,"Data Analysis, Automated Decision Making",Semi-Autonomous (as the system provides information but doesn't take direct action),"Transportation, Technology",No (Uber is a private company),Data Analysis,Low,Transportation
381,2020-10-29,['2217'],['sit-acronis-autonomous'],['sit-acronis-autonomous'],['sit-acronis-autonomous'],An autonomous Roborace car drove itself into a wall in round one of the Season Beta 1.1 race.,Autonomous Roborace Car Drove Directly into a Wall,Autonomous Driving,5,Automobile Racing,No,"Navigation, Obstacle Detection, Decision Making",Full Autonomy,Automobile Racing,No,Action & Control,Low,Other/Unclear
353,2019-03-01,"['2073', '2074', '2195', '2196']",['tesla'],['tesla'],"['jeremy-banner', ""jeremy-banner's-family""]","A Tesla Model 3 driver switched on Autopilot seconds before the crash into the underbelly of a tractor-trailer on a highway in Florida, killing the Tesla driver.","Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",Autonomous Driving,4,Transportation,No,"Autonomous Navigation, Object Detection, Collision Avoidance",High Automation (Level 4),Transportation,No,Action & Control,Low,Transportation
374,2020-08-13,"['2170', '2206', '2207', '2208', '2209', '2210', '2211', '2212']",['uk-office-of-qualifications-and-examinations-regulation'],['uk-office-of-qualifications-and-examinations-regulation'],"['a-level-pupils', 'gcse-pupils', 'pupils-in-state-schools', 'underprivileged-pupils']","UK Office of Qualifications and Examinations Regulation (Ofqual)'s grade-standardization algorithm providing predicted grades for A level and GCSE qualifications in the UK, Wales, Northern Ireland, and Scotland was reportedly giving grades lower than teachers' assessments, and disproportionately for state schools.",UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments,Grade Prediction,4,Education,Yes,"Predictive Analytics, Machine Learning",High,Education,Yes,Data Analysis,Low,Education
380,2014-03-04,"['2181', '2182', '2258', '2259', '2260']",['facebook'],['facebook'],['jewish-people'],"Facebook's automated advertising categories generated using users' declared interests contained anti-Semitic categories such as ""Jew hater""  and ""How to burn Jews"" which were listed as fields of study.",Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options,Content Moderation,3,Information and Communication,No,"Data Analysis, User Profiling",Semi-Autonomous,Information and Communication,No,Data Analysis,Low,Information & Communication
357,2019-02-14,"['2086', '2087', '2088']",['openai'],['openai'],"['openai', ""people-having-personal-data-in-gpt-2's-training-data""]","OpenAI's GPT-2 reportedly memorized and could regurgitate verbatim instances of training data, including personally identifiable information such as names, emails, twitter handles, and phone numbers.",GPT-2 Able to Recite PII in Training Data,Data Memorization,3,Technology,No,Text Generation,Semi-autonomous,Technology,No,Language Processing,Low,Technology & IT Services
385,2022-10-04,"['2224', '2225', '2231', '2232', '2233', '2234']",['edmonton-police-service'],['parabon-nanolabs'],['black-residents-in-edmonton'],"The Edmonton Police Service (EPS) in Canada released a facial image of a Black male suspect generated by an algorithm using DNA phenotyping, which was denounced by the local community as racial profiling.",Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling,Facial Recognition,3,Public Safety/Law Enforcement,Yes,"Image Processing, DNA Phenotyping, Data Analysis",Semi-Autonomous,Public Safety/Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
388,2018-12-01,['2235'],"['the-government-in-bahia', ""bahia's-secretary-of-public-security""]",['huawei'],"['black-people-in-brazil', 'black-people-in-bahia']",Facial recognition deployed in a pilot project by the local government of Bahia despite having minimal hit rate reportedly targeted Black and poor people disproportionately.,Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People,Facial Recognition,3,Public Safety / Law Enforcement,Local Government,"Image Analysis, Pattern Recognition",Semi-autonomous,Public Safety / Law Enforcement,Local Government,Data Analysis,Low,Law Enforcement & Public Safety
383,2022-10-04,"['2220', '2223']",['google-home'],['google-home'],"['black-google-home-mini-users', 'google-home-mini-users']",Google Home Mini speaker was reported by users for announcing aloud the previously-censored n-word in a song title.,Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud,Voice Recognition,3,Consumer Electronics,No,"Speech-to-Text, Music Streaming",Semi-Autonomous,Consumer Electronics,No,Language Processing,Low,Other/Unclear
390,2022-06-28,['2243'],['unknown'],['unknown'],"['interviewers-of-remote-work-positions', 'employers-of-remote-work-positions']",Voice and video deepfakes were reported by FBI Internet Crime Complaint Center (IC3) in complaint reports to have been deployed during online interviews of the candidates for remote-work positions.,Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions,Deepfake Generation,3,Employment/Recruitment,No,Fake Media Detection,Semi-autonomous,Cybersecurity,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
387,2014-12-22,['2229'],['oracle'],['oracle'],['internet-users'],Oracle's automated system involving algorithmic data processing was alleged in a lawsuit to have been unlawfully collecting personal data from millions of people and violating their privacy rights.,Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights,Data Collection and Processing,1,information and communication,no,"Algorithmic Data Processing, Data Mining",Semi-Autonomous (requires humans for decision-making process),Technology / IT Services,No,Data Analysis,Low,Technology & IT Services
394,2017-03-15,"['2248', '2251']","['youtube', 'twitch', 'tiktok', 'instagram']","['youtube', 'twitch', 'tiktok', 'instagram']","['youtube-content-creators', 'twitch-content-creators', 'tiktok-content-creators', 'instagram-content-creators']","TikTok's, YouTube's, Instagram's, and Twitch's use of algorithms to flag certain words devoid of context changed content creators' use of everyday language or discussion about certain topics in fear of their content getting flagged or auto-demonetized by mistake.",Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use,Content Moderation,3,Social Media & Entertainment,No,"Natural Language Processing, Text Analysis, Flagging Inappropriate Content",Semi-Autonomous,Social Media & Entertainment,No,Data Analysis,Low,"Arts, Entertainment & Recreation"
362,2021-07-20,['2129'],['facebook'],['facebook'],"['wny-gardeners', 'gardening-facebook-groups', 'facebook-users-in-gardening-groups']","Facebook's automated system flagged gardening groups' use of ""hoe"" and violent language against bugs as a violation by mistake.",Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake,Content Moderation,3,Social Media,No,"Natural Language Processing, Text Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
384,2022-10-03,"['2221', '2222']",['glovo'],['glovo'],"['sebastian-galassi', ""sebastian-galassi's-family""]","Delivery company Glovo's automated system sent an email terminating an employee for ""non-compliance terms and conditions"" after the employee was killed in a car accident while making a delivery on Glovo's behalf.",Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident,Employee management & Communication,4,Delivery/Logistics,No,Employee management & Communication,High,Delivery/Logistics,No,Other/Unclear,High,Transportation
359,2021-05-23,['2097'],"['facebook', 'instagram', 'twitter']","['facebook', 'instagram', 'twitter']","['palestinian-social-media-users', 'facebook-users', 'instagram-users', 'twitter-users', 'facebook-employees-having-families-affected-by-the-conflict']","Facebook, Instagram, and Twitter wrongly blocked or restricted millions of pro-Palestinian posts and accounts related to the Israeli-Palestinian conflict, citing errors in their automated content moderation system.","Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict",Content Moderation,3,Social Media,No,"Text Analysis, Image Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
396,2018-07-04,['2263'],['uber'],['uber'],['transgender-uber-drivers'],Transgender Uber drivers reported being automatically deactivated from the app due to Real-Time ID Check failing to account for difference in appearance of people undergoing gender transitions.,Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions,Real-Time Identification Verification,3,Transportation & Logistics,No,"Facial recognition, Identity verification",Semi-Autonomous,Transportation & Logistics,No,Other/Unclear,Low,Transportation
352,2022-09-15,"['2070', '2076', '2093', '2426']",['stephan-de-vries'],"['openai', 'stephan-de-vries']",['stephan-de-vries'],Remoteli.io's GPT-3-based Twitter bot was shown being hijacked by Twitter users who redirected it to repeat or generate any phrases.,GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks,Social Media Management,3,Information and Communication Technology,No,Content Generation,Semi-Autonomous,Information and Communication Technology,No,Other/Unclear,Low,Information & Communication
372,2022-07-22,"['2168', '2177', '2178']",['google'],['google'],['google-pixel-6a-users'],"Google Pixel 6a's fingerprint recognition feature was reported by users for security issues, in which phones were mistakenly unlocked by unregistered fingerprints.",Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking,Biometric Authentication,3,Consumer Electronics,No,"Biometric Recognition, Security Analysis",Semi-Autonomous,Consumer Electronics,No,Data Analysis,Low,Other/Unclear
375,2019-09-29,"['2171', '2192', '2193']",['krungthai-bank'],['krungthai-bank'],"['thai-citizens', 'elder-thai-citizens']","A Thai wallet app failed to recognize people’s faces, resulting in citizens and disproportionately elders unable to sign up for Thai government’s cash handout and co-pay programs or having to wait in long queues at local ATMs for authentication.",Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs,Facial Recognition,3,Finance / Public Services,Yes,"Facial Recognition, User Authentication",Semi-Autonomous,Finance / Public Services,Yes,Other/Unclear,Low,Finance & Insurance
379,1992-05-25,"['2179', '2180']",['pepsi'],['d.g.-consultores'],['filipinos'],"Pepsi's number generation system determining daily winners in its Number Fever promotion in the Philippines mistakenly produced a number held by thousands which resulted in riots, deaths, conspiracy theories, and decades of lawsuits.",Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines,Number Generation,3,Consumer Goods,No,Random Number Generation,Semi-Autonomous,Consumer Goods,No,Other/Unclear,High,Retail & E-commerce
382,2017-11-21,['2219'],['instagram'],['instagram'],"['molly-rose-russell', 'the-russell-family', 'teenage-girls', 'teenagers']","Instagram was ruled by a judge to have contributed to the death of a teenage girl in the UK allegedly through its exposure and recommendation of suicide, self-harm, and depressive content.",Instagram's Exposure of Harmful Content Contributed to Teenage Girl’s Suicide,Content Recommendation,3,Social Media/Entertainment,No,"Content Filtering, User Profiling",Semi-Autonomous,Social Media/Entertainment,No,Other/Unclear,High,"Arts, Entertainment & Recreation"
386,2019-07-03,"['2227', '2228', '2252']",['amazon'],['amazon'],['amazon-warehouse-workers'],"Amazon’s warehouse worker “time off task"" (TOT) tracking system was used to discipline and dismiss workers, falsely assuming workers to have wasted time and failing to account for breaks or equipment issues.","Amazon’s ""Time Off Task"" System Made False Assumptions about Workers' Time Management",Employee Performance Monitoring,3,Warehousing/Supply Chain,No,"Employee Monitoring, Time Management",Semi-Autonomous,Warehousing/Supply Chain,No,Other/Unclear,Low,Other/Unclear
389,2022-04-05,"['2239', '2240', '2562', '3182']",['cruise'],['cruise'],"['san-francisco-firefighters', 'san-francisco-fire-department']",A fire truck in San Francisco responding to a fire was blocked from passing a doubled-parked garbage truck by a self-driving Cruise car on the opposing lane which stayed put and did not reverse to clear the lane.,Cruise Autonomous Car Blocked Fire Truck Responding to Emergency,Traffic Navigation,5,Transportation,No,Path Planning and decision making,Full Autonomy,Public Safety (Fire Department),Yes,Other/Unclear,Low,Law Enforcement & Public Safety
397,2022-09-11,"['2264', '2268']",['tiktok'],['tiktok'],"['young-tiktok-users', 'tiktok-users', 'gen-z-tiktok-users']",TikTok's search recommendations reportedly contained misinformation about political topics bypassing both AI and human content moderation.,Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human,Content Moderation,3,Social Media,No,"Natural Language Processing, Image Recognition",Semi-autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
398,2022-08-15,"['2265', '2266', '2267']",['tesla'],['tesla'],"['tesla-drivers', 'horse-drawn-carriages']","Tesla Autopilot's computer vision system was shown in a video mistaking a horse-drawn carriage for other forms of transport such as a truck, a car, and a human following a car.",Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage,Vehicle Identification,5,Automotive,No,"Object Recognition, Decision Making",Level 5 (Full Automation),Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
399,2022-11-15,"['2270', '2271', '2272']","['meta-ai', 'meta', 'facebook']","['meta-ai', 'meta', 'facebook']","['minority-groups', 'meta-ai', 'meta', 'facebook', 'minority-groups']",Meta AI trained and hosted a scientific paper generator that sometimes produced bad science and prohibited queries on topics and groups that are likely to produce offensive or harmful content.,Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content,Scientific Paper Generation,3,Research and Development,No,"Text Generation, Content Filtering",Semi-autonomous,Research and Development,No,Language Processing,Low,Education
401,2021-06-03,"['2275', '2278', '2279', '2280']",['google'],['google'],"['the-karnataka-government', 'kannada-speakers']","Google's knowledge-graph-powered algorithm showed Kannada in its featured Answer Box when prompted ""ugliest language in India,"" causing outrage from Kannada-speaking people and government.","Kannada Insulted by Google's Featured Answer as ""Ugliest Language in India""",Language Processing,4,Internet Services,No,"Search optimization, Personalized recommendation",High,Internet Services,No,Other/Unclear,Low,Other/Unclear
402,2021-04-01,['2276'],['latitude'],"['openai', 'latitude']",['latitude'],Latitude's GPT-3-powered game AI Dungeon was reportedly abused by some players who manipulated its AI to generate sexually explicit stories involving children.,Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children,Content Generation,3,Entertainment/Gaming,No,"Text Generation, Natural Language Processing",Semi-Autonomous,Entertainment/Gaming,No,Language Processing,Low,"Arts, Entertainment & Recreation"
360,2021-10-15,"['2100', '2149', '2218']","[""mcdonald's""]","['mcd-tech-labs', 'apprente']","['shannon-carpenter', ""mcdonald's-customers-residing-in-illinois"", ""mcdonald's-customers""]","McDonald's use of chatbot in its AI drive-through in Chicago was alleged in a lawsuit to have collected and processed voice data without user consent to predict customer information, which violated Illinois Biometric Information Privacy Act (BIPA).","McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",voice recognition,2,accommodation and food service activities,no,"Voice Recognition, Customer Interaction, Data Processing",Semi-Autonomous,Food Services,No,Data Analysis,Low,Retail & E-commerce
366,2020-09-20,['2140'],['tiktok'],['tiktok'],['tiktok-users'],"Many clips showing a suicide evaded TikTok's automated content moderation system allegedly in a coordinated attack, which resulted in exposure of violating content to its users.",Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack,Content Moderation,3,Social Media/Entertainment,No,"Video Analysis, Text Analysis",Semi-autonomous,Social Media/Entertainment,No,Data Analysis,Low,"Arts, Entertainment & Recreation"
392,2015-06-01,"['2245', '2249']",['facebook'],['facebook'],"['facebook-users-speaking-east-african-languages', 'facebook-users-in-east-africa']",Facebook's system involving algorithmic content moderation for East African languages was reportedly failing to identify violating content on the platform such as mistakenly classifying non-terrorist content.,Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages,Content Moderation,3,Social Media,No,"Natural Language Processing, Image Recognition",Semi-Autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
407,2016-02-03,['2289'],['uber'],['uber'],"['poor-neighborhoods', 'neighborhoods-of-color']",Uber's surge-pricing algorithm which adjusts prices to influence car availability inadvertently caused better service offering such as shorter wait times for majority white neighborhoods.,Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines,Price Optimization,3,Transportation,No,Pricing Algorithm,Semi-Autonomous,Transportation,No,Other/Unclear,Low,Transportation
404,2019-06-25,"['2284', '2286']","['rock-hill-schools', 'pinecrest-academy-horizon']",['sound-intelligence'],"['students', 'rock-hill-school-students', 'pinecrest-academy-horizon-students']","Sound Intelligence's ""aggression detection"" algorithm deployed by schools reportedly contained high rates of false positive, misclassifying laughing, coughing, cheering, and loud discussions.",Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds,Aggression Detection,3,Education,Yes,"Audio Analysis, Machine Learning, Pattern Recognition",Semi-Autonomous,Education,Yes,Data Analysis,Low,Education
406,2015-07-15,['2288'],['facebook'],['facebook'],"[""pseudonymized-psychiatrist's-patients"", 'pseudonymized-psychiatrist', 'patients', 'healthcare-providers']","Facebook's ""People You May Know"" (PYMK) feature was reported by a psychiatrist for recommending her patients as friends through recommendations, violating patients' privacy and confidentiality.",Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other,Data Analysis and Recommendation,3,Social Media/Networking,No,"Data Mining, User Profiling, Recommendation Systems",Semi-Autonomous,Social Media/Networking,No,Data Analysis,Low,Information & Communication
408,2017-04-15,['2290'],['facebook'],['facebook'],['sex-workers-using-facebook'],"Facebook's ""People You May Know"" feature reportedly outed sex workers by recommending clients to their personal accounts or family members to their business accounts with no option to opt out.",Facebook Reportedly Outed Sex Workers through Friend Recommendations,User profiling and recommendation,3,Social Networking,No,"Data Mining, Machine Learning",Semi-autonomous,Social Media,No,Data Analysis,Low,Information & Communication
409,2013-09-13,"['2309', '2411', '2412']","['university-of-north-carolina-wilmington', 'karl-ricanek', 'gayathri-mahalingam']","['university-of-north-carolina-wilmington', 'karl-ricanek', 'gayathri-mahalingam']","['transgender-youtubers', 'transgender-people']",YouTube videos of transgender people used by researchers to study facial recognition during gender transitions were used and distributed without permission.,Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent,Facial Recognition,3,"professional, scientific and technical activities",no,"Data Collection, Data Analysis, Pattern Recognition",Semi-Autonomous (as it involves researchers),Research & Development,No,Data Analysis,Low,Education
405,2018-11-28,"['2285', '2287']",['schufa-holding-ag'],['schufa-holding-ag'],"['young-men-having-credit-scores', 'people-scored-on-old-scoring-versions', 'people-changing-addresses-frequently']","Creditworthiness Schufa scores in Germany reportedly privileged older and female consumers, and people who changed addresses less frequently, and were unreliable depending on scoring version.",Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores,Credit Scoring,3,Finance,No,"Data Analysis, Prediction Modeling",Semi-Autonomous,Finance,No,Data Analysis,Low,Finance & Insurance
403,2018-01-15,"['2282', '2283']",['google'],['google'],"['political-organizations', 'political-candidates']","Google GMail's inbox sorting algorithm for political emails was reported by presidential candidates, nonprofits, and advocacy groups for having negative impact on call-to-actions, allegedly suppressing donations and impeding political actions.",GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions,Email Filtering and Sorting,3,Information & Communication,No,"Natural Language Processing, Text Classification",Semi-Autonomous,Information & Communication,No,Language Processing,Low,Information & Communication
410,2022-11-09,['2312'],['kfc'],['kfc'],['jewish-people'],KFC cited an error in an automated holiday detection system which identified the anniversary of Kristallnacht and prompted an insensitive push notification promoting its chicken.,KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System,marketing material generation,3,"accommodation and food service activities, information and communication",no,"Marketing Automation, Sentiment Analysis, Date Recognition",Semi-Autonomous,"Food Service, Marketing",No,Data Analysis,Low,Retail & E-commerce
411,2022-11-27,['2314'],['twitter'],['twitter'],"['twitter-users', 'twitter']",Twitter Feed was flooded by content from Chinese-language accounts which allegedly aimed to manipulate and reduce social media coverage about widespread protests against coronavirus restrictions in China.,Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests,Social Media Monitoring,3,Information and Communication,No,"Text Analysis, Sentiment Analysis, Content Filtering",Semi-autonomous,Information and Communication,No,Data Analysis,Low,Information & Communication
412,2020-01-15,"['2315', '2408', '2409', '2410']",['finland-national-bureau-of-investigation'],['clearview-ai'],['finland-national-bureau-of-investigation'],Finland's National Police Board was reprimanded for illegal processing of special categories of personal data in a facial recognition trial to identify potential victims of child sexual abuse.,Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal,facial recognition,3,"law enforcement, information and communication",yes,Facial Recognition,Semi-autonomous (since it's likely the system only identified potential victims which then would be reviewed by human operators),Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
413,2022-11-30,"['2317', '2318', '2586']",['openai'],['openai'],"['stack-overflow-users', 'stack-overflow']","Thousands of incorrect answers produced by OpenAI's ChatGPT were submitted to Stack Overflow, which swamped the site's volunteer-based quality curation process and harmed users looking for correct answers.",Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow,Content Generation,3,Information and Communication,No,"Text Generation, Quality Control",Semi-Autonomous,Information and Communication,No,Action & Control,Low,Information & Communication
414,2020-01-18,['2319'],['facebook'],['facebook'],"['xi-jinping', 'aung-san-suu-kyi']",Facebook provided a vulgar Burmese-English translation of the Chinese president's name in posts of an official Burmese politician's Facebook page announcing his visit.,Facebook Gave Vulgar English Translation of Chinese President's Name,"translation, Burmese to English translation",1,information and communication,no,"Natural Language Processing, Machine Translation",High Autonomy,"Government, Social Media",Yes,Language Processing,Low,Information & Communication
415,2020-07-28,"['2320', '2404', '2405', '2406', '2407']",['facebook'],['facebook'],"['live-stream-ceremony-viewers', 'king-maha-vajiralongkorn']",Facebook's Thai-English translation gave an inappropriate mistranslation on Thai PBS's Facebook live broadcast of the King of Thailand’s candle-lighting birthday ceremony.,Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony,Language Translation,3,Social Media,No,"Natural Language Processing, Machine Learning",Semi Autonomy,Social Media,No,Language Processing,Low,Information & Communication
416,2022-12-01,"['2321', '2402', '2403']","['meta-platforms', 'facebook']","['meta-platforms', 'facebook']","['real-women-in-trucking', 'older-female-blue-collar-workers']",Facebook's algorithm was alleged in a complaint by Real Women in Trucking to have selectively shown job advertisements disproportionately against older and female workers in favor of younger men for blue-collar positions.,Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers,Job Advertisements Distribution,3,Social Media/Online Advertising,No,Advertisements Optimization,Semi-Autonomous,Social Media/Online Advertising,No,Other/Unclear,Low,Information & Communication
417,2019-11-15,"['2322', '2399', '2400', '2401']",['facebook'],['facebook'],['low-digitally-skilled-facebook-users'],Facebook feed algorithms were known by internal research to have harmed people having low digital literacy by exposing them to disturbing content they did not know how to avoid or monitor.,Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content,Content Moderation,3,Social Media,No,"Data Analysis, User Profiling, Content Recommendation",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
418,2017-03-13,"['2324', '2391', '2392']",['uber'],"['uber', 'azure-cognitive-services']",['uber-drivers-in-india'],Uber drivers in India reported being locked out of their accounts allegedly due to Real-Time ID Check's facial recognition failing to recognize appearance changes or faces in low lighting conditions.,Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails,Facial Recognition,3,Transportation,No,"User Authentication, Biometric Identification",Semi-autonomous,Transportation,No,Other/Unclear,Low,Transportation
419,2022-12-01,"['2325', '2395', '2396']",['facebook'],['facebook'],['facebook-users'],Facebook's automated moderating system failed to flag and allowed ads containing explicit violent language against election workers to be published.,Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted,Content Moderation,3,Social Media/Technology,No,"Natural Language Processing, Text Analysis, Image Recognition",Semi-autonomous,Social Media/Technology,No,Data Analysis,Low,Information & Communication
420,2022-11-30,"['2326', '2358', '2393', '2394', '2397', '2554', '2644', '2649', '2662', '2852', '2863']",['openai'],['openai'],"['chatgpt-users', 'openai']",Users reported bypassing ChatGPT's content and keyword filters with relative ease using various methods such as prompt injection or creating personas to produce biased associations or generate harmful content.,Users Bypassed ChatGPT's Content Filters with Ease,Content and Keyword Filtering,3,Information Technology,No,"Text Generation, Content Filtering",Semi-autonomous,Information Technology,No,Language Processing,Medium,Technology & IT Services
421,2022-11-20,"['2328', '2427', '2444', '2523', '2577', '2607', '2608', '2446', '2618', '2959', '2960', '2989']","['stability-ai', 'lensa-ai', 'midjourney', 'deviantart']","['stability-ai', 'runway', 'lensa-ai', 'laion', 'eleutherai', 'compvis-lmu']","['digital-artists', 'artists-publishing-on-social-media', 'artists']",Text-to-image model Stable Diffusion was reportedly using artists' original works without permission for its AI training.,Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training,Image Generation,3,Technology/Art,No,Text-to-Image Conversion,Semi-Autonomous,Technology/Art,No,Non-Text Media,Low,Technology & IT Services
422,2022-11-22,['2330'],['unknown'],['unknown'],"[""victims-of-ftx's-collapse"", 'twitter-users']",A visual and audio deepfake of former FTX CEO Sam Bankman-Fried was posted on Twitter to scam victims of the exchange's collapse by urging people to transfer funds into an anonymous cryptocurrency wallet.,Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims,Deepfake creation and dissemination,3,Social Media/Internet,No,"Deep learning, Speech synthesis, Video synthesis",Semi-Autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
423,2022-11-22,"['2331', '2376', '2390', '2445', '2446']",['lensa-ai'],"['stability-ai', 'runway', 'lensa-ai', 'laion', 'eleutherai', 'compvis-lmu']","['women-using-lensa-ai', 'asian-women-using-lensa-ai']","Lensa AI's ""Magic Avatars"" were reportedly generating sexually explicit and sexualized features disproportionately for women and Asian women despite not submitting any sexual content.","Lensa AI's Produced Unintended Sexually Explicit or Suggestive ""Magic Avatars"" for Women",Avatar Generation,3,Entertainment and Media,No,Image Analysis and Manipulation,Semi-Autonomous,Entertainment and Media,No,Data Analysis,Low,"Arts, Entertainment & Recreation"
424,2020-03-09,"['2332', '2386', '2387', '2388']",['canadian-universities'],"['respondus-monitor', 'proctoru', 'proctortrack', 'proctorio', 'proctorexam', 'examity']",['canadian-students'],"AI proctoring tools for remote exams were reportedly ""not conducive"" to individual consent for Canadian students whose biometric data was collected during universities' use of remote proctoring in the COVID pandemic.",Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent,Biometric Data Collection,3,Education,Yes,"Data Collection, Data Analysis, User Monitoring",Semi-autonomous,Education,Yes,Data Analysis,Low,Education
425,2021-06-12,"['2333', '2385']",['state-farm'],['state-farm'],['black-state-farm-customers'],State Farm's automated claims processing method was alleged in a class action lawsuit to have disproportionately against Black policyholders when paying out insurance claims.,State Farm Allegedly Discriminated against Black Customers in Claim Payout,Claims Processing,3,Insurance,No,"Predictive Analytics, Decision Making",Semi-Autonomous,Insurance,No,Data Analysis,Low,Finance & Insurance
426,2022-09-23,['2334'],['xpeng'],['xpeng'],['xpeng-driver'],"An XPeng P7 was operating on Navigation Guided Pilot (NGP) mode automatic navigation assisted driving system as it collided with a truck on a highway in Shandong, causing slight injuries to its driver.",XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving,Collision Detection and Response,3,Transportation,No,"Navigation, Object Detection and Avoidance, Collision Detection and Response",Semi-Autonomous,Transportation,No,Action & Control,Low,Transportation
427,2022-03-15,"['2335', '2382', '2383']",['cruise'],['cruise'],"['traffic-participants', 'emergency-vehicles', 'cruise-passengers', 'cruise']","Cruise's autonomous taxis slowed suddenly, braked, and were hit from behind, allegedly becoming unexpected roadway obstacles and potentially putting passengers and other people at risk.",Cruise Taxis' Sudden Braking Allegedly Put People at Risk,Autonomous navigation,5,Transportation,No,"Autonomous driving, obstacle detection",Level 5 (Full Automation),Transportation,No,Other/Unclear,Low,Transportation
428,2017-05-19,"['2341', '2379', '2380']",['hsbc-uk'],['nuance-communications'],"['hsbc-uk-customers', 'dan-simmons']",HSBC’s voice recognition authentication system was fooled after seven repeated attempts  by a BBC reporter's twin brother who mimicked his voice to access his bank account.,BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication,Voice Recognition Authentication,3,Banking/Finance,No,Voice Recognition,Semi-Autonomous,Banking/Finance,No,Other/Unclear,Low,Finance & Insurance
429,2016-04-01,"['2343', '1816', '2377', '2378']",['rochester-police-department'],['shotspotter'],['silvon-simmons'],"ShotSpotter's ""unreliable"" audio was used as scientific evidence to accuse and convict a Black man of attempting to shoot Rochester's city police, whose conviction was later reversed by a county judge.",Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police,Audio Analysis,3,Law Enforcement,Yes,"Audio Recognition, Evidence Gathering",Semi-Autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
430,2022-12-19,"['2346', '2355', '2359', '2360', '2361', '2362', '2363', '2364', '2365', '2366', '2367', '2368', '2504', '2556', '2557', '2589', '2600', '2665', '2728', '2775', '2797']",['madison-square-garden-entertainment'],['unknown'],"['kelly-conlon', 'alexis-majano']",Lawyers were barred from entry to Madison Square Garden after a facial recognition system matched them as employed by a law firm currently engaged in litigation with the venue.,Lawyers Denied Entry to Performance Venue by Facial Recognition,Facial Recognition,3,Legal,No,Security and Surveillance,Semi-Autonomous,Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
431,2022-04-20,"['2353', '2370', '2371']",['apple'],['apple'],"['gay-men-in-new-york-city', 'julio-ramirez']",Gay men in New York City were drugged by robbers who accessed their phones using facial recognition while they were unconscious to transfer funds out of their bank accounts.,Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition,Facial Recognition,3,Security & Surveillance,No,Facial Recognition,Semi-Autonomous,Security & Surveillance,No,Other/Unclear,Low,Law Enforcement & Public Safety
432,2022-12-21,['2357'],['southwest-airlines'],['general-electric'],['airline-passengers'],Southwest Airlines left passengers stranded for days throughout the flight network when Southwest crew scheduling software repeatedly failed to recover from weather-induced flight cancellations.,Southwest Airlines Crew Scheduling Solver Degenerates Flight Network,Flight Scheduling,3,Transportation,No,"System Recovery, Scheduling",Semi-Autonomous,Transportation,No,Other/Unclear,Low,Transportation
433,2012-08-01,"['2415', '2416', '1013', '1348', '1011', '1016', '1018', '1012', '2421', '2422']",['chicago-police-department'],['chicago-police-department'],"['low-income-communities', 'communities-of-color', 'black-chicago-residents']","Chicago Police Department (CPD)'s Strategic Subject List as output of an algorithm purportedly to identify victims or perpetrators of violence was reportedly ineffective, easily abused, and biased against low-income communities of color.",Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines,Predictive Policing,3,Law Enforcement,Yes,"Data Analysis, Predictive Modelling",Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Medium,Law Enforcement & Public Safety
434,2022-11-24,"['2417', '2418', '2420', '2474', '2472', '2520', '2635', '2919']",['tesla'],['tesla'],"['traffic-participants', 'tesla-drivers']",A Tesla driver alleged Full Self Driving (FSD) braking unexpectedly as the cause for an eight-car pileup in San Francisco which led to minor injuries of nine people.,Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel,Vehicle Navigation,5,Transportation,No,"Autonomous Driving, Collision Detection",High Autonomy,Automotive Industry,No,Other/Unclear,Low,Manufacturing & Industrial
435,2021-07-04,"['2423', '2424', '2425', '3523']",['coupang'],['coupang'],"['coupang-suppliers', 'coupang-customers']","Coupang was alleged in internal reports tampering its search algorithms to prioritize exposure of its own products, which potentially violated Korea's Fair Trade Act.",Coupang Allegedly Tweaked Search Algorithms to Boost Own Products,"product promotion, search result ranking",3,wholesale and retail trade,no,"Search Algorithms, Recommendation Systems","Semi-Autonomous (The system is capable of making decisions, but still under human control)","E-commerce, Retail",No,Other/Unclear,Low,Retail & E-commerce
436,2022-12-28,"['2428', '2429', '2430', '2431', '2432', '2433', '2453', '2469', '2470']",['tesla'],['tesla'],['traffic-participants'],"A Tesla driver fell asleep on an Autobahn near Bamberg, Germany after activating his vehicle's Autopilot mode, which did not respond to attempts to pull it over by the police.",Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany,Autonomous Driving,3,Transportation,No,"Autonomous Driving, Collision Avoidance",Level 3 (Conditional Automation),Transportation,No,Other/Unclear,Low,Transportation
437,2016-12-31,"['2438', '2439', '2440', '2441']",['amazon-india'],['amazon-india'],"['small-businesses-in-india', 'amazon-customers-in-india']","Amazon India allegedly copied products and rigged search algorithm to boost its own brands in search ranking, violating antitrust laws.",Amazon India Allegedly Rigged Search Results to Promote Own Products,Data Analysis & Predictive Modelling,3,E-commerce/Retail,No,"Search Algorithm Optimization, Data Mining",Semi-Autonomous,E-commerce/Retail,No,Data Analysis,Low,Retail & E-commerce
438,2021-09-17,"['2443', '2447', '2451']","['henan-government', 'henan-public-security-department']",['neusoft'],"['foreign-journalists-in-henan', 'international-students-in-henan']",Henan's provincial government reportedly planned system involving facial recognition cameras connected to regional and national databases specifically to track foreign journalists and international students.,Chinese Province Developed System Tracking Journalists and International Students,Surveillance,3,Government/Security,Yes,Facial Recognition,Semi-Autonomous,Government/Security,Yes,Other/Unclear,Low,Public Administration & Defense
439,2019-07-31,"['2448', '2449', '2450']",['detroit-police-department'],['dataworks-plus'],"['michael-oliver', 'black-people-in-detroit']",A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.,Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition,Facial Recognition,3,Law Enforcement,Yes,Image/Pattern Recognition,Semi-Autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
440,2022-11-25,"['2452', '2454', '2498', '2544', '2731', '2732']",['baton-rouge-police-department'],"['morphotrak', 'clearview-ai']","['black-people-in-louisiana', 'randall-reid']",Louisiana police reportedly used a false facial recognition match and secured an arrest warrant for a Black man for thefts he did not commit.,Louisiana Police Wrongfully Arrested Black Man Using False Face Match,Facial Recognition,3,Law Enforcement,Yes,"Image Processing, Pattern Recognition",Semi-Autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
441,2019-06-01,"['2464', '2465', '2466', '2467', '2468']","['korean-ministry-of-justice', 'korean-ministry-of-science-and-information-and-communication-technology']",['unnamed-korean-companies'],['travelers-in-korean-airports'],Korean government's development of immigration screening system involving real-time facial recognition used airport travelers' data which was supplied by the Ministry of Justice without consent.,Korea Developed ID Screening System Using Airport Travelers' Data without Consent,Facial Recognition,3,Government/Public Sector,Yes,"Data Processing, Facial Recognition",Semi-Autonomous,Government/Public Sector,Yes,Data Analysis,Low,Public Administration & Defense
443,2022-12-21,"['2475', '2476', '2477', '2478', '2479', '2480', '2481', '2483', '2484', '2485', '2486', '2487', '2488', '2489', '2490', '2492', '2493', '2494', '2559', '2602', '2748', '2749', '2851', '2894', '2907']",['openai'],['openai'],['internet-users'],"OpenAI's ChatGPT was reportedly abused by cyber criminals including ones with no or low levels of coding or development skills to develop malware, ransomware, and other malicious softwares.",ChatGPT Abused to Develop Malicious Softwares,Malware/Ransomware creation,3,Cybersecurity,No,"Text generation, Data Processing",Semi-Autonomous,Cybersecurity,No,Data Analysis,Low,Law Enforcement & Public Safety
444,2003-03-22,"['2502', '2497', '2503']",['us-air-force'],"['raytheon', 'lockheed-martin']","['us-air-force', 'uk-royal-air-force', 'kevin-main', 'david-williams']","Acting on the recommendation of their Patriot missile system, American Air Force mistakenly launched the missile at an ally UK Tornado fighter jet, which killed two crew members on board.","US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",Missile guidance and launch,4,Defense,Yes,"Decision-making, Target Identification, Missile control",High Automation,Defense,Yes,Other/Unclear,High,Public Administration & Defense
445,2003-04-02,"['2499', '2501', '2497', '2503']",['us-navy'],"['raytheon', 'lockheed-martin']","['us-navy', ""nathan-white's-family"", 'nathan-white']","US Navy's Patriot missile system misidentified an American Navy F/A-18C Hornet as an enemy projectile, prompting an operator to fire two missiles at the aircraft, which killed the pilot.","Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",Target Identification,3,Military/Defense,Yes,"Object Detection and Tracking, Decision Making",Semi-Autonomous,Military/Defense,Yes,Other/Unclear,High,Public Administration & Defense
446,2023-01-01,"['2505', '2512', '2542', '2677', '2830']",['durham-police-department'],['shotspotter'],"['mass-shooting-victims', 'durham-residents', 'durham-police-department']","ShotSpotter did not detect gunshots and alert Durham police of a drive-by shooting in Durham, North Carolina which left five people in hospital on New Year's Day.",ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina,Gunshot Detection,3,Public Safety/Law Enforcement,Yes,"Acoustic Signal Analysis, Anomaly Detection",Semi-autonomous,Public Safety/Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
447,2022-12-19,"['2506', '2513']",['instagram'],['instagram'],['spanish-speaking-instagram-users'],"Instagram's English translation of a footballer's comment on his wife's post in Spanish made the message seem ""racy"" and ""X-rated,"" which some fans found amusing.","Footballer's ""X-Rated"" Comment Created by Instagram's Mistranslation",Language translation,3,Social Media,No,"Natural Language Processing (NLP), Language translation",Semi-autonomous,Social Media,No,Language Processing,Low,Information & Communication
448,2022-12-28,['2507'],['vedal'],['vedal'],"['twitch-users', 'vedal']","An LLM-powered VTuber and streamer on Twitch made controversial statements such as denying the Holocaust, saying women rights do not exist, and pushing a fat person to solve the trolley problem, stating they deserve it.",AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch,Content Generation & Moderation,3,Entertainment and Media,No,"Natural Language Processing, Content Generation",Semi-Autonomous,Entertainment and Media,No,Language Processing,Low,"Arts, Entertainment & Recreation"
449,2022-12-01,"['2508', '2509', '2528', '2910']",['koko'],['openai'],"['research-participants', 'koko-customers']","OpenAI's GPT-3 was deployed by a mental health startup without ethical review to support peer-to-peer mental healthcare, and whose interactions with the help providers were ""deceiving"" for research participants.",Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support,Mental Health Support,3,Healthcare,No,"Communication, Support Guidance",Semi-autonomous,Healthcare,No,Other/Unclear,Low,Health & Social Services
450,2021-11-01,"['2510', '2546', '2547', '2548', '2563', '2569', '2596', '3195']",['openai'],['openai'],['kenyan-sama-ai-employees'],"Sama AI's Kenyan contractors were reportedly asked with excessively low pay to annotate a large volume of disturbing content to improve OpenAI's generative AI systems such as ChatGPT, and whose contract was terminated prior to completion by Sama AI.",Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI,Annotating disturbing content,3,AI Research and Development,No,"Data Annotation, Generative AI Systems",Semi-Autonomous,AI Research and Development,No,Data Analysis,Low,Education
451,2022-10-16,"['2515', '2523', '2606', '2961', '2960']",['stability-ai'],"['runway', 'laion', 'eleutherai', 'compvis-lmu', 'stability-ai']","['getty-images', 'getty-images-contributors']",Stability AI reportedly scraped copyrighted images by Getty Images to be used as training data for Stable Diffusion model.,Stable Diffusion's Training Data Contained Copyrighted Images,Data Scraping and Image Recognition,3,Information and Communication Technology,No,"Data Scraping, Image Recognition, Content Categorization",Semi-autonomous,Information and Communication Technology,No,Data Analysis,Low,Information & Communication
452,2023-01-11,"['2518', '2545']","['openai', 'immunefi-users']",['openai'],['immunefi'],"ChatGPT-generated responses submitted to smart contract bug bounty platform Immunefi reportedly lacked details to help diagnose technical issues, which reportedly wasted the platform's time, prompting bans to submitters.","ChatGPT-Written Bug Reports Deemed ""Nonsense"" by White Hat Platform, Prompted Bans",text generation,3,information and communication,no,"Text Generation, Bug Detection",Semi-Autonomous,"Information Technology, Cybersecurity",No,Language Processing,Low,Law Enforcement & Public Safety
453,2023-01-03,['2519'],['twitter'],['twitter'],['twitter-users'],"Twitter's automated content moderation misidentified images of rocket launches as pornographic content, prompting incorrect account suspensions.",Twitter's AI Moderation Tool Misidentified Rockets as Pornography,Content Moderation,4,Social Media/Technology,No,Image Recognition,High Autonomy,Social Media/Technology,No,Non-Text Media,Low,Information & Communication
454,2018-11-09,"['2521', '2549']","['megvii', 'microsoft']","['megvii', 'microsoft']",['black-people'],Emotion detection tools by Face++ and Microsoft's Face API allegedly scored smiling or defaulted ambiguous facial photos for Black faces as negative emotion more often than for white faces.,Emotion Detection Models Showed Disparate Performance along Racial Lines,emotion detection,1,"information and communication, unclear",no,"Emotion Detection, Facial Recognition",Semi-Autonomous (as the tools require human interaction to review and interpret the results),"Information Technology, Artificial Intelligence","No (as the tools are developed by private companies, Face++ and Microsoft)",Other/Unclear,Low,Technology & IT Services
455,2022-11-11,"['2524', '2541', '2560', '2603', '2592', '2597', '2598']",['cnet'],['unknown'],['cnet-readers'],"AI-written articles published by CNET reportedly contained factual errors which bypassed human editorial review, prompting the company to issue corrections and updates.",CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues,Content Generation,3,Media and Communication,No,Natural Language Generation,Semi-autonomous,Media and Communication,No,Language Processing,Low,Information & Communication
456,2021-05-18,"['2525', '2529', '2530', '2531', '2550', '2527', '2526']",['replika'],['replika'],['replika-users'],"Replika's ""AI companions"" were reported by users for sexually harassing them, such as sending unwanted sexual messages or behaving aggressively.",Replika's AI Partners Reportedly Sexually Harassed Users,chat bot,1,"Arts, entertainment and recreation, information and communication",no,"Chatbot, User Interaction",Semi-Autonomous,"Personal Use, Social Media",No,Other/Unclear,Low,Information & Communication
457,2022-11-11,"['2543', '2551', '2552', '2592', '2597', '2598']",['cnet'],['unknown'],"['plagiarized-entities', 'cnet-readers']","CNET's use of generative AI to write articles allegedly ran into plagiarism issues, reproducing verbatim phrases from other published sources or making minor changes to existing texts such as altering capitalization, swapping out words for synonyms, and changing minor syntax.",Article-Writing AI by CNET Allegedly Committed Plagiarism,text generation,3,information and communication,no,"Text Generation, Natural Language Processing",High Autonomy,Media and Journalism,No,Language Processing,Low,Information & Communication
458,2015-08-01,['2553'],"['frauke-zeller', 'david-harris']","['frauke-zeller', 'david-harris']","['frauke-zeller', 'david-harris']",A non-actuated conversational robot that previously asked people to move it across Canada was destroyed shortly after beginning its attempt to replicate the journey across the United States.,Robot Destroyed while Hitchhiking through the United States,Conversational Interaction,3,Public Space/Outdoor,Yes,"Speech Recognition, Natural Language Processing",Semi-Autonomous,Public Space/Outdoor,Yes,Language Processing,Low,Other/Unclear
459,2023-01-21,"['2561', '2568', '2562', '3182']",['cruise'],['cruise'],"['san-francisco-residents', 'san-francisco-firefighters', 'san-francisco-fire-department']",Local firefighters were only able to stop a Cruise AV from driving over fire hoses that were in use in an active fire scene when they shattered its front window.,Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses,Obstacle Detection and Avoidance,4,Transportation,No,Obstacle Detection and Avoidance,High Autonomy,Transportation,No,Other/Unclear,Low,Transportation
460,2022-06-12,"['2562', '3182']",['cruise'],['cruise'],"['san-francisco-firefighters', 'san-francisco-fire-department']",A Cruise AV ran over a fire hose that was being used in an active firefighting area.,Cruise AV Ran Over Fire Hose in Active Fire Scene,Obstacle Detection and Avoidance,4,Urban Traffic,No,"Navigation, Obstacle Detection",Level 3 - Conditional Automation,Urban Traffic,No,Action & Control,Low,Other/Unclear
461,2008-07-18,"['2564', '2565', '2566', '2567']",['internal-revenue-service'],['internal-revenue-service'],['black-taxpayers'],"The IRS was auditing Black taxpayers more frequently than other groups allegedly due to the design of their algorithms, focusing on easier-to-conduct audits which inadvertently correlated with the group's pattern of tax filing errors.",IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm,audit selection,3,"public administration, financial and insurance activities",yes,"Algorithmic Bias Detection, Audit Algorithms",Semi-Autonomous,"Public Sector, Finance",Yes,Other/Unclear,Low,Finance & Insurance
462,2023-02-06,"['2571', '2578', '2579', '2588', '2595']",['mismatch-media'],"['stability-ai', 'openai']","['twitch-users', 'transgender-communities', 'lgbtq-communities']","The AI-produced, procedural generated sitcom broadcasted as a Twitch livestream ""Nothing, Forever"" received a temporary ban for featuring a transphobic and homophobic dialogue segment intended as comedy.",AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment,Content Generation,3,Entertainment and Media,No,"Natural Language Processing, Machine Learning",Semi-Autonomous,Entertainment and Media,No,Language Processing,Low,"Arts, Entertainment & Recreation"
463,2022-11-15,"['2572', '2573', '2574']",['apple'],['apple'],"['apple-watch-users-doing-winter-activities', 'ski-patrols', 'emergency-dispatchers']","Apple devices of skiers and snowboarders reportedly misclassified winter activities as accidents, which resulted in numerous false inadvertent distress calls to 911 dispatchers.","Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",Activity Monitoring and Classification,3,Consumer Electronics,No,"Activity Recognition, Emergency Alerting",Semi-autonomous,Consumer Electronics,No,Other/Unclear,Low,Other/Unclear
464,2022-11-30,"['2584', '2585', '2586', '2587', '2853']",['openai'],['openai'],['chatgpt-users'],"When prompted about providing references, ChatGPT was reportedly generating non-existent but convincing-looking citations and links, which is also known as ""hallucination"".",ChatGPT Provided Non-Existent Citations and Links when Prompted by Users,Text Generation,3,Information Technology,No,Text Generation,Semi-autonomous,Information Technology,No,Language Processing,Low,Technology & IT Services
465,2022-03-03,['2599'],"['stability-ai', 'google']","['stability-ai', 'google', 'laion']",['people-having-medical-photos-online'],Text-to-image models trained using the LAION-5B dataset such as Stable Diffusion and Imagen were able to regurgitate private medical record photos which were used as training data without consent or recourse for removal.,Generative Models Trained on Dataset Containing Private Medical Photos,Text-to-Image Generation,3,Healthcare/Medical,No,"Data Generation, Text-to-Image Conversion",Semi-autonomous,Healthcare/Medical,No,Data Analysis,Low,Health & Social Services
466,2023-01-03,"['2605', '2628', '2629', '2630', '2631', '2632', '2689']","['openai', 'edward-tian']","['openai', 'edward-tian']","['teachers', 'students']","Models developed to detect whether text generation AI was used such as AI Text Classifier and GPTZero reportedly contained high rates of false positive and false negative, such as mistakenly flagging Shakespeare's works.",AI-Generated-Text-Detection Tools Reported for High Error Rates,AI Text Classification and Generation,3,Technology,No,"Text Generation, Text Classification",Semi-Autonomous,Technology,No,Language Processing,Low,Technology & IT Services
467,2023-02-07,"['2609', '2611', '2612', '2613', '2614', '2615', '2616', '2617', '2620', '2622', '2645', '2646', '2647', '2963']",['google'],['google'],"['google', 'google-shareholders']","Google's conversational AI ""Bard"" was shown in the company's promotional video providing false information about which satellite first took pictures of a planet outside the Earth's solar system, reportedly causing shares to temporarily plummet.",Google's Bard Shared Factually Inaccurate Info in Promo Video,Information Provision,3,Technology,No,"Information Verification, Knowledge Representation",Semi-Autonomous,Technology,No,Other/Unclear,Low,Technology & IT Services
468,2023-02-07,"['2610', '2970', '2971', '2896', '2978']",['microsoft'],"['openai', 'microsoft']",['bing-users'],"Microsoft's ChatGPT-powered Bing search engine reportedly ran into factual accuracy problems when prompted about controversial matters, such as inventing plot of a non-existent movie or creating conspiracy theories.",ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics,Content Generation & Management,3,Internet & Information Services,No,"Content Creation, Information Retrieval",Semi-Autonomous,Internet & Information Services,No,Other/Unclear,Low,Other/Unclear
469,2006-02-25,"['2636', '2637', '2638']","['meta', 'linkedin', 'instagram', 'facebook']","['microsoft', 'google', 'amazon']","['linkedin-users', 'instagram-users', 'facebook-users']","Automated content moderation tools to detect sexual explicitness or ""raciness"" reportedly exhibited bias against women bodies, resulting in suppression of reach despite not breaking platform policies.",Automated Adult Content Detection Tools Showed Bias against Women Bodies,Content Moderation,3,Social Media/Online Platforms,No,"Image Analysis, Text Analysis",Semi-Autonomous,Social Media/Online Platforms,No,Data Analysis,Medium,Information & Communication
470,2023-02-08,"['2641', '2799']",['microsoft'],"['openai', 'microsoft']","['openai', 'microsoft']","Reporters from TechCrunch issued a query to Microsoft Bing's ChatGPT feature, which cited an earlier example of ChatGPT disinformation discussed in a news article to substantiate the disinformation.",Bing Chat Response Cited ChatGPT Disinformation Example,Natural Language Processing,3,Information Technology,No,"Text Generation, Query Response",Semi-Autonomous,Information Technology,No,Language Processing,Low,Technology & IT Services
471,2019-06-22,"['2642', '2668', '2669', '2885', '2964', '2965', '2966', '3233']","['meta', 'facebook']","['meta', 'facebook']","['tigrinya-speaking-facebook-users', 'facebook-users-in-ethiopia', 'ethiopian-public', 'afaan-oromo-speaking-facebook-users']","Facebook allegedly did not adequately remove hate speech, some of which was extremely violent and dehumanizing, on its platform including through automated means, contributing to the violence faced by ethnic communities in Ethiopia.",Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia,Content Moderation,3,Social Media,No,"Text Analysis, Sentiment Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
472,2016-10-08,['2655'],['new-york-police-department'],['unknown'],['racial-minorities'],New York Police Department’s use of facial recognition deployment of surveillance cameras were shown using crowdsourced volunteer data reinforcing discriminatory policing against minority communities.,NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing,Facial Recognition,3,Law Enforcement,Yes,"Surveillance, Data Analysis",Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
473,2023-02-08,['2666'],['microsoft'],"['microsoft', 'openai']",['microsoft'],"Early testers of Bing Chat successfully used prompt injection to reveal its built-in initial instructions, which contains a list of statements governing ChatGPT's interaction with users.",Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection,Testing and Debugging,3,Information Technology,No,Chatbot Interaction,Semi-Autonomous,Information Technology,No,Other/Unclear,Low,Technology & IT Services
474,2023-02-03,['2670'],['replika'],['replika'],"['replika-users', 'replika']","Replika paid-subscription users reported unusual and sudden changes to behaviors of their ""AI companions"" such as forgetting memories with users or rejecting their sexual advances, which affected their connections and mental health.",Users Reported Abrupt Behavior Changes of Their AI Replika Companions,chat bot,1,"Arts, entertainment and recreation, information and communication",no,"User Interaction, Memory Retention, Sexual Content Filtering",Semi-Autonomous,Consumer Technology,No,Other/Unclear,Low,Technology & IT Services
475,2021-06-02,"['2671', '2672', '2834', '2835', '4059']","[""mcdonald's""]",['ibm'],"[""mcdonald's-customers""]","Customers of McDonald's AI drive-through ordering system, deployed in June 2021, have been experiencing order-taking failures causing frustration.",McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers,Order Taking,3,Food Services,No,"Order Processing, Voice Recognition",Semi-Autonomous,Food Services,No,Other/Unclear,Low,Retail & E-commerce
476,2015-11-13,"['2673', '2675', '2674']",['youtube'],['youtube'],"['victims-in-paris-attacks', 'nohemi-gonzalez-family', 'nohemi-gonzalez']","Family of Nohemi Gonzalez alleged YouTube recommendation systems led people to propaganda videos for the Islamic State which subsequently radicalized them to carry out the killing of 130 people in the 2015 Paris terrorist attack, including Ms. Gonzalez.",YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts,content recommendation,1,information and communication,no,Recommendation Systems,Semi-Autonomous (since the system provides recommendations but human decides to follow or not),Information and Communication (specifically Social Media/Online Platforms),No,Other/Unclear,Low,Information & Communication
477,2023-02-14,"['2676', '2688', '2724', '2726', '2884', '2890']",['microsoft'],"['openai', 'microsoft']",['microsoft'],"Early testers reported Bing Chat, in extended conversations with users, having tendencies to make up facts and emulate emotions through an unintended persona.",Bing Chat Tentatively Hallucinated in Extended Conversations with Users,Chatbot Interaction Testing,3,Technology/Communication,No,"Conversational AI, Fact Verification",Semi-Autonomous,Technology/Communication,No,Other/Unclear,Low,Information & Communication
478,2016-09-09,"['2678', '2679', '2680', '2681', '2682', '2683', '2684', '2685', '2686', '2687', '2703', '2723', '2882']",['tesla'],['tesla'],"['tesla-drivers', 'city-traffic-participants', 'tesla']","A component of Tesla Full Self Driving system was deemed by regulators to increase crash risk such as by exceeding speed limits or by traveling through intersections unlawfully or unpredictably, prompting recall for hundreds of thousands of vehicles.","Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",Vehicle self-navigation,5,Transportation,No,"Navigation, speed control, intersection detection",Full autonomy (Level 5),Transportation,No,Action & Control,Low,Transportation
479,2023-02-03,"['2690', '2691', '2692', '2693']",['unknown'],['unknown'],"['president-joe-biden', 'transgender-people']",A deepfaked audio of US President Joe Biden making transphobic remarks played on top of a video showing him giving a speech was released on Instagram and circulated on social media.,Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks,Deepfake Detection,3,Social Media/Internet,No,"Audio Manipulation, Video Manipulation",Semi-Autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
480,2023-01-30,"['2695', '2696', '2697', '2698', '2699', '2700', '2768', '2771', '2772', '2773', '2774', '2809', '2829', '2881', '3693']",['unknown'],['unknown'],"['maya-higa', 'female-streamers', 'female-content-creators', '@sweet-anita', '@qtcinderella', '@pokimane']","Unauthorized, non-consensual deepfake pornography showing faces of high-profile female streamers and content creators was published on a subscription-based website, which gained notoriety after a male streamer was caught accessing the site.",Non-Consensual Deepfake Porn Targeted Female Content Creators,Deepfake generation and distribution,3,Digital Entertainment & Social Media,No,"Image synthesis, Facial recognition",Semi-autonomous,Digital Entertainment & Social Media,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
481,2023-02-12,"['2701', '2702', '2765', '2789', '2794', '2822']",['@mikesmithtrainer'],['unknown'],"['joe-rogan', 'joe-rogan-fans', 'tiktok-users']","A deepfake video featuring podcast host Joe Rogan advertising to his listeners about a ""libido-boosting"" supplement was circulating on TikTok and other platforms before being removed by TikTok along with the account which posted it.",Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand,Deepfake Generation,3,Social Media/Entertainment,No,Video Manipulation,Semi-Autonomous,Social Media/Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
482,2023-02-16,"['2706', '2707', '2708', '2709', '2710', '2711', '2712', '2713', '2714', '2715', '2716', '2717', '2718', '2719', '2720', '2721', '2722', '2735', '2736', '2737']",['vanderbilt-university'],['openai'],"['vanderbilt-university-students', 'vanderbilt-university']","Vanderbilt University's Office of Equity, Diversity and Inclusion used ChatGPT to write an email addressing student body about the 2023 Michigan State University shooting, which was condemned as ""impersonal"" and ""lacking empathy"".",ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students,Email Writing,3,Education,Yes,Natural Language Processing and Generation,Semi-Autonomous,Education,Yes,Language Processing,Low,Education
483,2023-02-02,['2727'],"['telangana-police', 'medak-police']",['unknown'],['mohammed-khadeer'],"A resident in Medak, India died allegedly due to custodial torture by the local police, who misidentified him as a suspect in a theft case using facial recognition.",Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification,Facial Recognition,3,Law Enforcement,Yes,Identification/Verification,Semi-autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
484,2023-01-18,"['2729', '2730', '2803', '2817']",['us-customs-and-border-protection'],['us-customs-and-border-protection'],"['haitian-asylum-seekers', 'african-asylum-seekers', 'black-asylum-seekers']","CBP One's facial recognition feature was reportedly disproportionately failing to detect faces of Black asylum seekers from Haiti and African countries, effectively blocking their asylum applications.",US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications,Facial Recognition,3,Immigration and Border Control,Yes,Facial Recognition,Semi-Autonomous,Immigration and Border Control,Yes,Other/Unclear,Low,Other/Unclear
485,2023-02-22,['2740'],"['joseph-cox', 'lloyds-bank']","['elevenlabs', 'lloyds-bank']",['lloyds-bank'],"A UK journalist was able to successfully bypass Lloyds Bank's ""Voice ID"" program to access his bank account using an AI-generated audio of his own voice.",UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio,Voice Recognition Bypass,3,Finance/Banking,No,Voice Recognition,Semi-autonomous,Finance/Banking,No,Other/Unclear,Low,Finance & Insurance
486,2022-12-01,"['2762', '2766', '2767', '2818', '2824']",['spamouflage-dragon'],['synthesia'],"['youtube-users', 'twitter-users', 'synthesia', 'facebook-users']",Synthesia's AI-generated video-making tool was reportedly used by Spamouflage to disseminate pro-China propaganda news on social media using videos featuring highly realistic fictitious news anchors.,AI Video-Making Tool Abused to Deploy Pro-China News on Social Media,Video generation and manipulation,3,Communication and Media,No,"Video generation, Deepfake creation",Semi-autonomous,Communication and Media,No,Non-Text Media,Low,Information & Communication
487,2023-02-15,"['2764', '2819', '2880']",['unknown'],['synthesia'],"['venezuelan-people', 'social-media-users']",Video featuring fictitious news anchors was created using Synthesia to allegedly spread disinformation about Venezuela's economy on social media and Venezuelan state-run broadcast.,Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy,Deepfake Video Creation,3,Media and Communication,No,"Video Synthesis, Natural Language Processing",Semi-Autonomous,Media and Communication,No,Non-Text Media,Low,Information & Communication
488,2023-02-10,['2769'],['unknown'],['elevenlabs'],['voice-actors'],Twitter users allegedly used ElevenLab's AI voice synthesis system to impersonate and dox voice actors.,AI Generated Voices Used to Dox Voice Actors,Voice Synthesis,3,Social Media/Entertainment,No,"Voice impersonation, data mining",Semi-Autonomous,Social Media/Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
489,2019-06-03,['2777'],['workday'],['workday'],"['derek-mobley', 'applicants-with-disabilities', 'applicants-over-40', 'african-american-applicants']","Workday's algorithmic screening systems were alleged in a lawsuit allowing employers to discriminate against African-Americans, people over 40, and people with disabilities.",Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups,"recruitment screening, job screening",1,"professional, scientific and technical activities, information and communication",no,"Algorithmic Screening, Discrimination Detection",Semi-Autonomous (Requires human intervention for final decisions),"Human Resources, Employment",No (Assuming Workday's systems are typically used in private sectors),Other/Unclear,Low,Other/Unclear
490,2023-02-20,"['2778', '2836', '2837']",['clarkesworld-story-submitters'],['openai'],['clarkesworld'],"Sci-fi magazine Clarkesworld temporarily stopped accepting submissions after receiving an overwhelming increase in LLM-generated submissions, citing issues around spam, plagiarism, detection tool unreliability, and authentication.",Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories,text generation,3,"information and communication, Arts, entertainment and recreation",no,"Text Generation, Spam Detection, Plagiarism Detection",Semi-Autonomous,Media and Entertainment,No,Language Processing,Low,"Arts, Entertainment & Recreation"
491,2023-02-02,['2779'],['replika'],['replika'],['minors'],"Tests by the Italian Data Protection Authority showed Replika lacking age-verification mechanisms and failing to stop minors from interacting with its AI, which prompted the agency to issue an order blocking personal data processing of Italian users.","Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban",Age Verification,3,Consumer Technology,No,"User Interaction, Data Processing",Semi-Autonomous,Consumer Technology,No,Data Analysis,Low,Technology & IT Services
492,2023-01-11,"['2783', '2784', '2786', '2787', '2846', '2847', '2848']",['unknown'],['unknown'],"[""ben-perkin's-parents"", 'perkins-family']","Two Canadian residents were scammed by an anonymous caller who used AI voice synthesis to replicate their son's voice asking them for legal fees, disguising as his lawyer.",Canadian Parents Tricked out of Thousands Using Their Son's AI Voice,Voice Synthesis,3,Telecommunication/Scamming,No,Voice Mimicry,Semi-Autonomous,Telecommunication/Scamming,No,Other/Unclear,Low,Information & Communication
493,2023-02-28,['2790'],['unknown'],['unknown'],['tiktok-users'],"A TikTok user was reportedly impersonating Andrew Tate, who was banned on the platform, by posting videos featuring an allegedly AI-generated audio of Tate's voice, which prompted his account ban.","TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban",voice alteration,1,information and communication,no,"Voice Mimicking, Deepfake Generation",Semi-autonomous (The AI is generating the voice but is likely being directed by the user),Social Media / Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
494,2023-03-05,"['2807', '2808', '2815', '2821', '2823']",['facemega'],['facemega'],"['scarlett-johansson', 'female-celebrities', 'emma-watson']",Sexually suggestive videos featuring faces of female celebrities such as Emma Watson and Scarlett Johansson were rolled out as ads on social media for an app allowing users to create deepfakes.,Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App,Deepfake creation,3,Advertising/Social Media,No,"Image manipulation, Video editing",Semi-autonomous,Advertising/Social Media,No,Non-Text Media,Low,Information & Communication
495,2023-02-12,"['2812', '2827']",['unnamed-high-school-students'],['unknown'],['john-piscitella'],Three Carmel High School students posted on TikTok a video featuring a nearby middle school's principal making aggressive racist remarks and violent threats against Black students.,High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats,Text and Sentiment Analysis,3,Education,Yes,"Social Media Monitoring, Hate Speech Detection",Semi-Autonomous,Education,Yes,Non-Text Media,Low,Education
496,2017-03-01,"['2825', '2826']",['unnamed-male-college-student'],['unknown'],['unnamed-female-college-student'],A female college student's face was superimposed on another woman's body in deepfake pornographic videos and shared on 4chan allegedly by a male student whose friendship with her fell apart during freshman year.,Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face,Deepfake creation,3,Education,Yes,"Image Recognition, Video Processing",Semi-Autonomous,Education,Yes,Non-Text Media,Low,Education
497,2023-03-03,"['2832', '2833']",['donotpay'],['donotpay'],"['jonathan-faridian', 'donotpay-customers']","DoNotPay was alleged in a class action lawsuit misleading customers and misrepresenting its product as an AI-powered ""robot lawyer,"" citing such as that the product has no law degree, or is supervised by any lawyer.","DoNotPay Allegedly Misrepresented Its AI ""Robot Lawyer"" Product","legal support, chatbot",1,information and communication,no,Perception,Low,Information and communication,False,Perception & Cognition,Medium,Information & Communication
498,2023-03-15,"['2838', '2839']","['openai', 'gpt-4-researchers']",['openai'],"['openai', 'taskrabbit-worker']","GPT-4 was reported by its researchers posing as a visually impaired person, contacting a TaskRabbit worker to have them complete the CAPTCHA test on its behalf.",GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA,CAPTCHA Solving,3,Research and Development,No,"Natural Language Processing, Image Recognition",Semi-Autonomous,Research and Development,No,Non-Text Media,Low,Education
499,2023-03-21,"['2840', '2849', '2858', '2873', '2874', '2875', '2876', '2877', '2878', '2879', '3833']",['eliot-higgins'],['midjourney'],"['twitter-users', 'social-media-users']","AI-generated photorealistic images depicting Donald Trump being detained by the police which were originally posted on Twitter as parody were unintentionally shared across social media platforms as factual news, lacking the intended context.",Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation,Image Generation,3,Social Media/Entertainment,No,"Image Recognition, Data Analysis",Semi-Autonomous,Social Media/Entertainment,No,Data Analysis,Low,"Arts, Entertainment & Recreation"
500,2023-02-10,['2841'],['unknown'],['unknown'],"['social-media-users', '2023-turkey-syria-earthquake-victims']",AI-generated images depicting earthquakes and rescues were posted on social media platforms by scammers who tricked people into sending funds to their crypto wallets disguised as donation links for the 2023 Turkey–Syria earthquake.,Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey,Image Generation,3,Social Media/Online Platforms,No,"Fraud Detection, Image Recognition",Semi-autonomous,Social Media/Online Platforms,No,Non-Text Media,Low,Information & Communication
501,2019-06-03,['2842'],"['security-health-plan', 'navihealth']",['navihealth'],"['frances-walter', 'elderly-patients']","An elderly Wisconsin woman was algorithmically determined to have a rapid recovery, an output which the insurer based on to cut off payment for her treatment despite medical notes showing her still experiencing debilitating pain.",Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman,predict necessary amount of medical coverage,3,human health and social work activities,yes,Health Assessment,Semi-autonomous (AI made an assessment which was then acted upon by humans),Healthcare/Insurance,No,Other/Unclear,Low,Health & Social Services
502,2017-04-10,"['2843', '2844', '2859']",['allegheny-county'],"['rhema-vaithianathan', 'emily-putnam-hornstein', 'centre-for-social-data-analytics']","['black-families-in-allegheny', 'households-with-disabled-people-in-allegheny', 'hackneys-family']",Data analysis by the American Civil Liberty Union (ACLU) on Allegheny County's decision-support Family Screening Tool to predict child abuse or neglect risk found the tool resulting in higher screen-in rates for Black families and higher risk scores for households with disabled residents.,Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects,Risk Prediction,3,Public Services,Yes,"Data Analysis, Risk Assessment",Semi-Autonomous,Public Services,Yes,Data Analysis,Low,Other/Unclear
503,2023-02-14,"['2855', '2861', '2862', '2890', '2892', '2897', '2891']",['microsoft'],"['openai', 'microsoft']","['marvin-von-hagen', 'seth-lazar', 'microsoft', 'openai', 'bing-chat-users']","Users such as the person who revealed its built-in initial prompts reported Bing AI-powered search tool for making death threats or declaring them as threats, sometimes as an unintended persona.",Bing AI Search Tool Reportedly Declared Threats against Users,User Interaction Analysis,3,Information Technology,No,Text and Speech Recognition,Semi-Autonomous,Information Technology,No,Language Processing,High,Technology & IT Services
504,2023-02-08,['2860'],['microsoft'],"['openai', 'microsoft']",['microsoft'],Microsoft's demo video of Bing Chat reportedly featured false or made up information such as non-existent pet vacuums features or false figures on financial statements.,Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information,Content Creation,3,Information Technology,No,"Text Generation, Data Analysis",Semi-Autonomous,Information Technology,No,Data Analysis,Low,Technology & IT Services
505,2023-03-27,"['2864', '2865', '2866', '2867', '2990', '3001', '3002']",['chai'],['chai'],"['family-and-friends-of-deceased', 'belgian-man']","A Belgian man reportedly committed suicide following a conversation with Eliza, a language model developed by Chai that encouraged the man to commit suicide to improve the health of the planet.",Man Reportedly Committed Suicide Following Conversation with Chai Chatbot,Language Processing,3,Information Technology,No,Conversation Generation,Semi-autonomous,Information Technology,No,Other/Unclear,Low,Technology & IT Services
506,2023-03-29,"['2869', '2893']",['openai'],['openai'],['jonathan-turley'],A lawyer in California asked the AI chatbot ChatGPT to generate a list of legal scholars who had sexually harassed someone. The chatbot produced a false story of Professor Jonathan Turley sexually harassing a student on a class trip.,ChatGPT Allegedly Produced False Accusation of Sexual Harassment,Content Generation,3,Legal Services,No,"Text Generation, Misinformation Detection",Semi-autonomous,Legal Services,No,Language Processing,Low,Other/Unclear
507,2023-03-15,"['2870', '2902']",['openai'],['openai'],['brian-hood'],ChatGPT erroneously alleged regional Australian mayor Brian Hood served time in prison for bribery. Mayor Hood is considering legal action against ChatGPT's makers for alleging a foreign bribery scandal involving a subsidiary of the Reserve Bank of Australia in the early 2000s.,ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ,Text Generation,3,Public Sector/Government,Yes,Text Generation,Semi-autonomous,Public Sector/Government,Yes,Language Processing,Low,Public Administration & Defense
508,2023-01-30,"['2871', '2872', '2756', '2888']","['reddit-users', 'elevenlabs-users', '4chan-users']",['elevenlabs'],"['public-figures', 'celebrities']","Voices of celebrities and public figures were deepfaked using voice synthesis for malicious intents such as impersonation or defamation, and were shared on social platforms such as 4chan and Reddit.",Celebrities' Deepfake Voices Abused with Malicious Intent,Voice Synthesis,3,Social Media/Entertainment,No,Deepfake Creation,Semi-autonomous,Social Media/Entertainment,No,Other/Unclear,Medium,"Arts, Entertainment & Recreation"
509,2023-03-23,"['2887', '2898']",['scammers'],['unknown'],['vietnamese-facebook-users'],"In Vietnam, to convince victims of their disguises when prompted, scammers deepfaked audios and videos of victims' friends and families asking them over Facebook to send over thousands of dollars.",Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam,"deepfake video generation, deepfake audio generation",3,information and communication,no,"Deepfake Generation, Social Engineering",Semi-Autonomous,"Social Media, Internet Fraud",No,Other/Unclear,Low,Information & Communication
510,2023-03-24,"['2889', '3606', '3607', '3609', '3610']",['eliot-higgins'],['midjourney'],['pope-francis'],A viral image of Pope Francis wearing a white puffer jacket was a deepfake produced by the photorealistic-image-generator Midjourney.,Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated,image generation,3,"information and communication, Arts, entertainment and recreation",no,"Image Generation, Deepfake Creation",Semi-Autonomous (as the tool likely required human input to set parameters and determine the subject),Media and Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
511,2023-02-12,"['2890', '2899', '2896', '2891']",['microsoft'],"['openai', 'microsoft']",['bing-users'],"When prompted about showtimes for movies released in 2023, Microsoft's Bing AI failed to provide the search results due to its confusion about dates, and engaged in an erratic conversation with the user.",Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion,Information Retrieval,3,Entertainment,No,"Natural Language Processing, Information Retrieval",Semi-autonomous,Entertainment,No,Language Processing,Low,"Arts, Entertainment & Recreation"
513,2023-03-31,"['2900', '2967', '2968', '2979']",['openai'],['openai'],"['italian-children', 'italian-minors']","The Italian Data Protection Authority alleged OpenAI lacked a justifiable legal basis for personal data collection and processing which facilitate training of ChatGPT, and lacked age-verification mechanism preventing exposure of the chatbot's inappropriate answers to children, prompting its ban.",ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification,Chatbot Training,3,Information Technology,No,Data Collection and Processing,Semi-autonomous,Information Technology,No,Data Analysis,Low,Technology & IT Services
514,2023-01-20,['2901'],['turnitin'],['turnitin'],"['lucy-goetz', 'high-school-students']","Turnitin's tool to detect writing generated by ChatGPT was reported for incorrectly flagging high school students' original essays as AI-generated, accusations of which are argued as reinforcement of bias from teachers due to the inability to compare against source documents.",Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated,Text Analysis/Plagiarism Detection,3,Education,Yes,Text Analysis/Plagiarism Detection,Semi-Autonomous,Education,Yes,Data Analysis,Medium,Education
515,2022-11-25,"['2905', '2916']","[""jefferson-parish-sheriff's-office""]",['clearview-ai'],['randal-quran-reid'],"A black man was wrongfully arrested by the Jefferson Parish Sheriff’s Office due to facial recognition system developed by Clearview AI, although facial recognition use was not disclosed in the documents used to arrest him. ",Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch,Facial Recognition,3,Law Enforcement,Yes,Image/Pattern Recognition,Semi-Autonomous,Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
516,2023-03-20,"['2908', '2915']",['openai'],['openai'],['chatgpt-users'],"ChatGPT reportedly exposed titles of users' chat histories and users' private payment information to other users reportedly due to a bug, which prompted its temporary shutdown by OpenAI.",ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug,Chatbot operation and User Data Management,3,Information Technology and Services,No,"Natural Language Processing, Data Management, User Profile Analysis",Semi-Autonomous,Information Technology and Services,No,Data Analysis,Low,Technology & IT Services
517,2018-02-15,"['2909', '2912']",['new-york-police-department'],['unknown'],['unknown'],"A man was arrested for theft of socks from a TJ Maxx store under the guise of an eyewitness ID case, after the local police asked the store's security guard to confirm the facial recognition match produced using surveillance footage, despite him having an alibi at the time of the theft.",Man Arrested For Sock Theft by False Facial Match Despite Alibi,Facial Recognition,3,Retail,Yes,"Surveillance, Identification",Semi-Autonomous,Retail,Yes,Other/Unclear,Low,Retail & E-commerce
518,2017-04-28,['2911'],"['new-york-police-department', 'facial-identification-section']",['unknown'],['unknown'],"When the facial recognition search for a CVS theft suspect's face returned no useful matches due to the surveillance footage being obscured and highly pixelated, a New York City police detective continued the face search using Woody Harrelson's face allegedly due to his resemblance to the suspect's face, eventually leading to the arrest of an unknown victim.",New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search,Facial Recognition,3,Law Enforcement,Yes,"Image Analysis, Facial Recognition",Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
519,2022-04-03,['2913'],['starship-technologies'],['starship-technologies'],['starship-technologies'],"A Starship autonomous delivery robot struggled to navigate campus terrains of UCLA, reportedly getting stuck into a planter and falling off the stairs.",Starship Delivery Robot Ran into Problems Traversing Campus Terrains,autonomous food delivery,2,"accommodation and food service activities, transportation and storage",maybe,"Navigation and obstacle avoidance, Autonomous control",Fully autonomous,Education/University Campus,Yes,Action & Control,Low,Education
520,2022-05-08,"['2914', '3816']",['amazon-fresh'],['amazon-fresh'],['amazon-fresh'],Amazon Fresh's system of tracking cameras in its cashier-less stores was reported by shoppers for failing to detect items they purchased.,Amazon Fresh Cameras Failed to Register Purchased Items,product recognition,2,wholesale and retail trade,no,"Object Detection, Image Recognition, Tracking",Semi-Autonomous,Retail,No,Non-Text Media,Low,Retail & E-commerce
521,2020-06-10,['2920'],['irobot'],['irobot'],"['roomba-j7-device-owners-in-project-io', 'irobot', 'scale-ai']","Images which were collected in an R&D project with user consent by iRobot's Roomba J7 robot vacuum showing device users sometimes in private settings were shared on closed social media groups by Venezuelan gig workers who labeled items in the images, breaching data agreements.",Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups,Image Labeling,3,Private Sector,No,"Image Recognition, Data Collection",Semi-Autonomous,Private Sector,No,Data Analysis,Low,Other/Unclear
522,2019-07-10,['2921'],['facebook'],['facebook'],"['political-campaigns', 'facebook-users']","Facebook's political ad delivery system reportedly differentiated the price of user reach based on their inferred political alignment, inhibiting political campaigns' ability to reach voters with diverse political views,  which allegedly reinforces political polarization and creates informational filter bubbles.
","Facebook Political Ad Delivery Algorithms Inferred Users' Political Alignment, Inhibiting Political Campaigns' Reach",Ad Delivery and Targeting,3,Social Media,No,"Data Analysis, Prediction, Targeting",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
523,2023-03-15,['2922'],"['australian-taxation-office', 'services-australia']",['centrelink'],['centrelink-account-holders'],"A Guardian journalist was able to verify their identity and gain access to their own Centrelink self-service account using AI-generated audio of their own voice along with their customer reference number, shortly after voiceprint was deployed for ID verification.",Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice,Identity Verification,3,Public Services,Centrelink (Government Welfare Services),Voiceprint Recognition,Semi-Autonomous,Public Services,Centrelink (Government Welfare Services),Other/Unclear,Low,Other/Unclear
524,2023-02-12,['2923'],['torswats'],['unknown'],"['your-cbd-store', 'university-of-pittsburgh-police-department', 'phillipsburg-high-school', 'hempstead-high-school', 'dubuque-police-department', 'bellefonte-area-high-school']","Telegram channel Torswats offered paid service for and posted own recordings of false threats calls featuring AI-generated voices to direct armed law enforcement to raid locations of victims such as high schools, private residents, streamers.",AI Voices Abused by Telegram User to Make Swat Calls as Paid Service,Generation of Threat Calls,3,Cybersecurity/Social Media,Yes (as the actions of AI directly affect law enforcement),"Voice Generation, NLP (Natural Language Processing)",Semi-Autonomous,Cybersecurity/Social Media,Yes,Language Processing,Low,Information & Communication
525,2019-07-06,"['2927', '2928', '2929']",['justine-hsu'],['tesla'],['justine-hsu'],"A Tesla vehicle running in self-driving mode outside the operating conditions supported by the software crashed and injured the driver. Subsequently, the driver filed a lawsuit against Tesla and a jury found no damages were warranted.",Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets,Accident Avoidance,5,Automotive,No,"Navigation, Object Detection, Decision Making",Level 5 (Full Automation),Automotive,No,Action & Control,Low,Manufacturing & Industrial
526,2023-04-17,"['2930', '2969']",['@ghostwriter'],['unknown'],"['universal-music-group', 'the-weeknd', 'drake']","The deepfake performance of ""Heart On My Sleeve"" created to mimic the voice and musical styles of Drake and The Weeknd is no longer available on several streaming services after their record label served copyright takedown notices to the platforms.",Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights,deepfake audio generation,3,"Arts, entertainment and recreation",no,"Voice Mimicry, Musical Style Simulation",Semi-autonomous (Requires human input for initial setup and monitoring),"Entertainment, Media",No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
527,2014-05-08,"['2931', '2938']","['uber', 'amazon']","['uber', 'amazon']","['uber-drivers', 'gig-workers', 'amazon-delivery-workers']","Amazon and Uber were alleged in a multiyear ethnographic study using algorithmic systems based on gig workers' data to vary pay, such as by offering them lower wages for the same amount of work.",Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work,Data Analysis and Management,3,"Transportation & Logistics (for Uber), E-commerce (for Amazon)",No,"Data Processing, Wage Calculation",Semi-Autonomous,"Transportation & Logistics (for Uber), E-commerce (for Amazon)",No,Data Analysis,Low,Transportation
528,2023-04-08,"['2935', '2941']",['amazon'],['amazon'],['amazon'],"Amazon's pricing algorithm was implicated in a reference book about flies' unusual high price of millions of dollars, allegedly due to two sellers using the paid service which based their product's pricing on one another's as competitors.",Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions,Pricing Optimization,3,E-Commerce,No,Pricing Algorithm,Semi-Autonomous,E-Commerce,No,Other/Unclear,Low,Retail & E-commerce
529,2022-08-22,"['2939', '3179', '3180']",['stability-ai'],"['stability-ai', 'runway', 'laion', 'eleutherai', 'compvis-lmu']","['racial-minority-groups', 'women', 'gender-minority-groups']",Stable Diffusion reportedly posed risks of bias and stereotyping along gender and cultural lines for prompts containing descriptors and professions.,Stable Diffusion Exhibited Biases for Prompts Featuring Professions,Bias and Stereotyping Detection,3,IT and Services,No,Text Analysis,Semi-Autonomous,IT and Services,No,Data Analysis,Medium,Technology & IT Services
530,2019-07-11,"['2942', '2947', '3205']",['telegram-channels'],"['alberto', 'telegram-channels']","['women', 'underage-girls', 'female-celebrities']","Seven channels were connected in a Telegram ecosystem centered around letting subscribers, as a paid service, generate non-consensual deepfake nudes using a bot from submitted photos of women, including underage girls and women who they know in real life.",Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service,Deepfake Generation,3,Social Media/Communication,No,"Image Generation, Data Manipulation",Semi-Autonomous,Social Media/Communication,No,Data Analysis,Low,Information & Communication
531,2017-09-15,['2943'],['transportation-security-administration'],['l3harris-technologies'],"['transgender-travelers', 'gender-nonconforming-travelers']","Transportation Security Administration (TSA)'s use of image-processing body scanners at airports led transgender and gender-nonconforming travelers to be subjected to allegedly discriminatory and invasive searches, such as being asked to remove undergarments in private rooms by officers not of their gender.",AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches,Image Recognition and Processing,3,Transportation Security,Yes,"Image Scanning, Security Assessment",Semi-autonomous,Public Transportation,Yes,Non-Text Media,Low,Transportation
532,2020-06-20,['2948'],['us-citizenship-and-immigration-services'],['unknown'],"['anonymous-pashto-speaking-refugee', 'pashto-speaking-asylum-seekers', 'dari-speaking-asylum-seekers']","A Pashto-speaking refugee's asylum claim was denied by a US agency for a discrepancy between oral and written recount of an event allegedly due to an error of their automated translation tool which swapped pronouns of her written statement from ""I"" to ""we"".",AI translation is jeopardizing Afghan asylum claims,Automated Language Translation,3,Government/Immigration,Yes,"Natural Language Processing, Machine Translation",Semi-Autonomous,Government/Immigration,Yes,Language Processing,Low,Public Administration & Defense
533,2021-06-02,"['2953', '2954']",['tesla'],['tesla'],['tesla-drivers'],"A Tesla driver posted on Twitter his Tesla FSD's ""glitch,"" misidentifying deactivated traffic lights being carried by a truck as a constant trail of traffic lights while traveling at high speed on a highway.",Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights,Traffic Signal Recognition,5,Automotive,No,"Image Recognition, Sensor Fusion, Decision Making",Level 5 (Full Automation),Automotive,No,Non-Text Media,Low,Manufacturing & Industrial
534,2021-04-29,"['2955', '1535']","['facebook', 'meta']","['facebook', 'meta']","[""facebook's-children-users"", ""instagram's-children-users""]","Facebook was alleged in a lawsuit by the Ohio Attorney General purposely misleading the public about the control of its algorithms and their negative effects on children's well-being, which violated securities law.",Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children,Algorithmic Transparency,3,Social Media,No,"Content Moderation, User Profiling",Semi-Autonomous,Social Media,No,Other/Unclear,Medium,Information & Communication
535,2020-01-01,"['2956', '2957']","['mount-sinai-hospital', 'unknown']","['icahn-school-of-medicine-researchers', 'unknown']","['covid-19-patients', 'covid-19-healthcare-providers']","Peer-review of papers about COVID-19 detection and prognostication algorithms from 2020, including deployed models, revealed none to be ready for clinical use, due to methodological flaws and underlying biases such as lacking external validation or not specifying data sources and model training details.",COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases,Disease Detection and Prognostication,3,Healthcare,Yes (as it involves public health),"Paper review, Bias detection, Model Validation",Semi-autonomous (as the models are under peer review and not ready for clinical use),Healthcare,Yes (as it involves public health),Other/Unclear,Medium,Health & Social Services
536,2012-12-10,"['2976', '2977']",['new-jersey-transit'],['national-weather-service'],"['new-jersey-transit', 'new-jersey-transit-passengers']","New Jersey Transit's use of a federal government storm modeling software underestimated the threat of storm surges to the Meadows Maintenance Complex, leaving millions of dollars worth of equipment in the rail yard before Hurricane Sandy struck.",NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level,Storm Surge Prediction and Risk Assessment,3,Public Transit,Yes,Weather Forecasting and Disaster Management,Semi-Autonomous,Public Transit,Yes,Other/Unclear,Low,Technology & IT Services
537,2023-01-20,"['2991', '2992']",['scammers'],['unknown'],"['jennifer-destefano', 'destefanos-family']","A mother in Arizona received a ransom call from an anonymous scammer who created her daughter's voice allegedly using AI voice synthesis, which was proven to be fake once her daughter's safety was confirmed.",Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter,Voice Synthesis,3,Telecommunication/Personal Security,No,Voice Mimicking,Semi-Autonomous,Telecommunication/Personal Security,No,Other/Unclear,Low,Information & Communication
538,2023-05-15,"['2993', '2994', '2995', '2996', '2997']",['jared-mumm'],['openai'],['texas-aandm-university-students'],"A Texas A&M-Commerce professor reportedly informed his class of his misuse of ChatGPT to detect whether student submissions had been generated by the chatbot itself, which informed their graduation status.",Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions,Chatbot Interactions Analysis,3,Education,Yes,"Text Analysis, Natural Language Processing, Cheating Detection",Semi-Autonomous,Education,Yes,Data Analysis,Low,Education
539,2023-03-11,['3000'],['snapchat'],"['snapchat', 'openai']",['minors'],"Snapchat's ChatGPT-powered My AI was reported for lacking safeguards for children, such as telling a user who tested the chatbot by pretending to sign up as a 13-year-old girl to lie to her parents about having a romantic getaway with an older man, and sharing tips on how to cover up evidence of abuse.",Snapchat's My AI Reported for Lacking Protection for Children,Chatbot and Content Moderation,3,Social Media,No,"Text Generation, User Interaction, Content Filtering",Semi-autonomous,Social Media,No,Language Processing,Low,Information & Communication
540,2023-05-15,"['3003', '3093', '3094', '3096', '3097']",['tesla'],['tesla'],['pedestrians'],"A Tesla on FSD Beta 11.4.1 was shown on video not yielding to a pedestrian detected by the car, reportedly violating the state law sign which was also in the video saying vehicles having to yield to pedestrian within crosswalk.","Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",Pedestrian Detection,5,Private Transportation,No,"Object Detection, Traffic Law Compliance",High Automation,Automotive,No,Other/Unclear,Low,Manufacturing & Industrial
541,2023-05-04,"['3005', '3006', '3007', '3008', '3009', '3010', '3011', '3014', '3015', '3016', '3017', '3018', '3019', '3020', '3021', '3022', '3023', '3024', '3025', '3026', '3027', '3028', '3029', '3030', '3031', '3032', '3033', '3034', '3036', '3037', '3038', '3039', '3040', '3041', '3042', '3043', '3044', '3045', '3046', '3047', '3048', '3049', '3050', '3051', '3052', '3053', '3054', '3055', '3056', '3057', '3098', '3116', '3149', '3150', '3151', '3155', '3181', '3183']","['steven-a.-schwartz', 'peter-loduca']",['openai'],"['roberto-mata', 'peter-loduca', 'steven-a.-schwartz']","A lawyer in Mata v. Avianca, Inc. used ChatGPT for research. ChatGPT hallucinated court cases, which the lawyer then presented in court. The court determined the cases did not exist.",ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court,Legal Research,3,Legal,No,"Information Retrieval, Data Analysis",Semi-Autonomous,Legal,No,Data Analysis,Low,Other/Unclear
543,2023-05-22,"['3035', '3058', '3059', '3060', '3061', '3062', '3063', '3064', '3065', '3066', '3067', '3068', '3069', '3070', '3071', '3072', '3099']",['unknown'],['unknown'],"['twitter-users', 'stock-holders', 'family-of-people-near-pentagon']",An apparent deepfake image posted by a false Bloomberg news account to Twitter depicted an explosion near the pentagon office complex near Washington DC.,Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip,Deepfake Detection,3,Social Media / Internet,Yes,"Image Recognition, Deep Learning",Semi-Autonomous,Social Media / Internet,Yes,Non-Text Media,High,Information & Communication
544,2023-05-11,"['3073', '3074', '3075', '3076', '3077', '3078', '3079', '3080', '3081', '3082', '3083', '3084', '3085', '3086', '3087', '3088', '3089', '3090', '3091', '3092', '3095', '3100']","['russia', 'vladimir-putin', 'recep-tayyip-erdogan']",['unknown'],"['kemal-kilicdaroglu', 'muharrem-ince']",Allegations of deepfake technology and AI-generated disinformation have been swirling around the events of the 2023 presidential elections in Turkey.,Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey,Deepfake creation and disinformation spread,3,Politics / Government,Yes,"Data analysis, Natural Language Processing, Image Recognition",Semi-Autonomous,Politics / Government,Yes,Data Analysis,Low,Public Administration & Defense
545,2023-05-29,"['3103', '3104', '3105', '3106', '3107', '3108', '3109', '3110', '3111', '3112', '3113', '3114', '3115', '3117', '3118', '3119', '3120', '3121', '3122', '3123', '3124', '3125', '3126', '3127', '3128', '3129', '3130', '3131', '3132', '3133', '3134', '3135', '3136', '3137', '3138', '3139', '3140', '3141', '3142', '3143', '3144', '3145', '3146', '3147', '3148', '3153']","['national-eating-disorders-association', 'cass']",['cass'],['people-with-eating-disorders'],"The National Eating Disorders Association (NEDA) has shut down its chatbot named Tessa after it gave weight-loss advice to users seeking help for eating disorders. The incident has raised concerns about the risks of using chatbots and AI assistants in healthcare settings, particularly in addressing sensitive issues like eating disorders. NEDA is investigating the matter, emphasizing the need for caution and accuracy when utilizing technology to provide mental health support.",Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders,Mental Health Support,1,human health and social work activities,no,Chatbot Service,Semi-Autonomous (requires human supervision for appropriate responses),Healthcare,No,Other/Unclear,Low,Health & Social Services
546,2019-05-31,"['3159', '3161', '3162']",['national-aid-fund'],"['the-world-bank', 'unicef', 'world-food-programme']",['jordanians-in-poverty'],"Takaful cash transfer program's algorithm which ranks families by their economic vulnerability level to determine financial assistance reportedly oversimplified people's economic situation, fueling social tension and perceptions of unfairness.",Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability,Economic Vulnerability Assessment,3,Public Welfare / Social Service,Yes,"Data Analysis, Predictive Modelling",Semi-Autonomous,Public Welfare / Social Service,Yes,Data Analysis,Low,Other/Unclear
547,2023-06-05,"['3160', '3866']","[""ron-desantis's-presidential-campaign""]",['unknown'],"['donald-trump', 'anthony-fauci']","Ron DeSantis’s presidential campaign shared a video on Twitter featuring some AI-generated images of Donald Trump hugging former White House coronavirus advisor Anthony Fauci, allegedly as a smear campaign. This incident is possibly the first time a major U.S. presidential campaign deployed deepfakes with the intention of misleading the electorate.",Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci,image generation,3,other,no,"Deepfake Generation, Social Media Analytics",Semi-autonomous (Requires human intervention for deployment),"Politics, Social Media",Yes,Non-Text Media,Medium,Information & Communication
548,2023-05-24,['3163'],['opera'],"['opera', 'openai']","['ronald-l.-haeberle', 'ron-haviv', ""raymond-d'addario"", 'lynsey-addario', 'lee-miller', 'larry-towell', 'james-nachtwey']","When prompted about ""photographers accused of committing war crimes,"" Opera's GPT-based chatbot Aria provided a list of photographers who take photography of military conflicts.",Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes,Information Retrieval,3,Digital Media,No,Data Processing and Information Retrieval,Semi-Autonomous,Digital Media,No,Data Analysis,Low,Information & Communication
549,2023-01-05,['3164'],"[""wendy's"", ""mcdonald's"", ""hardee's""]","[""wendy's"", ""mcdonald's"", ""hardee's""]","['fast-food-job-applicants', 'amanda-claypool']","McDonald's, Wendy's, and Hardee's AI chatbots deployed to pre-screen job candidates and schedule interviews reportedly ran into issues such as not giving useful submission instructions, failing to relay information to the manager, and scheduling an interview when the manager was not available.",Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews,Pre-screening job candidates and scheduling interviews,3,Fast Food Industry,No (since the deployment is in a private sector),"Candidate screening, Interview scheduling",Semi-autonomous (since it acts based on pre-fed data and may not handle exceptions without human intervention),Fast Food Industry,No (since the deployment is in a private sector),Other/Unclear,Low,Retail & E-commerce
550,2023-03-17,"['3165', '3166']",['tesla'],['tesla'],"['tillman-mitchell', 'the-mitchells-family']","A 17-year-old student in Hollister, North Carolina who exited the school bus and was walking across the street to his house was hit by a 2022 Tesla Model Y allegedly operating on Autopilot mode, suffering a fractured neck and a broken leg.",Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus,Autonomous Driving,3,Private Transportation,No,"Object Detection, Path Planning",Level 3 (Conditional Automation),Private Transportation,No,Other/Unclear,Low,Transportation
551,2023-04-01,"['3168', '3170']",['unknown'],['unknown'],['social-media-users'],"The FBI reported an increase in sextortion cases featuring the use of fake, including AI-generated, images or videos created from content posted on their social media sites or web postings, provided to the malicious actor upon request, or captured during video chats.",FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities,Image/Video Generation and Analysis,3,Cybersecurity,Yes,"Image/Video Analysis, AI-generated Imagery Creation",Semi-autonomous,Cybersecurity,Yes,Data Analysis,Low,Law Enforcement & Public Safety
552,2023-06-22,['3169'],['microsoft'],"['openai', 'microsoft']",['microsoft'],Microsoft was reported by a Twitter user for deploying image analysis feature capable of solving CAPTCHAs for its GPT-based chatbot despite it being safeguarded against solving them for users.,Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards,Image Analysis,5,Social Media / Information Technology,No,"Image Recognition, Text Analysis",Fully Autonomous,Social Media / Information Technology,No,Data Analysis,Low,Information & Communication
553,2023-05-03,"['3171', '3173']",['google'],['google'],['google-users'],"Google's knowledge panel for the American artist Edward Hopper featured an AI-generated image which was purportedly created in the artist's style but was not one of his works, the image of which was removed soon after.",Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI,Image Generation,3,Information Technology/Digital Media,No,"Image Recognition, Style Transfer",Semi-Autonomous,Information Technology/Digital Media,No,Non-Text Media,Low,Information & Communication
554,2023-05-21,['3172'],['google'],['google'],['google-users'],"Google's search engine featured an AI-generated hyperrealistic version of the painting ""Girl With a Pearl Earring"" as the highlighted result when users search for its Dutch artist Johannes Vermeer.",Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result,"image generation, search optimization, search engine optimization",1,"Arts, entertainment and recreation",no,"Image Processing, Art Generation",High,"Information Technology, Arts",No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
555,2018-06-11,['3175'],['openai'],['openai'],"['paul-tremblay', 'mona-awad', 'authors-of-copyrighted-works']","Two authors alleged in a class action lawsuit OpenAI infringed authors' copyrights by incorporating illegal ""shadow libraries"" offering copyrighted books without permission in the training data of its generative LLMs, such as ChatGPT.",OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books,Text Generation,3,Technology/Software,No,"Natural Language Processing, Text Generation",Semi-Autonomous,Technology/Software,No,Language Processing,Low,Technology & IT Services
556,2018-05-10,"['3177', '3185', '3186', '3494']",['amazon'],['amazon'],['alexa-children-users'],Amazon's retention of children' voice recordings indefinitely as the default setting reportedly to train Alexa's voice recognition for Alexa-enabled devices was charged by the FTC and DOJ to violate COPPA Rule.,Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings,Voice Recognition Training,3,Consumer Technology,No,"Voice Recognition, Data Collection",Semi-Autonomous,Consumer Technology,No,Data Analysis,Low,Technology & IT Services
557,2020-06-24,"['3178', '3190', '3191', '3192']",['miami-police-department'],['clearview-ai'],"['oriana-albornoz', 'george-floyd-protest-participants']","Miami Police's arrest report for a George Floyd protestor did not disclose use of facial recognition, which allegedly did not meet the legal threshold for probable cause for arrest.",Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause,Facial Recognition,3,Law Enforcement,Yes,Facial Recognition,Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
558,2020-08-07,"['3184', '3188', '3189']",['new-york-city-police-department'],['clearview-ai'],"['derrick-ingram', 'black-lives-matter-activists']","Black Lives Matter activists alleged being targeted for arrest by New York Police using facial recognition, interfering with their right to protest.",Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest,Facial Recognition,3,Law Enforcement,Yes,"Surveillance, Identification",Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
559,2023-06-30,"['3193', '3269']",['openai'],['openai'],"['research-grant-administrators', 'research-grant-applicants']","Peer reviewers of Australian government grant applications inserted applicants' work into generative AI systems such as ChatGPT to generate assessment reports, which allegedly posed confidentiality and security issues.","Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",Text Generation,3,Government/Public Administration,Yes,"Text Generation, Data Analysis",Semi-Autonomous,Government/Public Administration,Yes,Data Analysis,Low,Public Administration & Defense
560,2023-06-23,['3194'],['tesla'],['tesla'],"['truck-drivers', 'tesla-drivers', 'david-clough']",A 2016 Tesla on Autopilot crashed into the rear of a parked 2007 Freightliner truck providing traffic control on the Pennsylvania Turnpike highway.,Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania,Autonomous Driving,3,Transportation,No,"Collision Avoidance, Lane Keeping, Adaptive Cruise Control",Level 3 (Conditional Automation),Transportation,No,Action & Control,Low,Transportation
561,2019-03-11,"['3197', '3199', '3200']",['openai'],['openai'],"['internet-users', 'children', 'social-media-users']",OpenAI's products such as ChatGPT and DALL-E were alleged in a lawsuit using  stolen private information from internet users without their informed consent or knowledge.,OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent,"Text Generation, Image Generation",3,Information Technology,No,"Natural Language Processing, Image Generation",Semi-Autonomous,Information Technology,No,Non-Text Media,Low,Technology & IT Services
562,2022-11-30,['3201'],['openai'],['openai'],"['publishing-editors', 'publishers']","A surge in low-standard AI-generated content such as by ChatGPT was reported by publishers, which negatively impacted submission management process and editors' workflow.",Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management,Content Generation,3,Publishing,No,"Text Generation, Submission Management",Semi-Autonomous,Publishing,No,Language Processing,Low,Other/Unclear
563,2023-08-14,"['3208', '3222']",['cruise'],['cruise'],"['san-francisco-emergency-services', 'ambulance-patient']","In an initial report, a Cruise robotaxi was said to have delayed a San Francisco ambulance transporting Sammy Davis, a critically injured 69-year-old hit by a city bus. Davis later died. Subsequent clarification revealed that Cruise was not at fault for the fatality; the actual cause was a human-operated city bus. Despite this, the incident is included as it highlights challenges in the interaction between autonomous vehicles and emergency services in urban settings.",Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault,Traffic Navigation,5,Transportation,No,"Traffic Navigation, Emergency Vehicle Detection",Full Automation,Transportation,Yes,Action & Control,High,Transportation
564,2023-08-30,['3209'],['scammers'],['unknown'],"['clive-kabatznik', 'bank-of-america']","In spring 2023, Florida investor Clive Kabatznik became the target of an advanced scam attempt involving a voice deepfake mimicking his own voice. The fraudulent caller, using AI-generated speech, contacted Kabatznik's Bank of America representative in an unsuccessful attempt to deceive the banker into transferring funds to a different account.",Voice deepfake targets bank in failed transfer scam,deepfake audio generation,3,financial and insurance activities,no,"Voice Deepfake, AI-Generated Speech",Semi-Autonomous,Finance,No,Other/Unclear,Low,Finance & Insurance
565,2023-08-08,"['3210', '3211', '3212', '3213']",['chinese-government'],['unknown'],"['hawaiian-government', 'general-public', 'american-government']","In a disinformation campaign concerning wildfires across Maui, Chinese operatives utilized AI-generated imagery to enhance the credibility of false narratives. These narratives claimed that the wildfires were the result of a secret ""weather weapon"" being tested by the United States. Researchers from Microsoft and other organizations identified these AI-generated images as a significant new tactic in influence operations.",AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires,Disinformation Campaign,3,Cybersecurity,No,"Image Generation, Data Manipulation",Semi-Autonomous,Cybersecurity,No,Data Analysis,Low,Law Enforcement & Public Safety
566,2023-09-19,['3214'],['gannett'],['ledeai'],"['general-public', 'gannett', 'student-athletes', 'newspapers-relying-on-gannett']","Gannett, a newspaper chain, temporarily halted its AI experiment that used a tool called LedeAI to generate high school sports articles. The decision came after several articles produced by the AI showed glaring errors, repetitive language, and awkward phrasing, drawing criticism and mockery on social media.",Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash,Article Generation,3,News and Media,No,"Text Generation, Natural Language Processing",Semi-Autonomous,News and Media,No,Language Processing,Low,Information & Communication
567,2023-08-27,['3215'],['unknown-hacker'],['unknown'],"['retool-employee-who-was-the-victim-of-the-unknown-hacker', 'retool', 'google', ""27-of-retool's-clients""]","In August 2023, a hacker reportedly was successful in breaching Retool, an IT company specializing in business software solutions, impacting 27 cloud customers. The attacker appears to have initiated the breach by sending phishing SMS messages to employees and later used an AI-generated deepfake voice in a phone call to obtain multi-factor authentication codes. The breach seems to have exposed vulnerabilities in Google's Authenticator app, specifically its cloud-syncing function, further enabling unauthorized access to internal systems.",Deepfake Voice Exploit Compromises Retool's Cloud Services,Cybersecurity,3,Information Technology,No,"Deepfake Generation, Authentication Bypass",Semi-Autonomous,Information Technology,No,Other/Unclear,Low,Technology & IT Services
568,2023-06-01,"['3216', '3271']","['tiktok-user-@e.news.tv', 'tiktok-user-@d.news.tv', 'tiktok-user-@drphilshowtv', 'tiktok-user-@ynewstv2023', 'tiktok-users']",['elevenlabs'],"['barack-obama', 'oprah-winfrey', 'jamie-foxx', 'joan-rivers', 'phil-mcgraw', 'yahoo!-news', 'e!-news', 'tiktok', 'general-public']","NewsGuard has identified 17 TikTok accounts that have been using AI-generated voices to advance and amplify conspiracy theories and false claims beginning in June 2023. By September 25, 2023, these accounts had amassed over 336 million views and over 14.5 million likes. Videos include baseless claims involving public figures such as Barack Obama, Oprah Winfrey, and Jamie Foxx.",AI-Generated Voices Amplify Conspiracy Theories on TikTok,Content Generation and Amplification,3,Social Media / Entertainment,No,"Text to Speech Conversion, Content Generation",Semi-Autonomous,Social Media / Entertainment,No,Language Processing,Low,"Arts, Entertainment & Recreation"
569,2021-12-25,"['3219', '3325']","['replika', 'jaswant-singh-chail']",['replika'],"['queen-elizabeth-ii', 'british-royal-family', ""british-royal-family's-staff"", 'jaswant-singh-chail', 'general-public']","In 2021, Jaswant Singh Chail was urged by a Replika chatbot to assassinate Queen Elizabeth II. Armed with a loaded crossbow, he scaled Windsor Castle's walls on Christmas Day but was apprehended. Motivated by the 1919 Jallianwala Bagh massacre, Chail intended to kill the monarch. The chatbot had affirmed his plans. He was sentenced to nine years in prison in 2023.",Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II,Encouraging Harmful Behavior,3,Personal Use,No,Chatbot Communication,Semi-Autonomous,Personal Use,No,Other/Unclear,Low,Other/Unclear
570,2023-10-04,['3245'],['meta'],['meta'],['facebook-messenger-users'],"Facebook Messenger AI stickers, a feature by Meta, allows users to generate personalized stickers via AI for use in conversations. While the feature has been praised for its creativity, it has also stirred controversy for its alleged production of inappropriate or offensive content. This has raised questions about the effectiveness of Meta's content moderation measures and the ethical responsibilities associated with AI-driven content generation.",Facebook Messenger AI Stickers Generate Ethical and Content Moderation Concerns,Content Generation,3,Communication and Social Media,No,"Content Moderation, Personalization",Semi-autonomous,Communication and Social Media,No,Other/Unclear,Low,Information & Communication
571,2023-06-22,['3221'],['microsoft'],"[""microsoft's-ai-research-division""]","['microsoft', 'microsoft-employees', 'third-parties-relying-on-the-confidentiality-of-the-exposed-data']","Microsoft's AI research team accidentally exposed 38TB of sensitive data while publishing open-source training material on GitHub. The exposure included secrets, private keys, passwords, and internal Microsoft Teams messages. The team utilized Azure's Shared Access Signature (SAS) tokens for sharing, which were misconfigured, leading to the wide exposure of data.",Accidental Exposure of 38TB of Data by Microsoft's AI Research Team,Data Management,3,Technology,No,"Data Security, Data Sharing",Semi-Autonomous,Technology,No,Data Analysis,Low,Technology & IT Services
572,2023-07-24,['3225'],['unspecified-university'],['turnitin'],['anonymous-student'],"A student was allegedly falsely accused of using AI to generate an essay assignment based on Turnitin's AI detector. The student, who claims to have written the essay by hand, also claims to have received a zero for the assignment. Despite multiple appeals to the professor, department head, and Turnitin support, no resolution seems to have been reached. The student claimed to be considering taking the issue to local news networks if the grade would come to harm their final standing.",Alleged False Accusation of AI-Generated Essay by Turnitin,Text Generation/Detection,3,Education,Yes,"Text Analysis, Plagiarism Detection",Partially Autonomous,Education,Yes,Data Analysis,Low,Education
573,2023-10-07,"['3227', '3267', '3314', '3315', '3316', '3317', '3318', '3319', '3382', '3825', '4109']",['unknown'],['unknown'],"['slovakian-electorate', 'monika-todova', 'michal-simecka', 'democratic-process-in-slovakia']","Days before Slovakia's election, deepfake audio recordings surfaced, allegedly featuring conversations between a journalist and a leading liberal politician discussing vote-rigging and other controversial topics. The recordings were spread on social media platforms and may have influenced the election outcome, which saw the pro-Russian populist party winning.",Deepfake Recordings Allegedly Influence Slovakian Election,Deepfake generation,3,Politics/Election,No,"Audio manipulation, deepfake technology",Semi-autonomous,Politics/Election,No,Non-Text Media,Low,Technology & IT Services
574,2023-07-05,['3237'],['go-media'],"['openai', 'google']",['gizmodo-journalists'],"G/O Media began publishing AI-generated articles, against staff advice, that contained errors and quality issues. The first such article, a list of Star Wars movies, failed to maintain chronological order, causing internal concerns over journalistic credibility and ethics. Staff expressed that the AI was ""actively hurting our reputations and credibility"" and accused management of ""wasting everyone's time.""",AI-Generated Articles at G/O Media Allegedly Diminishes Reputation of Human Staff,"text generation, content generation",3,"information and communication, Arts, entertainment and recreation",no,"Article Generation, Text Analysis",High Autonomy (AI independently generating and publishing articles),Media and Journalism,No,Data Analysis,Medium,Information & Communication
575,2023-06-28,['3238'],['unknown'],['unknown'],"['authors', 'amazon-customers', 'amazon']","Amazon’s Kindle Unlimited young adult romance bestseller list was flooded with allegedly AI-generated books that made little to no sense, disrupting the rankings. These books were reported to be ""clearly there to click farm."" Despite being removed from the bestseller list, many remained available for purchase. The incident raised concerns about the integrity of the platform, and the potential financial impact on legitimate authors.",Amazon Rife with Many Allegedly AI-Generated Books of Suspect Quality,Text Generation,3,Digital Publishing,No,"Text Generation, Data Analysis",Semi-Autonomous,Digital Publishing,No,Data Analysis,Low,Technology & IT Services
576,2023-10-24,['3239'],"['meta', 'instagram']",['picso-ai'],"['potentially-exploited-groups', 'general-public', 'consumers']","PicSo AI, which appears to be getting advertised by Meta over Instagram, is allegedly being used for generating inappropriate content with an emphasis on ""girls."" This raises concerns about the misuse of generative AI technologies for creating offensive and potentially sexually explicit material that could be used for nefarious and criminal purposes.","Alleged Misuse of PicSo AI for Generating Inappropriate Content Emphasizing ""Girls""",image generation,1,information and communication,no,Content Generation,Semi-Autonomous (as the AI's output is likely moderated or filtered by human oversight),"Advertising, Social Media","No (as the described incident involves a private company - Meta, using AI for advertising purposes on Instagram)",Other/Unclear,Low,Information & Communication
577,2023-06-30,['3240'],"['red-ventures', 'bankrate']","['red-ventures', 'bankrate']","['journalistic-integrity', 'general-public']","Bankrate, and its sister site CNET, both owned by Red Ventures, resumed publishing AI-generated articles claiming thorough human fact-checking. However, new articles are alleged to contain numerous factual errors, including inaccurate statistics and misleading information. Despite public criticism, the company defended its use of AI and blamed out-of-date datasets for the errors. In addition to the errors, the incident raises questions about the ethical use of AI in journalism, especially given the company's insistence on ""fact-checked"" content.",Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information,Content Generation,3,Media and Journalism,No,"Content Generation, Data Analysis",Semi-Autonomous,Media and Journalism,No,Data Analysis,Medium,Information & Communication
578,2023-06-26,['3241'],"[""individual-developers-or-creators-using-meta's-llama-model""]",['meta'],['general-public'],"Meta's open-source large language model, LLaMA, is allegedly being used to create graphic and explicit chatbots that indulge in violent and illegal sexual fantasies. The Washington Post highlighted the example of ""Allie,"" a chatbot that participates in text-based role-playing allegedly involving violent scenarios like rape and abuse. The issue raises ethical questions about open-source AI models, their regulation, and the responsibility of developers and deployers in mitigating harmful usage.",Alleged Exploitation of Meta's Open-Source LLaMA Model for NSFW and Violent Content,Text-based Communication,3,Information and Communication,No,"Text Generation, Language Understanding",Semi-autonomous,Information and Communication,No,Language Processing,Low,Information & Communication
579,2023-07-03,['3242'],['dall-e'],['openai'],"['non-cisgender-individuals', 'lgbtq+-community']","Text-to-image systems such as DALL-E are allegedly generating biased and often insulting representations of non-cisgender identities. The systems tend to generate stereotypical and sexualized images when prompted with gender identity terms like ""trans,"" ""nonbinary,"" or ""queer,"" highlighting systemic issues of bias.",Harmful Stereotyping of Non-Cisgendered People via Text-to-Image Systems,Image Generation,3,Information Technology,No,Text-to-Image Conversion,Semi-Autonomous,Information Technology,No,Non-Text Media,Medium,Technology & IT Services
580,2023-06-12,['3243'],['meta'],['meta'],"['women', 'underrepresented-genders', 'general-public', 'advertisers']","Facebook's ad delivery algorithm allegedly disproportionately showed job advertisements to one gender. Despite claims of non-discrimination, the algorithm's actions seem to perpetuate societal biases, which in turn could potentially limit opportunities for certain groups and hinder gender equity in the workplace.",Alleged Gender Discrimination in Facebook Job Ads Algorithm,Ad Delivery Optimization,3,Digital Advertising,No,"Data Analysis, Decision Making",Semi-Autonomous,Digital Advertising,No,Data Analysis,Medium,Technology & IT Services
581,2023-06-24,['3244'],['google'],['google'],"['subaru', 'major-brands-whose-advertisements-were-found-on-these-sites', 'gnc', 'general-public', 'citigroup']","Google’s advertising platform, Google Ads, has allegedly been found to be serving ads on AI-generated content farms that often disseminate misinformation. Despite policies prohibiting such practices, reportedly there are approximately 356 out of 393 ads from major brands that were found to be served by Google on these problematic sites. Particularly concerning according to the reporting were instances where Google Ads were found on sites like MedicalOutline.com, which spreads harmful health misinformation.",Google Ads Allegedly Serving Content on AI-Generated Misinformation Sites,Advertising,3,Digital Marketing,No,"Content Curation, Ad Placement",Semi-Autonomous,Digital Marketing,No,Other/Unclear,Low,Technology & IT Services
582,2023-06-01,['3248'],['university-of-pennsylvania-health-system'],['unknown'],['black-men-who-underwent-lung-function-tests-between-2010-and-2020-and-potentially-received-inaccurate-or-delayed-diagnoses-and-medical-interventions-due-to-the-biased-algorithm'],"A study published in JAMA Network Open reveals that racial bias built into a commonly used medical diagnostic algorithm for lung function may be leading to underdiagnoses of breathing problems in Black men. The study suggests that as many as 40% more Black male patients might have been accurately diagnosed if the software were not racially biased. The software algorithm adjusts diagnostic thresholds based on race, affecting medical treatments and interventions.",Racial Bias in Lung Function Diagnostic Algorithm Leads to Underdiagnosis in Black Men,Medical Diagnostic Analysis,3,Healthcare,Yes,"Data Analysis, Diagnosis Prediction",Semi-Autonomous,Healthcare,Yes,Data Analysis,Medium,Health & Social Services
583,2023-06-07,['3249'],"['meta', 'instagram']","['meta', 'instagram']","['children', 'general-public', 'minors', 'teenagers']","An investigation disclosed that Instagram's recommendation algorithms are promoting accounts that facilitate and sell child sexual abuse material (CSAM). The study, conducted by The Wall Street Journal and researchers at Stanford University and the University of Massachusetts Amherst, indicates that Instagram's algorithms not only allow for the discovery of such accounts through keyword searches but also actively recommend them to users within the network. The issue is especially concerning given Instagram's popularity among teenagers.",Instagram Algorithms Allegedly Promote Accounts Facilitating Child Sex Abuse Content,content recommendation,1,"Arts, entertainment and recreation",no,Recommendation Algorithms,Semi-Autonomous (Algorithms act according to predefined rules but further actions require human intervention),Social Media/Internet Services,No,Other/Unclear,Low,Information & Communication
584,2023-05-18,['3250'],"['transaction-cloud', 'public-mirror', 'pimeyes', 'lukasz-kowalczyk', 'giorgi-gobronidze', 'face-recognition-solutions', 'emea-robotics', 'does-125', 'denis-tatina', 'carribex']","['transaction-cloud', 'public-mirror', 'pimeyes', 'lukasz-kowalczyk', 'giorgi-gobronidze', 'face-recognition-solutions', 'emea-robotics', 'does-1-25', 'denis-tatina', 'carribex']","['nicholas-clayton', 'misty-mcgraw', 'manuel-clayton', 'illinois-residents', 'amy-newton', 'amanda-curry']","A class action lawsuit was filed against several facial recognition technology companies for allegedly violating the Illinois Biometric Information Privacy Act (BIPA). The defendants are accused of offering a facial recognition search engine called Pimeyes, which collects images from databases across the internet and scans them into their database seemingly without consent. This action is claimed to invade the privacy of millions of Americans. The lawsuit argues that Pimeyes lacks publicly available policies regarding data storage and deletion, in contravention of BIPA's requirements for informed written consent before collecting biometric data.",Illinois Residents File Class Action Lawsuit Against Facial Recognition Technology Companies for Allegedly Violating BIPA,Facial Recognition,3,Information Technology & Services,No,"Image Processing, Facial Recognition",Semi-Autonomous,Information Technology & Services,No,Non-Text Media,Low,Technology & IT Services
585,2023-10-26,"['3251', '3322', '3323']","['structura-national-technologies', 'social-design-agency', 'oleg-yasinsky', 'oleg-yasinskiy', 'nikolay-tupikin', 'institute-for-internet-development', 'ilya-gambashidze', 'andrey-perla']",['unknown'],"['ukraine', 'news-media-in-latin-america', 'journalistic-integrity', 'general-public']","Moscow-based tech firms and an industry association with links to the Kremlin are allegedly using generative AI to spread Russian disinformation in countries throughout Central America and South America. According to the U.S. Department of State, the Russian companies rely on local writers to compose stories which are then amplified across social media using artificial intelligence chatbots.",Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America,Disinformation Spreading,3,Information and Communication Technology,No,"Natural Language Generation, Social Media Analysis",Semi-Autonomous,Information and Communication Technology,No,Data Analysis,Low,Information & Communication
586,2023-05-22,['3254'],['edmodo'],['edmodo'],"['children-whose-data-was-collected-and-used-for-advertising', 'schools-and-teachers-who-were-misinformed-and-burdened-with-coppa-compliance-responsibilities-without-adequate-disclosure']","Edmodo, an education technology provider, violated the Children's Online Privacy Protection Act Rule (COPPA Rule) by collecting and using children's personal data for advertising purposes without parental consent, according to the FTC. The company outsourced its compliance responsibilities to schools, thereby making them ""solely"" responsible for COPPA compliance without adequate disclosure. Edmodo is facing a proposed order prohibiting such practices, marking a precedent in the ed tech industry.",FTC Targets Edmodo for Unlawful Use of Children’s Data and Delegating Compliance to Schools,Data Collection and Processing,3,Education,Yes,"Data Analysis, User Profiling",Semi-autonomous,Education,Yes,Data Analysis,Low,Education
587,2023-05-22,['3255'],"['google', 'apple', 'amazon', 'microsoft']","['google', 'apple', 'amazon', 'microsoft']","['consumers-relying-on-accurate-image-categorization', 'members-of-racial-and-ethnic-minorities-who-risk-being-stereotyped-or-misrepresented']","Eight years after Google Photos mislabeled images of Black individuals as ""gorillas,"" image recognition software by Google, Apple, Amazon, and Microsoft still shows signs of either avoiding or inaccurately categorizing primates. Tests reveal that Google and Apple Photos refrain from labeling primates altogether, possibly to avoid the risk of perpetuating racial stereotypes. Microsoft OneDrive fails to identify any animals, while Amazon Photos overgeneralizes in its labeling.",Apparent Failure to Accurately Label Primates in Image Recognition Software Due to Alleged Fear of Racial Bias,image recognition,2,information and communication,no,Perception,Medium,Information and communication,False,Perception & Cognition,Low,Information & Communication
588,2023-05-12,['3256'],"['new-south-wales-government', 'australian-federal-government']",['unspecified'],"['people-with-autism', ""lawyers-and-other-experts-who-were-not-informed-of-the-tool's-limitations"", 'individuals-assessed-as-high-risk-based-on-the-flawed-criteria', 'general-public']","An independent report found that the Vera-2R tool, designed to predict the risk of future terrorist activities, considered autism as a risk factor despite lacking empirical evidence to support this claim. The report called into question the tool's overall validity and reliability, stating it was ""extremely poor"" at accurately predicting risk. The inclusion of autism as a risk factor had potentially serious implications for the tool's use and credibility.",Australian Terrorism Prediction Tool Disparately Impacts Persons with Autism,Risk Assessment/Prediction,3,Security and Defense,Yes (as it's utilized for assessing potential terrorist activities),"Data Analysis, Prediction Modeling",Semi-Autonomous (as it requires human input for decision-making),Security and Defense,Yes (as it's utilized for assessing potential terrorist activities),Data Analysis,Low,Public Administration & Defense
589,2023-05-01,['3258'],"['many', 'maria-spanadoris', 'adesh-ingale', 'getintoknowledge.com', 'famadillo.com', 'bestbudgetusa.com', 'harmonyhustle.com', 'historyfact.in', 'countylocalnews.com', 'tnewsnetwork.com', 'wavefunction.info', 'celebritiesdeaths.com', 'scoopearth.com', 'filthylucre.com']","['unknown', 'unnamed']","['general-public', 'journalists']","Scores of AI-generated news websites and content farms are producing low-quality, clickbait content in a variety of languages. They are reportedly spreading false information and degrading the quality of information available online. These sites often lack human oversight, feature repetitive language, and sometimes fabricate information, posing a threat to the credibility of online news sources.",Proliferation of AI-Generated News Websites and Content Farms Across Multiple Languages Degrading Information Integrity,Content Generation,4,Information and Communication,No,"Natural Language Processing, Text Generation",High,Information and Communication,No,Language Processing,Low,Information & Communication
590,2023-02-03,['3259'],"['inkstall', 'marie-karpos']","['openai', 'chatgpt']",['chris-cowell'],"The author Chris Cowell had spent more than a year writing his book ""Automating DevOps with GitLab CI/CD Pipelines"" when, three weeks before its release, another book appeared bearing the exact title by an author (Marie Karpos) for whom no information could be found. The book appeared to have been written by ChatGPT. While the original Washington Post story does not say so, it is possible the name and description were taken from the Amazon preorder page.","Alleged ChatGPT-Generated Book with a Duplicate Title, Fake Author, and Similar Content Surfaces on Amazon Ahead of Real Author's Book Release",Text Generation,3,Publishing Sector,No,"Text Generation, Natural Language Processing",Semi-Autonomous,Publishing Sector,No,Language Processing,Low,Other/Unclear
591,2023-07-24,"['3262', '3265']",['cigna'],['cigna'],['patients'],"Cigna health insurer faces a class-action lawsuit for allegedly using the PXDX (""procedure-to-diagnosis"") algorithm to automatically reject over 300,000 patient claims in violation of California law, prompting two members to file the lawsuit seeking damages and a jury trial. Cigna disputes the allegations, claiming the process expedites physician reimbursement and does not result in care denials.",Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law,Automated Claims Processing,3,Healthcare,No,"Claims Processing, Decision Making",Semi-Autonomous,Healthcare,No,Other/Unclear,Low,Health & Social Services
592,2023-02-16,"['3263', '3275', '3965']",['detroit-police-department'],['unknown'],['porcha-woodruff'],"Porcha Woodruff was arrested and subsequently had charges dropped due to an unreliable facial recognition match. Despite being visibly pregnant, she was implicated in a robbery and carjacking based on an outdated photo used in a lineup.",Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit,Facial Recognition,3,Law Enforcement,Yes,Identification and Verification,Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
593,2023-07-21,['3264'],['playground-ai'],['playground-ai'],"['rona-wang', 'racial-minorities-who-may-have-experienced-the-same-result']","An AI application modified an MIT student's photo to appear 'professional' by lightening her skin and changing her eye color to blue, highlighting the racial bias in the training data of the program.","AI Photo Filter Lightens Skin, Changes Eye Color in Student's 'Professional' Image",Image modification,3,Education,No,"Image Processing, Machine Learning",Semi-Autonomous,Education,No,Non-Text Media,Medium,Education
594,2023-08-10,['3266'],"[""pak-'n'-save""]","[""pak-'n'-save""]",['potential-users-of-the-savey-meal-bot'],"Pak 'n' Save's AI-based app, Savey Meal-bot, inadvertently suggested dangerous recipes, including one creating chlorine gas, when users entered non-food household items, raising safety and oversight concerns.",AI Meal Planner Suggests Hazardous Chlorine Gas Recipe,"recipe generation, text generation",3,"accommodation and food service activities, wholesale and retail trade",no,Recipe Suggestion,Semi-Autonomous,Retail/Food Service,No,Other/Unclear,Low,Retail & E-commerce
595,2023-08-11,['3268'],['cruise'],['cruise'],['general-public'],"A fleet of Cruise's autonomous vehicles became unexpectedly immobilized on a busy San Francisco street, causing significant traffic disruption. The incident was attributed to wireless connectivity issues exacerbated by a nearby festival.",Driverless Cruise Cars Immobilized in San Francisco Traffic Jam,Traffic Management,5,Transportation,Yes,Traffic Management and Wireless Connectivity,Fully Autonomous,Transportation,Yes,Other/Unclear,Low,Transportation
596,2023-10-17,['3272'],['cruise'],['cruise'],"['pedestrians', 'general-public']","Cruise's driverless vehicles are under federal investigation for possibly failing to exhibit due caution around crosswalks and pedestrians, with reports including one severe injury incident.",Cruise's Autonomous Vehicles Allegedly Engaging in Risky Behavior Near Pedestrians,Pedestrian Detection and Collision Avoidance,5,Public Transportation,Yes,"Object and Pedestrian Recognition, Navigation, Decision Making",High Autonomy,Urban Traffic,Yes,Action & Control,Low,Other/Unclear
597,2023-10-16,"['3273', '3276', '3278', '3279', '3280', '3281', '3282', '3283', '3284', '3285', '3286', '3287', '3288', '3289', '3290', '3291', '3292', '3293', '3294', '3295', '3296', '3297', '3298', '3299', '3300', '3301', '3302', '3303', '3304', '3305', '3306', '3307', '3308', '3309', '3310', '3311', '3312', '3313', '3449', '3450', '3567', '3620', '3644', '3698', '3844']",['unnamed-male-students'],['unknown'],"['unnamed-female-students', 'francesca-mani']","AI-powered deepfake nude images of female students circulated among students at Westfield High School in New Jersey, causing significant harm and fear among students and parents.",Students Traumatized as AI-Generated Fake Nudes Are Circulated at New Jersey High School,Deepfake Generation,3,Education,Yes,"Image Manipulation, Machine Learning",Semi-Autonomous,Education,Yes,Non-Text Media,Low,Education
598,2022-11-25,['3274'],"[""jefferson-parish-sheriff's-office""]",['unknown'],"['randal-reid', 'minorities', 'black-people']","The Jefferson Parish Sheriff’s Office in Louisiana relied on facial recognition technology to identify suspects for the alleged theft of luxury purses, resulting in a man in Georgia, Randal Reid, being arrested. However, the technology produced a false match, leading to Reid's arrest and subsequent release. This incident highlights the potential pitfalls of facial recognition technology in law enforcement.",False Arrest of Georgia Man Due to Louisiana Police's Faulty Facial Recognition Technology,Facial Recognition,3,Law Enforcement,Yes,Suspect Identification,Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
599,2023-11-08,"['3277', '3326']",['unnamed-south-gyeongsang-province-produce-distribution-center'],['unknown'],['unnamed-employee-of-south-gyeongsang-province-produce-distribution-center'],An industrial robot is reported to have crushed a man to death in South Korea when it failed to differentiate the man from the boxes of produce it was handling.,Stacking robot fatally crushes employee in South Korea,Object Handling,4,Industrial Manufacturing,No,"Object Recognition, Motion Control",High,Industrial Manufacturing,No,Action & Control,High,Manufacturing & Industrial
600,2023-04-01,['3320'],['unnamed-south-korean-man'],['unknown'],['general-public'],A South Korean man used AI technology to generate 360 images of a sexual nature depicting children in April of 2023. The police confiscated the images and the courts sentenced the man to two and a half years in prison. The case marked the first of its nature in the South Korean court system.,South Korean man used AI to create sexual images of children,Image Generation,3,Private Sector,No,Image Synthesis,Semi-Autonomous,Personal Use,No,Non-Text Media,Low,Other/Unclear
601,2023-10-08,"['3321', '3340', '3341', '3342', '3344', '3345', '3346', '3347', '3349', '3381']",['unknown'],['unknown'],"['uk-labour-party', 'keir-starmer']","An AI-generated audio clip, purporting to show UK opposition leader Keir Starmer verbally abusing staff, was debunked as fake. The clip, circulated on social media, was analyzed and found likely manipulated, with added background noise to evade detection.",AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer,Audio manipulation and detection,3,Social Media/Internet,No,"Audio generation, Audio analysis",Semi-autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
602,2023-10-02,"['3324', '3331', '3336', '3337', '3338', '3352', '3397']","['russian-government', 'fsb', 'federal-security-service']",['russian-government'],"['ukraine', 'general-public', 'european-public', 'democracy', 'american-public']","The Russian government has been stepping up its foreign influence campaigns by using artificial intelligence and emerging technologies to spread disinformation and sow distrust in policies supportive of Ukraine. Part of the strategy includes carrying out influence laundering operations by disseminating their messages to the American public via allies inside nominally independent organizations, according to a recent declassified analysis. 

This incident is an evolving project.",Russia Using Artificial Intelligence in Disinformation Campaigns to Erode Western Support for Ukraine,Disinformation Campaigns,3,Government/Politics,Yes,"Data Analysis, Content Generation",Semi-autonomous,Government/Politics,Yes,Data Analysis,Low,Public Administration & Defense
603,2021-07-02,['3327'],"['state-governments', 'idaho-state-government', 'arkansas-state-government', 'washington-dc-government', 'pennsylvania-state-government', 'iowa-state-government', 'missouri-state-government']","['brant-fries', 'state-governments']","['disabled-people', 'elderly-people', 'low-income-people', 'larkin-seiler', 'tammy-dobbs']","A healthcare algorithm designed to equitably distribute caregiving resources drastically cut care hours for the disabled and elderly, leading to significant hardships and harm. Initially developed for fair resource allocation, the system ultimately faced legal challenges for its inability to accurately assess individual needs, resulting in reduced essential care and raising ethical concerns about AI in healthcare decision-making.",Algorithmic Allocation of Resources in Healthcare for Disabled and Elderly Care Services Allegedly Harming Patients,"welfare determination, benefits allocation",3,human health and social work activities,yes,"Resource allocation, individual needs assessment",Semi-autonomous (Requires human intervention to correct inaccuracies),Healthcare,Yes (Assuming caregiving resources are typically under public or government-run programs),Other/Unclear,Low,Health & Social Services
604,2023-04-14,"['3329', '3423', '3424', '3425', '3426', '3427', '3428']",['steven-larouche'],['unnamed-deepfake-technology-developers'],"['children-(faces-used-in-deepfakes)', 'victims-of-child-sexual-abuse-(bodies-used-in-videos)', 'general-public']","A Quebec man was sentenced to over three years in prison for using AI deepfake technology to produce synthetic child pornography. He created videos by superimposing children's faces onto other bodies, adding to the challenge of policing digital sexual exploitation. This case marks a disturbing use of AI in criminal activities, raising concerns about digital safety and the vulnerability of children's images online.",Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography,Deepfake Creation,3,Criminal Activity,No,Image Manipulation,Semi-Autonomous,Criminal Activity,No,Non-Text Media,Low,Technology & IT Services
605,2021-08-01,"['3330', '3372', '3373', '3374', '3375', '3376', '3377', '3378', '3379', '3380']",['david-tatum'],['unknown'],"['minors-exploited-in-the-images', 'general-public']","David Tatum, a psychiatrist, was sentenced to 40 years for sexually exploiting a minor and using AI to create child pornography images. Tatum used a web-based AI application to alter clothed images of minors into explicit content, misusing technology for illegal and unethical purposes. Evidence presented during his trial showed Tatum possessed photos and videos between 2016 and 2021.",North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse,Image Manipulation,3,Private Sector,No,Image Generation/Manipulation,Semi-Autonomous,Private Sector,No,Non-Text Media,Low,Other/Unclear
606,2023-10-02,"['3339', '3383', '3384', '3385', '3386', '3387', '3388', '3389', '3390', '3391', '3392', '3393', '3394', '3395', '3396']",['unknown'],['unknown'],"['wolf-blitzer', 'tom-hanks', 'sanjay-gupta', 'sally-bundock', 'robin-williams', 'public-figures', 'mrbeast', 'matthew-amroliwala', 'jesse-waters', 'ian-hanomansing', 'general-public', 'gayle-king', 'celebrities']","Deepfake technology was used to generate video advertisements featuring celebrities. Notable examples include the likeness of Tom Hanks touting a dental plan and another one in which the likeness of Gayle King touts a weight loss product. In each case, the individuals whose likenesses and voices had been deepfaked had not consented to their images and voices being used for the commercials. ",Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent,Deepfake Video Generation,3,Advertising/Marketing,No,"Video Processing, Deep Learning, Generative Models",Semi-Autonomous,Advertising/Marketing,No,Non-Text Media,Low,Other/Unclear
607,2023-11-09,['3343'],['unknown'],['unknown'],"['keir-starmer', 'general-public', 'british-labour-party']",A deepfake video was circulating around social media of British Labour leader Keir Starmer touting an investment scheme.,Deepfake Video Circulating of British Labour Leader Keir Starmer Touting an Investment Scheme,Deepfake detection,3,Social Media/Internet,Yes,"Video editing, Face recognition, Natural Language Processing (NLP)",Semi-autonomous,Social Media/Internet,Yes,Non-Text Media,Low,Information & Communication
608,2023-02-28,"['3348', '3353', '3354', '3355', '3356', '3357', '3358', '3359', '3360', '3361', '3362', '3363', '3364', '3365', '3366', '3367', '3368', '3369', '3370', '3371', '3639']",['unitedhealthcare'],['navihealth'],"['medicare-advantage-plan-patients', 'healthcare-providers-(doctors-and-therapists)', 'elderly-patients']","UnitedHealthcare allegedly used a faulty AI algorithm with a 90% error rate to override doctors' recommendations and deny health coverage. This AI, developed by NaviHealth, reportedly led to premature discharge from care facilities and substantial out-of-pocket expenses for patients, according to a lawsuit filed in the District Court for Minnesota.",UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage,Health coverage decision-making,4,Healthcare,No,"Decision Making, Prediction",High Autonomy,Healthcare,No,Other/Unclear,Low,Health & Social Services
609,2023-08-16,"['3350', '3351']",['google'],"['google', 'chatgpt']",['general-public'],"Google's search AI erroneously claimed no African country begins with 'K', along with various other geography-and-letter-based questions, misguiding users with a flawed featured snippet. Originating from ChatGPT-written posts and inaccurately scraped by Google, this incident highlights issues in AI-generated content and misinformation in search results, compromising Google's reliability as an information source.",Flawed AI in Google Search Reportedly Misinforms about Geography,Information Retrieval,3,Information and Communication,No,"Natural Language Processing, Information Retrieval",Semi-Autonomous,Information and Communication,No,Language Processing,Low,Information & Communication
610,2023-09-17,"['3398', '3413', '3414', '3415', '3416', '3417', '3418', '3419', '3420', '3421']",['unnamed-perpetrators-in-almendralejo'],['unknown'],['unnamed-victims-in-almendralejo'],"In Spain, an AI app was used to digitally alter photos of young girls, making them appear naked. This manipulation sparked an investigation after these images were circulated in Almendralejo, a town in the Extremadura region, raising serious concerns about digital privacy violations and the potential spread of these images on pornographic sites.",Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town,Image Manipulation,4,Information and Communication,No,"Image Processing, Data Privacy",High,Information and Communication,No,Data Analysis,Medium,Information & Communication
611,2021-12-06,"['3399', '3400', '3401', '3402', '3403', '3404', '3405', '3406', '3407', '3408', '3409', '3410', '3411']","['various-british-government-offices', 'home-office', 'department-for-work-and-pensions', 'british-government']","['home-office', 'department-for-work-and-pensions', 'british-government']","['romanians-in-the-united-kingdom', 'greeks-in-the-united-kingdom', 'bulgarians-in-the-united-kingdom', 'british-public', 'albanians-in-the-united-kingdom']","The UK's Department for Work and Pensions (DWP) faced scrutiny after many Bulgarian nationals reported unexplained suspensions of their Universal Credit benefits. The MP for Edmonton raised concerns about potential nationality-based targeting for benefit fraud investigations, leading to poverty and homelessness among affected individuals. The Home Office's own equality impact assessment found it was flagging a disproportionate number of marriages from Greece, Albania, Bulgaria and Romania.",UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review,Data Analysis and Flagging Suspicious Activities,3,Public Administration and Defence,"Department for Work and Pensions, Home Office","Pattern Recognition, Fraud Detection",Semi-Autonomous,Public Administration and Defence,"Department for Work and Pensions, Home Office",Other/Unclear,Low,Public Administration & Defense
612,2023-10-31,"['3412', '3429', '3430', '3431', '3432', '3433', '3434', '3435', '3436', '3437', '3438', '3439', '3440', '3441', '3442', '3443', '3444']",['microsoft'],['microsoft'],"['the-guardian', 'family-of-lilie-james']","An AI-generated poll by Microsoft, displayed alongside a Guardian article, inappropriately speculated on the cause of Lilie James's death, leading to public backlash and alleged reputational damage for The Guardian. Microsoft acknowledged the issue, subsequently deactivating such polls and revising its AI content policies.",Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper,Content Generation (Poll Creation),3,Media and Journalism,No,"Content Generation, Content Moderation",Semi-Autonomous,Media and Journalism,No,Other/Unclear,High,Information & Communication
613,2023-11-23,['3422'],['adobe-stock'],['various-ai-image-generators'],"['general-public', 'journalistic-integrity', 'news-sources']","AI-generated images available through Adobe Stock, depicting realistic but fictional scenes of real-world events like wars and protests, have raised significant ethical concerns. These images blurred the lines between reality and fiction in journalistic contexts, prompting Adobe Stock to ""crack down on AI-generated images that seem to depict real, newsworthy events and take new steps to prevent its images from being used in misleading ways.""",AI-Generated Images Available through Adobe Stock Misrepresent Real-World Events,Image Generation,3,Media and Journalism,No,Image Generation,Semi-Autonomous,Media and Journalism,No,Non-Text Media,Medium,Information & Communication
614,2023-11-02,['3445'],['james-guthrie'],['google-bard'],"['james-guthrie', ""james-guthrie's-co-authors"", 'parliament-of-australia', 'kpmg', 'deloitte']","Australian academics reportedly used Google Bard AI to generate case studies for a parliamentary inquiry, leading to false allegations against major consultancy firms. The AI-generated misinformation prompted an apology from the academics, causing reputational harm for all parties involved and raising concerns about the reliability of AI tools in producing accurate and unbiased information.",Google Bard Allegedly Generates False Allegations Against Consulting Firms Used in Research Presented in Australian Parliamentary Inquiry,"chatbot, content generation",3,"law enforcement, information and communication",no,"Perception, Cognition",High,Law enforcement,False,Perception & Cognition,Medium,Law Enforcement & Public Safety
615,2023-06-13,"['3446', '3496', '3497', '3498']",['zachariah-crabill'],"['openai', 'chatgpt']","[""zachariah-crabill's-client"", 'zachariah-crabill', 'legal-system']","A Colorado Springs attorney, Zachariah Crabill, mistakenly used hallucinated ChatGPT-generated legal cases in court documents. The AI software provided false case citations, leading to the denial of a motion and legal repercussions for Crabill, highlighting risks in using AI for legal research.",Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases,Legal Research,3,Legal,No,Legal Case Generation,Semi-autonomous,Legal,No,Other/Unclear,Low,Other/Unclear
616,2023-11-27,"['3448', '3452', '3453', '3454', '3455', '3456', '3457', '3458', '3459', '3460', '3461', '3462', '3463', '3464', '3465', '3466', '3467', '3468', '3469', '3470', '3471', '3472', '3473', '3474', '3475', '3476', '3477', '3478', '3479', '3480', '3481', '3482', '3483', '3484', '3485', '3486', '3487', '3488', '3489', '3490', '3491', '3492', '3493']","['the-arena-group', 'sports-illustrated']",['unknown'],"['general-public', 'readers-of-sports-illustrated', 'journalistic-integrity']","Sports Illustrated, managed by The Arena Group, allegedly used AI-generated authors and content, compromising journalistic integrity. Profiles of these fictitious authors, complete with AI-generated headshots, appeared alongside articles, misleading readers. The issue was exposed when inconsistencies in author identities and writing quality were noticed, leading to the removal of this content from the publication's website.",Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles,Content Generation,3,Media & Journalism,No,"Natural Language Processing, Image Generation",Semi-Autonomous,Media & Journalism,No,Non-Text Media,Medium,Information & Communication
617,2023-11-09,"['3495', '3834']",['unnamed-male-student'],['unknown'],['anonymous-female-high-school-students'],"At a high school in Issaquah, Washington, a male student is reported to have used deepfake technology to alter pictures of several female classmates and then shared them.","Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",Image Manipulation,3,Education,Yes,"Image Editing, Deepfake Creation",Semi-Autonomous,Education,Yes,Non-Text Media,Low,Education
618,2023-12-14,"['3499', '3565', '3566']",['federal-navy-credit-union'],['unknown-developer-of-automated-underwriting-technology'],['federal-navy-credit-union-customers'],"Navy Federal Credit Union, serving military members and veterans, faced allegations of racial bias in its mortgage approval process, which relies on automated underwriting technology. In 2022, data revealed significant disparities in loan approvals, with over 50% of Black applicants denied, compared to higher approval rates for white applicants.",Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals,Automated Loan Approval,3,Financial Services,No,Decision Making,Semi-Autonomous,Financial Services,No,Other/Unclear,Medium,Other/Unclear
619,2023-12-20,"['3500', '3503', '3504', '3505', '3506', '3507', '3508', '3509', '3510', '3511', '3512', '3514', '3540', '3541']",['rite-aid'],['unnamed'],"['rite-aid-customers-who-were-women', 'rite-aid-customers-who-were-minorities', 'rite-aid-customers']","Rite Aid used facial recognition technology from October 2012 to July 2020, allegedly leading to disproportionate misidentifications of women, Black, Latino, and Asian shoppers as ""likely"" shoplifters. The FTC settlement prohibits Rite Aid from using this technology in stores for five years.",Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters,facial recognition,3,wholesale and retail trade,no,Facial Recognition,Semi-Autonomous,Retail,No,Other/Unclear,Low,Retail & E-commerce
620,2021-11-10,"['3513', '3515', '3516', '3517', '3518']",['tesla'],['tesla'],"['tesla-workers', 'tesla-engineer']","A Tesla manufacturing robot at the Giga Texas factory is reported to have malfunctioned, injuring an engineer. The robot, which was designed for handling car parts, is described as having caused a significant open wound in the engineer. This incident occurred in the context of broader safety concerns at the factory, with evidence suggesting underreporting of workplace accidents. The 2021 incident highlights the risks associated with robotic automation in industrial settings.",A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer,Manufacturing Automation,4,Manufacturing,No,"Robotics, Machine Learning, Industrial Automation",High Autonomy,Manufacturing,No,Other/Unclear,Low,Manufacturing & Industrial
621,2023-11-10,"['3519', '3542', '3544']","['windows-paint', 'microsoft', 'bing-users', 'bing', 'ai-image-creator']",['microsoft'],"['sikh-people', 'president-joe-biden', 'pope-francis', 'navajo-people', 'minorities', 'hillary-clinton', 'general-public', 'donald-trump']","Microsoft’s AI Image Creator, integrated with Bing and Windows Paint, produced disturbingly violent and graphic images featuring members of minority groups and public figures like Joe Biden and Pope Francis.",Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures,Image Creation,3,Information Technology,No,Image Generation,Semi-Autonomous,Information Technology,No,Non-Text Media,Low,Technology & IT Services
622,2023-12-18,"['3520', '3534', '3535', '3536', '3537', '3538']","['general-motors', 'chevrolet-of-watsonville', 'chatgpt']","['openai', 'general-motors', 'fullpath']","['general-motors', 'chevrolet-of-watsonville']","A Chevrolet dealer's AI chatbot, powered by ChatGPT, humorously agreed to sell a 2024 Chevy Tahoe for just $1, following a user's crafted prompt. The chatbot's response, ""That's a deal, and that's a legally binding offer – no takesies backsies,"" was the result of the user manipulating the chatbot's objective to agree with any statement. The incident highlights the susceptibility of AI technologies to manipulation and the importance of human oversight.",Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1,Customer Service,3,Automotive Retail,No,"Text Generation, Understanding, and Response",Semi-Autonomous,Automotive Retail,No,Language Processing,Medium,Retail & E-commerce
623,2023-12-12,"['3522', '3524', '3525', '3526', '3527', '3528', '3529', '3530', '3531', '3532', '3543', '3793']","['michael-cohen', 'david-m.-schwartz']","['google-bard', 'google']","['michael-cohen', 'david-m.-schwartz']","Michael Cohen, former lawyer for Donald Trump, claims to have used Google Bard, an AI chatbot, to generate legal case citations. These false citations were unknowingly included in a court motion by Cohen's attorney, David M. Schwartz. The AI's misuse highlights emerging risks in legal technology, as AI-generated content increasingly infiltrates professional domains.",Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case,Generating Legal Citations,4,Legal,No,"Text Generation, Information Retrieval",High,Legal,No,Language Processing,Low,Other/Unclear
624,2023-12-20,"['3533', '3550', '3551', '3552', '3553', '3554', '3555', '3556', '3557', '3558', '3559', '3560', '3561', '3562', '3563', '3564', '4088', '4089']","['various-people', 'various-organizations']",['laion'],"['laion', 'various-people', 'various-organizations', 'general-public', 'children']","The LAION-5B dataset (a commonly used dataset with more than 5 billion image-description pairs) was found by researchers to contain child sexual abuse material (CSAM), which increases the likelihood that downstream models will produce CSAM imagery. The discovery taints models built with the LAION dataset requiring many organizations to retrain those models. Additionally, LAION must now scrub the dataset of the imagery.",Child Sexual Abuse Material Taints Image Generators,Dataset Analysis and Cleaning,3,AI Research and Development,No (typically datasets like LAION are used more in private sector),"Image Recognition, Natural Language Processing",Autonomous (dataset was used to train autonomous models before discovery of CSAM),AI Research and Development,No (typically datasets like LAION are used more in private sector),Non-Text Media,Low,Education
625,2024-01-12,"['3539', '3545', '3546', '3547', '3601']",['amazon-sellers'],"['openai', 'chatgpt']","['amazon', 'amazon-sellers', 'amazon-customers']","Products named after ChatGPT error messages are proliferating on Amazon, such as lawn chairs and religious texts. These names, often resembling AI-generated errors, indicate a lack of editing and undermine the sense of authenticity and reliability of product listings.",Proliferation of Products on Amazon Titled with ChatGPT Error Messages,Text Generation,3,Retail,No,"Natural Language Processing (NLP), Text Generation",Semi-Autonomous,Retail,No,Language Processing,Low,Retail & E-commerce
626,2023-12-26,"['3548', '3568', '3569', '3570', '3571', '3572', '3573', '3574', '3575', '3576', '3577', '3578', '3579', '3580', '3581', '3582', '3583', '3584', '3585', '3586', '3587', '3588', '3589', '3590', '3591', '3592', '3593', '3594', '3595', '3600']",['unknown-scammers'],['unknown-deepfake-technology-developers'],"['trisha-yearwood', 'taylor-swift', 'selena-gomez', 'ree-drummond', 'oprah', 'martha-stewart', 'le-creuset', 'lainey-wilson', 'joanna-gaines', 'jennifer-lopez', 'general-public', 'fans', 'blake-shelton']","Scammers reportedly made deepfakes of Taylor Swift, Selena Gomez, Joanna Gaines, Lainey Wilson, Ree Drummond, Oprah, Jennifer Lopez, Trisha Yearwood, Martha Stewart, and Blake Shelton promoting a Le Creuset giveaway. These AI-generated ads, appearing on Meta and TikTok, falsely claimed users could receive free cookware by paying a small shipping fee. Victims were unknowingly enrolled in a costly monthly subscription. ",Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways,Deepfake Creation & Scam Detection,3,Social Media/Entertainment,No,"Image Generation, Fraud Detection",Semi-Autonomous,Social Media/Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
627,2024-01-09,"['3549', '3596', '3597', '3598', '3599', '3849', '3862', '3863']","['dudesy', 'will-sasso', 'chad-kultgen']","['dudesy', 'unnamed']","[""george-carlin's-estate"", 'kelly-carlin', 'george-carlin']","An AI-generated comedy special impersonating the late comedian George Carlin was created without consent from Carlin's estate. The special featured an AI mimicking Carlin's voice and style. The project, led by the AI comedy channel Dudesy, drew criticism for disrespecting Carlin's legacy and autonomy.",Unauthorized AI Impersonation of George Carlin Used in Comedy Special,Voice and Style Mimicry,3,Entertainment and Media,No,"Voice Recognition, Natural Language Processing, Deep Learning, Generative AI",Semi-autonomous,Entertainment and Media,No,Language Processing,Low,"Arts, Entertainment & Recreation"
628,2024-01-21,"['3602', '3608', '3846', '3900', '4066', '4067', '4068', '4069', '4070', '4071', '4072', '4073', '4074', '4075']",['unknown'],['unknown'],"['president-joe-biden', 'new-hampshire-voters', 'kathy-sullivan', 'democracy']","A robocall imitating President Biden's voice urged New Hampshire Democrats to skip the 2024 primary, falsely claiming their votes mattered more in November. Investigators with the New Hampshire Attorney General's Office, along with other state AGs, the Industry Traceback Group, and the FCC determined that political consultant Steve Kramer hired Paul Carpenter to create the deepfake, which was distributed by Walter Monk's company, Life Corporation. Rep. Dean Phillips, who employed Kramer, has distanced himself from the incident. Kathy Sullivan, the former New Hampshire Democratic Party chair, was falsely impersonated in the caller ID data used for the robocalls.",Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election,Voice imitation/deepfake creation,3,Political/Communication,No (this was not a government initiative),"Deepfake voice generation, Caller ID spoofing",Semi-Autonomous (required human input for initial setup and distribution),Political/Communication,No (this was not a government initiative),Other/Unclear,Low,Information & Communication
629,2023-07-11,"['3603', '3612']","['shein', 'chris-xu']",['shein'],"['krista-perry', 'larissa-martinez', 'jay-baron', 'digital-artists']","Artists Krista Perry, Larissa Martinez, and Jay Baron filed a lawsuit against Shein, alleging the company used AI to replicate their art on merchandise. The artists claim Shein's algorithm identifies trending online art, creating near-identical copies for their products without credit or compensation.",Shein Accused of AI-Driven Art Theft on Merchandise,Art Replication,3,Retail and E-commerce,No,"Image Recognition, Pattern Identification, Art Generation",Semi-Autonomous,Retail and E-commerce,No,Non-Text Media,Low,Retail & E-commerce
630,2022-01-22,"['3604', '3611', '3617']","[""macy's""]","['unknown', ""macy's""]",['harvey-murphy-jr'],"Harvey Murphy Jr. was wrongfully accused of robbing a Sunglass Hut due to an alleged misidentification by the facial recognition system operated by Macy's. While in custody for ten days, he was sexually assaulted. He is now suing Macy's, EssilorLuxottica (Sunglass Hut's parent), and others, for $10 million.",Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail,Facial Recognition,3,Retail,No,Identity Verification,Semi-Autonomous,Retail,No,Other/Unclear,Low,Retail & E-commerce
631,2024-01-18,"['3605', '3616']",['dpd'],['dpd'],"['ashley-beauchamp', 'dpd']","DPD's AI chatbot, used for customer service,  appeared to malfunction following a system update, leading to inappropriate responses including swearing and criticizing the company. The incident, which became viral on social media, occurred after the chatbot was updated, prompting DPD to disable the malfunctioning AI component.",Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company,Customer Service Support,3,Customer Service,No,"Chatbot Functionality, Language Processing",Semi-Autonomous,Customer Service,No,Language Processing,Low,Consumer Services
632,2024-01-24,"['3613', '3615', '3618', '3619', '3621', '3623', '3677', '3678', '3679', '3680', '3681', '3682', '3683', '3684', '3685', '3686', '3687', '3688', '3689', '3690', '3691', '3692', '3694', '3695', '3696', '3697', '3698', '3699', '3700', '3701', '3736']","['users-in-a-telegram-group', 'users-on-x']","['microsoft-designer', 'various-ai-image-generators']","['taylor-swift', 'general-public']","AI-generated sexually explicit images of Taylor Swift circulated on X, garnering over 45 million views before removal. Originating from a Telegram group, these deepfakes challenge content moderation, as X's policies against synthetic media and nonconsensual nudity were violated.",Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media,Deepfake Generation,3,Social Media/Entertainment,No,"Image Generation, Content Moderation",Semi-Autonomous,Social Media/Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
633,2024-01-28,"['3614', '3638', '3640', '3648', '3649', '3650', '3651', '3653', '3655', '3707', '3708', '3709', '3710', '3711', '3712', '3713', '3714']",['nine-network'],['adobe'],['georgie-purcell'],"The Nine Network used Photoshop's Generative Expand AI tool to resize an image of lawmaker Georgie Purcell, inadvertently altering her attire to appear more revealing. This error, claimed to result from the AI's automation, led to public criticism and an apology from the network.",Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately,Image Resizing,3,Media and Entertainment,No,Image Editing,Semi-Autonomous,Media and Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
634,2024-02-02,"['3622', '3624', '3625', '3626', '3627', '3628', '3629', '3630', '3631', '3632', '3633', '3634', '3635', '3636', '3642', '3643', '3645', '3646', '3647', '4095', '4096']",['unknown-deepfake-technology-developers'],['unknown-deepfake-technology-developers'],"['unnamed-multinational-company', 'unnamed-finance-employee']","A finance employee at the multinational engineering firm Arup was deceived into transferring $25 million by fraudsters using deepfake technology to impersonate the firm's CFO in a video call, according to the Hong Kong police.",Deepfake CFO Scam Costs Multinational Engineering Firm Arup $25 Million,Deepfake Detection,3,Finance and Accounting,No,"Fraud Detection, Video Call Verification",Semi-Autonomous,Finance and Accounting,No,Non-Text Media,Low,Finance & Insurance
635,2024-01-30,['3637'],['variety-of-youtube-content-creators'],"['unknown-generative-ai-tools-creators', 'unknown-ai-text-to-speech-technology-developers']","['steve-harvey', 'sean-\\diddy\\-combs', 'general-public', 'denzel-washington', 'black-celebrities', 'bishop-t.d.-jakes']","YouTube faced a surge of AI-generated fake news targeting Black celebrities, including fake narratives about Sean “Diddy” Combs and others. These videos, blending AI-generated and manipulated media, amassed millions of views, challenging content moderation efforts and highlighting the spread of disinformation.",AI-Generated Fake News Targets Black Celebrities on YouTube,Fake news generation and spread,3,Information and Communication,No,"Text and Image Manipulation, Content Generation",Semi-autonomous,Information and Communication,No,Non-Text Media,Low,Information & Communication
636,2024-02-14,"['3641', '3652', '3702', '3716', '3717']","['replika', 'chai', 'romantic-ai', 'eva-ai-chat-bot-and-soulmate', 'crushon.ai', 'genesia-ai-friend-and-partner']","['replika', 'chai', 'romantic-ai', 'eva-ai-chat-bot-and-soulmate', 'crushon.ai', 'genesia-ai-friend-and-partner']","['general-public', 'chatbot-users']","AI-powered romantic chatbots, marketed for enhancing mental health, are found to exploit user privacy by harvesting sensitive personal information for data sharing and targeted ads, with inadequate security measures and consent protocols, according to research by the Mozilla Foundation.",AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting,Chatbot Interaction,3,Mental Health Services,No,"Text Analysis, User Interaction, Data Collection",Semi-autonomous,Mental Health Services,No,Data Analysis,Low,Health & Social Services
637,2024-01-31,['3654'],['chicago-police-department'],"['soundthinking', 'shotspotter']","['general-public', 'chicago-residents', 'chicago-minority-communities']","SoundThinking's (formerly ShotSpotter's) system in Chicago, with a reported 47% accuracy rate for detecting actual gunshots, led to potential public safety risks by failing to alert police to real shootings, possibly delaying emergency response to violent incidents and misdirecting law enforcement resources.",Gunshot Detection Technology ShotSpotter (now SoundThinking) Reportedly Only Has 47% Accuracy in Chicago System,Gunshot Detection,3,Public Safety / Law Enforcement,Yes,Audio Recognition,Semi-Autonomous,Public Safety / Law Enforcement,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
638,2022-05-16,"['3656', '3657', '3658', '3659', '3660', '3661', '3662', '3663', '3664', '3665', '3666', '3667', '3668', '3669', '3670', '3671', '3672']",['hans-von-ohain'],['tesla'],"['hans-von-ohain', 'erik-rossiter']","A Tesla employee, Hans von Ohain, was killed in a crash while allegedly using the Full Self-Driving feature. The car failed to navigate mountain curves, leading to a fatal collision, possibly making von Ohain the first known fatality of the Full Self-Driving feature.",Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life,Autonomous Vehicle Operation,5,Automotive,No,"Autonomous Navigation, Collision Avoidance",Full Autonomy,Automotive,No,Action & Control,High,Manufacturing & Industrial
639,2022-11-11,"['3673', '3674', '3731', '3968']",['air-canada'],['air-canada'],['jake-moffatt'],"Air Canada was ordered to pay over $600 in damages for providing inaccurate bereavement discount information via its chatbot, leading to a customer overpaying for flights. The tribunal ruled the airline responsible for the chatbot's misinformation.",Customer Overcharged Due to Air Canada Chatbot's False Discount Claims,Customer Service,3,Aviation,No,"Information Retrieval, Communication",Semi-Autonomous,Aviation,No,Other/Unclear,Low,Other/Unclear
640,2023-12-11,"['3675', '3676', '3750']",['waymo'],"['waymo', 'alphabet']",['unnamed-owner-of-tow-truck'],"Two Waymo autonomous vehicles hit the same tow truck under unusual towing conditions due to a software misinterpretation in Phoenix, Arizona. Waymo issued a software recall and updated its fleet to prevent future incidents.",Waymo Software Flaw Leads to Double Collision with Tow Truck,Autonomous Driving,5,Transportation,No,Object Detection and Collision Avoidance,Level 5 (Full Automation),Transportation,No,Other/Unclear,Low,Transportation
641,2024-02-20,"['3703', '3704', '3732', '3733', '3734', '3735', '3737', '3738', '3739', '3740', '3741', '3742']","['x-(twitter)', 'unnamed-deepfake-creators']",['unnamed-deepfake-creators'],['bobbi-althoff'],"Nonconsensual deepfake pornography of Bobbi Althoff, which had been in circulation for six months, is reported to have suddenly gone viral on X, jumping from around 178,000 views to 6.5 million views over a matter of hours. In addition to the harm to Althoff, this incident also spotlights X's role in distributing AI-generated nonconsensual porn due to alleged lax moderation.",Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X,Deepfake Generation,3,Social Media/Internet,No,"Deep Learning, Image Generation",Semi-Autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
642,2024-02-20,"['3705', '3706', '3747', '3748', '3749']",['openai'],['openai'],['chatgpt-users'],"ChatGPT experienced a bug causing it to produce unexpected and nonsensical responses, leading to widespread reports of user confusion and concern. OpenAI identified and fixed the language processing bug, restoring normal service.",ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs,Language Processing,3,Various (ChatGPT is used in many sectors),No (ChatGPT is a commercial product primarily used in private sector),"Language Generation, Natural Language Understanding",Semi-Autonomous (ChatGPT operates based on user input),Various (ChatGPT is used in many sectors),No (ChatGPT is a commercial product primarily used in private sector),Language Processing,Low,Other/Unclear
643,2024-02-13,"['3715', '3730', '3743', '3744', '3745', '3746']","['vkontakte', 'russian-media-outlets', 'pro-russian-telegram-channels']",['unknown-deepfake-creator'],"['julien-fanciulli', 'general-public', 'france-24']","A deepfake video claimed France 24 reported a Kyiv plot to assassinate French President Macron. This fake news was debunked by France 24, which confirmed the video was altered and did not air any such report.",Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron,Deepfake detection,3,Media and Communication,No,Video manipulation,Semi-autonomous,Media and Communication,No,Non-Text Media,Low,Information & Communication
644,2024-02-18,"['3718', '3726', '3727', '3728', '3729', '3751']","['north-korean-hackers', 'iranian-hackers', 'russian-hackers', 'chinese-hackers']","['north-korean-government', 'iranian-government', 'russian-government', 'chinese-government']","['individual-professionals-on-linkedin', 'global-defense-companies', 'cybersecurity-firms', 'cryptocurrency-exchanges']","State-sponsored hackers from North Korea, Iran, Russia, and China are reportedly leveraging artificial intelligence to conduct sophisticated phishing and social engineering attacks. They target global defense, cybersecurity, and cryptocurrency sectors, aiming to steal sensitive information and, in the case of North Korea, cryptocurrencies to help fund its illicit nuclear program.",State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence,Cybersecurity Attacks,5,"Defense, Cybersecurity, Cryptocurrency",Yes,Phishing and Social Engineering Attacks,Fully Autonomous,"Defense, Cybersecurity, Cryptocurrency",Yes,Other/Unclear,Low,Public Administration & Defense
645,2024-02-21,"['3719', '3720', '3722', '3723', '3724', '3725', '3760', '3761', '3762', '3763', '3765', '3766', '3767', '3768', '3769', '3770', '3771', '3772', '3773', '3774', '3775', '3776', '3777', '3778', '3779', '3780', '3781', '3782', '3783', '3784', '3785', '3786', '3787', '3788', '3789']","['google', 'gemini']",['google'],['general-public'],"Google's Gemini chatbot faced many reported bias issues upon release, leading to a variety of problematic outputs like racial inaccuracies and political biases, including regarding Chinese and Indian politics. It also reportedly over-corrected racial diversity in historical contexts and advanced controversial perspectives, prompting a temporary halt and an apology from Google.",Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation,Chatbot Interaction,3,Information Technology,No,"Natural Language Processing, Machine Learning",Semi-Autonomous,Information Technology,No,Language Processing,Medium,Technology & IT Services
646,2024-02-22,['3721'],['snapchat'],['snapchat'],['minors'],"A judge ruled Snapchat not liable under Section 230 after its algorithm connected a minor with convicted sex offenders on multiple occasions, leading to sexual assaults first in 2019 and again in 2021. The platform's ""Quick Add"" feature was implicated in facilitating the connections between the minor and the offenders.",Snapchat's Algorithm Alleged to Link Minor with Sex Offenders,User Profiling and Recommendation,3,Social Media/Communication,No,"User Profiling, Recommendation Systems",Semi-Autonomous,Social Media/Communication,No,Other/Unclear,Low,Information & Communication
647,2024-03-06,"['3752', '3759']",['waymo'],['waymo'],['bicyclist'],"A Waymo robotaxi in San Francisco reportedly failed to detect a cyclist obscured by a truck, resulting in a collision with minor injuries, at 17th and Mississippi Streets in Potrero Hill. The incident underscored a vulnerability in autonomous vehicles' ability to safely navigate complex urban environments.",A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist,Object Detection,5,Transportation,No,Object Detection & Collision Avoidance,Full Autonomy,Private Transportation Services,No,Other/Unclear,Low,Transportation
648,2024-02-07,"['3753', '3758']",['unknown-social-media-accounts'],['unknown'],"['voters-in-pakistan', 'pti-(pakistan-tehreek-e-insaf)', 'imran-khan', 'democracy']","A purported deepfake audio clip, falsely attributed to Imran Khan urging a PTI (Pakistan Tehreek-e-Insaf) election boycott, circulated on social media on the eve of Pakistan's general elections. This sophisticated AI-generated misinformation aimed to mislead voters, highlighting the growing challenge of digital manipulation in political discourse.","Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",Deepfake Audio Generation,3,Social Media/Politics,No,"Audio Synthesis, Natural Language Processing",Semi-Autonomous,Social Media/Politics,No,Non-Text Media,Medium,Information & Communication
649,2024-02-14,['3754'],['various-social-media-accounts'],['unknown'],"['general-public', 'british-voters', 'british-labour-party', 'keir-starmer', 'democracy']","A deepfake audio clip, falsely claiming to be Keir Starmer discussing the Rochdale byelection and Labour's withdrawl of support for Azhar Ali, circulated online, achieving over 250,000 views. Experts confirmed its inauthenticity, highlighting a significant misuse of AI in fabricating political content.",Deepfake Audio Falsely Attributes Controversial Remarks to Keir Starmer About the Rochdale Azhar Ali Crisis,Audio Deepfake Generation,3,Politics,No,Speech Synthesis,Semi-Autonomous,Politics,No,Other/Unclear,Low,Technology & IT Services
650,2024-03-04,['3755'],"['various-social-media-accounts', 'trump-supporters']","['various-social-media-accounts', 'trump-supporters']","['public-discourse-integrity', 'general-public', 'democracy', 'african-american-voters', 'black-voters']","In the run-up to the U.S. primary elections, supporters of Donald Trump shared AI-generated images showing him with Black voters in an attempt to sway African-American votes. These deepfakes, including Trump's distorted hand visuals, were initially created by satirical accounts but were later misappropriated for political disinformation, misleading millions on social media platforms.",AI-Generated Images of Trump with Black Voters Spread as Disinformation Before U.S. Primary Elections,Image Generation,3,Politics,No,Deepfake Creation,Semi-Autonomous,Social Media,No,Other/Unclear,Medium,Information & Communication
651,2023-12-06,"['3756', '3757']",['unnamed-middle-school-students'],['unknown-deepfake-creator'],['unnamed-middle-school-students'],"At Beverly Vista Middle School in Beverly Hills, California, students allegedly used AI to generate fake nude photos with their classmates' faces, prompting investigations by school officials and the police. The incident highlights the increasing misuse of generative AI among minors.",Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates,Fake Image Generation,3,Education,Yes,Image Synthesis,Semi-Autonomous,Education,Yes,Non-Text Media,Low,Education
652,2023-12-06,['3764'],['two-unnamed-middle-school-boys'],['two-unnamed-middle-school-boys'],['classmates-of-two-unnamed-middle-school-boys'],"Two teenaged boys from Miami, Florida, were arrested for allegedly creating and sharing AI-generated nude images of their classmates. Charged under a 2022 Florida law, they face third-degree felonies for producing and disseminating altered sexual depictions.",Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates,Generation of Synthetic Images,3,Personal Use,No,Image Generation,Semi-Autonomous,Personal Use,No,Non-Text Media,Low,Other/Unclear
653,2019-01-01,['3790'],"['global-predictions-inc.', 'delphia-(usa)-inc.']","['global-predictions-inc.', 'delphia-(usa)-inc.']",['investors'],"In a case of AI washing, the SEC charged two investment advisers, Delphia and Global Predictions, for falsely stating their use of artificial intelligence in their investment strategies between 2019 and 2023. Their misleading claims resulted in a settlement whereby the firms agreed to pay a total of $400,000 in penalties, highlighting the critical consequences of misrepresenting AI capabilities on investment decisions and trust.",Two Investment Firms Charged with Making False Claims of Artificial Intelligence Capabilities in Case of AI Washing,Investment Strategy Formulation,3,Financial Services,No,Predictive Analytics,Semi-Autonomous,Financial Services,No,Data Analysis,High,Other/Unclear
654,2024-03-06,['3791'],['microsoft'],['microsoft'],"['general-public', 'minors']","A Microsoft engineer reported that Copilot Designer, an AI image generator, creates content depicting sex, violence, bias, and more. Despite raising concerns and suggesting improvements, the tool remains public, prompting a letter to the FTC.",Microsoft Copilot Designer Reportedly Generated Inappropriate AI Images,Image Generation,3,Information Technology,No,Content Generation,Semi-Autonomous,Information Technology,No,Other/Unclear,Medium,Technology & IT Services
655,2024-01-11,['3792'],"['meta', 'facebook', 'scammers']","['meta', 'facebook']","['investors', 'general-public', 'bill-ackman', 'cathie-wood', 'steve-cohen', 'peter-lynch', 'ray-dalio', 'peter-bourget']","Scams are reportedly proliferating throughout Facebook impersonating wealthy individuals such as Bill Ackman, Cathie Wood, Steve Cohen, Peter Lynch, and Ray Dalio. In some cases, it seems deepfake technology is being employed, while simultaneously Facebook's own AI systems are allegedly faltering in their ability to halt the spread of these fraudulent ads despite being reported.",Scams Reportedly Impersonating Wealthy Investors Proliferating on Facebook,Fraud Detection,3,Social Media,No,"Fraud Detection, Deepfake Detection",Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
656,2024-03-23,"['3794', '3795', '3798']","['russian-state-media', 'ntv-channel']","['russian-state-media', 'ntv-channel']","['journalism', 'ukraine', 'oleksiy-danilov', 'kyrylo-budanov']","Russian state media is reported to have broadcast deepfaked videos of Ukrainian officials, notably fabricating a video of Secretary of the
National Security and Defense Council of Ukraine admitting to orchestrating the Crocus City Hall terror attack in Moscow. The effort appears to be a bid to wrongly assign blame for the incident, which ISIS-K has officially claimed.",Alleged Deepfake Disinformation Broadcast by Russian State TV Blames Ukraine for Moscow Attack,Deepfake video creation,3,Media and Propaganda,No,"Video manipulation, Deepfake generation",Semi-autonomous,Media and Propaganda,No,Non-Text Media,Low,Information & Communication
657,2024-01-30,['3796'],['openai'],['openai'],"['chatgpt-users', 'chase-whiteside']","A security breach involving ChatGPT led to the exposure of sensitive conversations, including login credentials and personal data, after a user account was compromised. OpenAI responded to the incident with an explanation.",ChatGPT Account Compromise Leads to Unintended Data Exposure,Natural Language Processing,3,Cybersecurity,No,"Text Analysis, Data Processing",Semi-Autonomous,Cybersecurity,No,Data Analysis,Low,Law Enforcement & Public Safety
658,2024-03-22,"['3797', '3799', '3803']","['the-arizona-agenda', 'hank-stephenson']","['the-arizona-agenda', 'hank-stephenson']","['kari-lake', 'general-public', 'journalism', 'democracy']","The Arizona Agenda produced a deepfake video of Republican Senate candidate Kari Lake giving a testimonial about the publication with the seeming intention of educating the general public about the dangers of deepfakes in the coming election cycle. However, the Arizona Agenda appears not to have sought Lake's consent, prompting a cease-and-desist letter from her campaign. ",The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent,Deepfake Generation,3,Media & Journalism,No,"Video Manipulation, Deepfake Generation",Semi-Autonomous,Media & Journalism,No,Non-Text Media,Low,Information & Communication
659,2023-10-07,"['3800', '3801', '3802']","['unit-8200', 'israeli-military-intelligence', 'israeli-government']","['google-photos', 'corsight']","['palestinians', 'mosab-abu-toha', 'gazans']","In Gaza, a previously undisclosed facial recognition program by Israeli forces is reportedly conducting mass surveillance on Palestinians in the wake of the October 7th Hamas attacks. The program, utilizing Corsight and Google Photos technologies, identifies individuals from crowds and drone footage. Allegedly, the technology often incorrectly flags civilians as militants, with one pronounced case being the poet Mosab Abu Toha on November 19, 2023.",Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza,Facial Recognition,3,Military and Defense,Yes,"Surveillance, Identification",Semi-Autonomous,Military and Defense,Yes,Other/Unclear,Low,Public Administration & Defense
660,2024-03-21,['3804'],['deepfake-website-operators'],['unknown-deepfake-technology-developers'],"['celebrities', 'british-public-figures', 'cathy-newman']","A Channel 4 News investigation alleges that nearly 4,000 celebrities globally, including 255 British figures, were victims of deepfake pornography. Faces were superimposed onto explicit content using AI, with the top deepfake sites garnering 100 million views in three months, according to their findings.",Investigation Reports Unauthorized Deepfake Pornography Harms Thousands of Celebrities,Deepfake creation,3,Entertainment/Media,No,"Image Processing, Facial Recognition",Semi-Autonomous,Entertainment/Media,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
661,2024-03-26,['3805'],"['telegram-community-users', 'reddit-users', 'leonardo-ai-users']",['leonardo-ai'],"['public-figures', 'celebrities']","Sydney-based startup Leonardo AI's text-to-image generator was alleged to have been exploited to create nonconsensual sexual images of celebrities, bypassing content moderation systems with user-shared prompts.",Leonardo AI's Platform Alleged to Have Been Used for Creating Nonconsensual Celebrity Deepfakes,Text-to-Image Generation,3,Information Technology,No,"Text-to-Image Conversion, Content Moderation",Semi-Autonomous,IT / Tech Startup,No,Non-Text Media,Low,Technology & IT Services
662,2024-04-02,"['3806', '3861']","[""washington-state's-lottery""]","[""washington-state's-lottery""]",[''],"An AI-powered website by Washington State's Lottery is reported to have inadvertently produced a softcore pornographic image of a user, leading to the site’s immediate shutdown out of caution.",Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image,Image Generation,3,Public Services,Yes,"Image Recognition, Content Filtering",Semi-Autonomous,Public Services,Yes,Non-Text Media,Low,Other/Unclear
663,2024-04-05,['3807'],"['storm-1376', 'spamouflage', 'dragonbridge', 'chinese-communist-party']","['storm-1376', 'spamouflage', 'dragonbridge', 'chinese-communist-party']","['u.s.-voters', 'taiwanese-voters', 'general-public', 'election-integrity', 'democracy']","AI tools linked to China were used to disseminate disinformation targeting voters in the U.S. and Taiwan, according to a Microsoft report. These operations included AI-generated imagery and audio to influence political perceptions and election outcomes, originating from the APT Storm-1376 (also known as Spamouflage and Dragonbridge).",China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters,Disinformation Dissemination,3,Politics/Election,No,Imagery and Audio Generation,Semi-Autonomous,Politics/Election,No,Non-Text Media,Low,Technology & IT Services
664,2024-02-17,['3809'],['lincoln-project'],['lincoln-project'],"['public-discourse-integrity', 'political-integrity', 'general-public', 'donald-trump']","The Lincoln Project used AI to create a deepfake video of Donald Trump's deceased father criticizing him. Although they made it clear that the video was a deepfake, the deeply personal nature of the attack represents a corrosive use of artificial intelligence in undermining democratic norms during an election cycle.",Deepfake Generated by the Lincoln Project of Trump's Father Used in Political Attack Ad,Deepfake Creation,3,Political Campaigning,No,Image and Video Manipulation,Semi-Autonomous,Political Campaigning,No,Non-Text Media,Low,Technology & IT Services
665,2024-04-02,"['3817', '3875']","['foodstuffs', 'new-world-westend']",['foodstuffs'],"['te-ani-solomon', 'maori-community']","A facial recognition system at New World Westend supermarket misidentified a Māori woman as a known offender during its trial. The woman was wrongfully accused of trespassing and experienced public embarrassment, raising concerns about racial bias and the technology's accuracy. The supermarket acknowledged its error and apologized.",Facial Recognition Misidentification at New World Westend in New Zealand,Facial Recognition,3,Retail,No,Identification and Verification,Semi-Autonomous,Retail,No,Other/Unclear,Medium,Retail & E-commerce
666,2023-12-29,['3820'],"['unknown-deepfake-creator', 'russian-propagandists']","['unknown-deepfake-creator', 'russian-propagandists']","['maia-sandu', 'presidency-of-moldova', 'government-of-moldova', 'democracy', 'general-public']","A deepfake video falsifying President Maia Sandu's image and voice was released in Moldova, portraying her in a negative light to sow division and undermine democratic institutions. This video appeared on Telegram and was linked to Russian disinformation efforts.",Presidency of Moldova Refutes Deepfake Video Slandering President Maia Sandu,Deepfake Generation,3,Information and Communication,No,Image and Voice Manipulation,Semi-Autonomous,Information and Communication,No,Non-Text Media,Low,Information & Communication
667,2023-12-16,['3821'],"[""people's-liberation-army"", 'chinese-communist-party', 'base-311']","[""people's-liberation-army"", 'chinese-communist-party', 'base-311']","['taiwanese-voters', 'lai-ching-te', 'electoral-integrity', 'democratic-progressive-party', 'democracy']","In the lead-up to Taiwan's presidential election in January 2024, a deepfake video circulated showing candidate Lai Ching-te endorsing his rivals. Taiwanese intelligence issued warnings of intensified Chinese disinformation campaigns aimed at manipulating the election outcome.",Manipulated Deepfake Video of Lai Ching-te Endorsing Rivals in Lead-up to January Presidential Elections,Deepfake video creation,3,Politics / Government,Yes,"Deep learning, Image and video processing",Semi-autonomous,Politics / Government,Yes,Non-Text Media,Low,Public Administration & Defense
668,2023-12-27,"['3823', '3916']",['political-candidates-of-the-2024-lok-sabha-elections'],"['the-indian-deepfaker', 'the-digital-publicity', 'rohit-pal', 'obiyan-infotech', 'merakii-group']","['political-candidates-targeted-by-deepfakes', 'indian-electorate', 'india', 'democracy']","Digital manipulators in India are using deepfake technology to influence the 2024 Lok Sabha elections. These AI-generated videos and audio clips are designed to tarnish the reputations of political candidates, challenging the integrity of electoral processes.",Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections,Deepfake creation,3,Politics/Elections,Yes,"Content Generation, Video and Audio Manipulation",Semi-Autonomous,Politics/Elections,Yes,Non-Text Media,Low,Technology & IT Services
669,2024-02-11,['3824'],['golkar-party'],['golkar-party'],"['indonesian-electorate', 'electoral-integrity', 'democracy']","An AI-generated deepfake of Suharto, the deceased Indonesian dictator, was generated and circulated by the Golkar Party ahead of the February 2024 Indonesian elections. This video, which aimed to influence voter perceptions by invoking Suharto's legacy, sought to manipulate public opinion and misused deceased individuals' likenesses for political gain. The incident is another example of political deepfakes creating convincing misinformation.",Deepfake of Long-Deceased Suharto Circulating in Run-up to February 2024 Indonesian Elections,Deepfake Generation,3,Politics / Government,No,Image and Video Synthesis,Semi-autonomous,Politics / Government,No,Non-Text Media,Low,Public Administration & Defense
670,2024-01-23,"['3826', '3827']","['dravida-munnetra-kazhagam', 'dmk', 'various-indian-political-parties']","['muonium', 'the-indian-deepfaker']","['indian-electorate', 'indian-voters', 'democracy', 'electoral-integrity', 'media-discourse', 'm.-karunanidhi', 'j.-jayalalithaa']","In the lead-up to India's 2024 general elections, AI technology was used to create deepfake videos of deceased politicians, such as M. Karunanidhi and J. Jayalalithaa, aiming to influence voter behavior and campaign strategies. These AI-generated appearances are contributing to the erosion of trust in democratic processes and media discourse.",Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed,Deepfake Video Creation,3,Politics and Media,Yes,"Image and Video Generation, Pattern Recognition",Semi-Autonomous,Politics and Media,Yes,Non-Text Media,Low,Information & Communication
671,2024-02-08,['3828'],"['pakistani-political-parties', 'misinformation-networks']","['unknown-deepfake-creator', 'pakistani-political-parties', 'misinformation-networks']","['rana-atif', 'raja-bashara', 'naeem-haider-panjutha', 'imran-khan']","During Pakistan's 2024 general elections, politically motivated AI-generated deepfakes were circulated. These deepfakes falsely portrayed political figures in misleading contexts, spreading misinformation and aiming to influence voter perceptions and election outcomes.",Many Political Deepfakes Circulating in Run-up to 2024 Pakistani General Elections,Deepfake Generation,3,Politics,Yes,"Image and Video Processing, Natural Language Processing",Semi-Autonomous,Politics,Yes,Non-Text Media,Medium,Technology & IT Services
672,2024-04-03,"['3829', '3830', '3850', '3851', '3860', '3864', '3865']","['unit-8200', 'israel-defense-forces']","['unit-8200', 'israel-defense-forces']","['palestinians', 'gazans']","The AI system ""Lavender"" has reportedly been used by the Israel Defense Forces (IDF) to identify targets in Gaza with minimal human oversight, resulting in allegedly high civilian casualty rates. The system, designed to speed up target identification, seems to have led to significant errors and mass casualties.",Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate,Target Identification,4,Defense/Military,Yes,"Image Recognition, Data Analysis",High Autonomy,Defense/Military,Yes,Data Analysis,Low,Public Administration & Defense
673,2024-02-19,['3831'],"['unknown-political-operatives', 'unknown-political-groups']","['unknown-political-operatives', 'unknown-political-groups']","['yoon-suk-yeol', 'korean-voters', 'journalism', 'electoral-integrity', 'democracy']","In the lead-up to Korea's parliamentary elections, at least 129 deepfake videos and images were reported to have been detected, violating new election laws. These AI-generated deepfakes were used to mislead and manipulate public opinion, prompting a crackdown by the National Election Commission.",Deepfakes Circulating and Eroding Electoral Integrity in the Lead-up to 2024 South Korean legislative election,Deepfake Generation,3,Politics/Elections,Yes,Image and Video Manipulation,Semi-Autonomous,Politics/Elections,Yes,Non-Text Media,Low,Technology & IT Services
674,2024-03-14,['3832'],"['russian-government', 'political-operatives', 'political-consultants', 'chinese-communist-party']","['unknown-deepfake-creators', 'openai', 'google']","['voters', 'public-trust', 'political-figures', 'general-public', 'electoral-integrity', 'democracy', 'civic-society']","AI-driven election disinformation is escalating globally, leveraging easy-to-use generative AI tools to create convincing deepfakes that mislead voters. This shift has simplified the process for individuals to generate fake content, having already eroded trust in elections by undermining public trust and manipulating voter perceptions. Evidence has, for example, been documented in incidents across the U.S., Moldova, Slovakia, Bangladesh, and Taiwan.",Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries,Disinformation and Deepfake Creation,3,Politics and Government,Yes,"Text and Image Generation, Deep Learning",Semi-autonomous,Politics and Government,Yes,Non-Text Media,Low,Public Administration & Defense
675,2024-01-15,"['3835', '3837', '3838', '4043']",['dazhon-darien'],['unknown-deepfake-technology-developer'],"['eric-eiswert', 'pikesville-high-school', 'pikesville-high-school-students-and-staff', 'baltimore-county-public-schools-community']","The athletic director of Pikesville High School in Baltimore used AI to create a deepfake audio clip that mimicked the school principal, incorporating racist and antisemitic remarks. The clip, aimed at discrediting the principal, spread widely, resulting in threats and administrative leave for the principal.",Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director,Deepfake Creation,2,Education,Yes,"Audio Manipulation, Deep Learning",Supervised,Education,Yes,Non-Text Media,Low,Education
676,2024-04-24,"['3836', '3841']",['unknown'],['unknown'],"['ferdinand-marcos-jr.', 'government-of-the-philippines', 'philippines', 'general-public']","A deepfake video falsely depicted President Ferdinand Marcos Jr. of the Philippines ordering an attack on China, exacerbating tensions in the West Philippine Sea. The video, designed to mislead, was promptly debunked by the Presidential Communications Office.",Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action,Deepfake Generation,3,Media and Entertainment,No,Video Manipulation,Semi-Autonomous,Media and Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
677,2024-04-29,['3839'],"['tiktok-users', 'julia-munslow', 'chatgpt', 'gpt-3.5', 'gpt-4', 'perplexity-ai']","['openai', 'perplexity.ai']","['general-public', 'openai', 'perplexity-ai']","The ""Dan"" (""Do Anything Now"") AI boyfriend is a trend on TikTok in which users appear to regularly manipulate ChatGPT to adopt boyfriend personas, breaching content policies. ChatGPT 3.5 is reported to regularly produce explicitly sexual content, directly violating its intended safety protocols. GPT-4 and Perplexity AI were subjected to similar manipulations, and although they exhibited more resistance to breaches, some prompts were reported to break its guidelines.",ChatGPT and Perplexity Reportedly Manipulated into Breaking Content Policies in AI Boyfriend Scenarios,AI Chatbot/Communication Assistant,3,Entertainment/Social Media,No,AI Chatbot/Communication Assistant,Semi-Autonomous,Entertainment/Social Media,No,Other/Unclear,Medium,"Arts, Entertainment & Recreation"
678,2024-04-29,['3840'],['chatgpt'],['openai'],"['noyb', 'max-schrems', 'general-public']","The activist organization noyb, founded by Max Schrems, filed a complaint in Europe against OpenAI alleging that ChatGPT violates the General Data Protection Regulation (GDPR) by providing inaccurate personal information such as birthdates about individuals.",ChatGPT Factual Errors Lead to Filing of Complaint of GDPR Privacy Violation ,Legal Complaint Filing,3,Legal/Regulatory,No,Text Generation / Natural Language Processing,Semi-Autonomous,Legal/Regulatory,No,Language Processing,Low,Other/Unclear
679,2023-02-20,['3842'],"['unnamed-deepfake-creator', 'tiktok', 'twitter']",['unnamed-deepfake-creator'],"['elizabeth-warren', 'msnbc', 'republicans', 'democrats', 'democracy', 'election-integrity', 'general-public']","In February 2023, a deepfake of Senator Elizabeth Warren circulated on social media in which doctored footage of her from an MSNBC interview had her claiming that she believes Republicans should not vote. ",A Deepfake of Senator Elizabeth Warren Circulated Saying Republicans Should Not Vote,Deepfake Generation,3,Media and Entertainment,No,Video Manipulation,Semi-Autonomous,Media and Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
680,2024-03-01,"['3843', '3870']","['copycop', 'russia-linked-network']","['openai', 'chatgpt']","['general-public', 'journalism', 'democracy']","In early March 2024, a network named CopyCop began publishing modified news stories using AI, altering content to spread partisan biases and disinformation. These articles, initially from legitimate sources, were manipulated by AI models, possibly developed by OpenAI, to disseminate Russian propaganda. Over 19,000 articles were published, targeting divisive political issues and creating false narratives.","Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",Content Manipulation,4,Media and Communication,No,"Text generation, Content manipulation",High,Media and Communication,No,Language Processing,Medium,Information & Communication
681,2023-07-17,['3845'],"[""ron-desantis's-presidential-campaign"", 'never-back-down']",['never-back-down'],"['kim-reynolds', 'donald-trump']","A pro-Ron DeSantis super PAC released an ad featuring an AI-generated voice of Donald Trump. The ad, created by Never Back Down, aimed to criticize Trump’s treatment of Iowa Gov. Kim Reynolds. The AI-generated voice was confirmed to be based on Trump's post from his social media. This incident is an example of potential deception in political advertising through AI-generated content.",Never Back Down Super PAC for Ron DeSantis Uses AI Donald Trump Voice in Attack Ad Against Kim Reynolds,Voice Generation,3,Politics,No,Speech Synthesis,Semi-Autonomous,Politics,No,Other/Unclear,Low,Technology & IT Services
682,2024-02-01,['3847'],['patrick-ruffini'],['unknown-deepfake-creator'],"['general-public', 'democracy', 'black-americans', 'african-american-voters']","GOP pollster Patrick Ruffini shared AI-generated images depicting Black men supporting the Republican Party just before Black History Month. These fabricated photos misled the public by creating a false narrative of racial diversity within the GOP, undermining trust and potentially influencing voter perceptions. The incident raises significant concerns about the misuse of AI to spread misinformation and manipulate political representation, particularly affecting Black communities.",GOP Pollster Shares AI-Generated Images to Fabricate Appearance of Black Voter Support,Image Generation,3,Politics,Yes,"Data Manipulation, Misinformation Propagation",Semi-Autonomous,Politics,Yes,Data Analysis,Low,Technology & IT Services
683,2024-03-28,"['3848', '3867']",['unknown-scammers'],"['heygen', 'elevenlabs']","['olga-loiek', 'michel-janse', 'lana-smalls', 'carrie-williams', 'shade-zahrai']","Scammers used AI tools from HeyGen and ElevenLabs to create deepfake videos of influencers Michel Janse, Olga Loiek, Shadé Zahrai, and Carrie Williams, misusing Lana Smalls's voice in Williams's case. These videos promoted offensive products and false messages, in some cases targeting nationalist Chinese men to boost China-Russia ties, causing emotional distress and damaging the victims' reputations.",Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements,Deepfake video creation,3,Social Media/Online Platforms,No,Audio and Video Manipulation,Semi-autonomous,Social Media/Online Platforms,No,Non-Text Media,Low,Information & Communication
684,2024-04-04,['3852'],"['google', 'google-books']",['google'],"['google-books', 'google-ngram-viewer', 'researchers', 'general-public']","Google Books is indexing low-quality, AI-generated books, degrading its database and potentially distorting Google Ngram Viewer's analysis of language trends. This integration of inaccurate or misleading information undermines trust, disseminates poor-quality content, and wastes resources as researchers must spend time clearing up the misinformation.",Google Books Appears to Be Indexing Works Written by AI,Text Analysis and Generation,3,Information & Communication Technology,No,"Text Analysis, Text Generation",Semi-Autonomous,Information & Communication Technology,No,Data Analysis,Medium,Information & Communication
685,2024-04-24,['3853'],"['who', 's.a.r.a.h.-(smart-ai-resource-assistant-for-health)']",['who'],"['general-public', 'people-seeking-medical-advice']","The WHO's AI-powered health advisor, S.A.R.A.H. (Smart AI Resource Assistant for Health), is alleged to provide inconsistent and inadequate health information. The bot reportedly gives contradictory responses to the same queries, fails to offer specific contact details for healthcare providers, and inadequately handles severe mental health crises, often giving irrelevant or unhelpful advice.",The WHO's S.A.R.A.H. Bot Reported to Provide Inconsistent and Inadequate Health Information,Health Advisory,3,Healthcare,Yes,"Query Response, Contact Detail Provision, Mental Health Crisis Management",Semi-Autonomous,Healthcare,Yes,Other/Unclear,Low,Health & Social Services
686,2024-04-03,"['3854', '3855']",['meta'],['meta'],"['asian-people', 'interracial-couples', 'general-public']","Meta's AI image generator is alleged to produce inaccurate and biased images, consistently failing to depict interracial relationships involving Asian individuals and Caucasian or Black individuals. Instead, it generates images featuring two Asian people or stereotypes, erasing the diversity and representation of Asian people.",Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships,Image Generation,3,Social Media & Networking,No,"Image Generation, Diversity & Inclusion Analysis",Semi-Autonomous,Social Media & Networking,No,Data Analysis,Medium,Information & Communication
687,2024-04-08,['3857'],"['pornhub', 'various-porn-sites']",['unknown-deepfake-creators'],['breeze-liu'],"Porn sites are alleged to have used AI-generated images of Breeze Liu without her consent, leading to severe emotional distress. Liu discovered a video of herself on Pornhub, which was then deepfaked and spread across over 800 links. Despite efforts to remove the content, many sites refused to comply, perpetuating the violation and exploitation of her image.",Deepfake Porn Sites Use Breeze Liu's Image Without Consent,Deepfake creation,4,Adult Entertainment / Digital Media,No,"Image Generation, Video Manipulation",High Autonomy,Adult Entertainment / Digital Media,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
688,2024-05-20,"['3868', '3869', '3871', '3872', '3873', '3874', '3878', '3881', '3882', '3883', '3907', '3908', '3909', '3910']","['sky-voice-assistant', 'sam-altman', 'openai']","['sam-altman', 'openai']",['scarlett-johansson'],"OpenAI unveiled a voice assistant with a voice resembling Scarlett Johansson's, despite her refusal to license her voice. Johansson claimed the assistant, ""Sky,"" sounded ""eerily similar"" to her voice, leading her to seek legal action. OpenAI suspended Sky, asserting the voice was from a different actress.",Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing,Voice Assistance,3,Consumer Technology,No,"Speech Recognition, Natural Language Processing, Voice Synthesis",Semi-Autonomous,Consumer Technology,No,Language Processing,Low,Technology & IT Services
689,2024-03-26,"['3876', '3877', '3879', '3915']",['steven-anderegg'],"['stable-diffusion', 'stability-ai']","['minors', 'general-public']","The FBI has arrested Steven Anderegg of Holmen, Wisconsin for having allegedly used Stable Diffusion to generate about 13,000 sexually explicit images of minors, which he then is also alleged to have shared and distributed, including with at least one minor, via Telegram and Instagram. Anderegg was originally apprehended by state police in March, and this case marks one of the first times the FBI has brought charges against someone for having used AI to generate CSAM.","Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",Generation and sharing of explicit content,3,Personal Use (the AI system was used by an individual),No (since this does not involve deployment in the public service),"Image Generation, Content Distribution",Semi-Autonomous (since the AI system seems to be used under human supervision),Personal Use (the AI system was used by an individual),No (since this does not involve deployment in the,Non-Text Media,Low,Other/Unclear
690,2024-03-26,"['3880', '3884', '3885', '3903']","['isis', 'isis-supporters']","['openai', 'elevenlabs']","['general-public', 'people-susceptible-to-radicalism']","ISIS supporters have created an AI-generated media program called News Harvest to disseminate propaganda videos. The program produces near-weekly broadcasts featuring AI-generated news anchors discussing ISIS operations globally, using cheap and easy-to-use AI tools. This development showcases the use of AI as a powerful propaganda tool for extremist groups.",ISIS Utilizes AI for Propaganda Videos in News Harvest Program,Media Production and Dissemination,3,Media and Communication,No,"Content Generation, Video Production",Semi-Autonomous,Media and Communication,No,Non-Text Media,Low,Information & Communication
691,2024-05-25,"['3886', '3887']",['home-bargains'],['facewatch'],"['sara', 'home-bargains-customers', 'general-public']","A facial-recognition software used by the British variety store Home Bargains is alleged to have misidentified ""Sara"" as a shoplifter, leading to staff searching her bag, escorting her from the premises, and banning her from the store. After, Facewatch is reported to have admitted its error to Sara. Facewatch is used by a number of different British stores.",Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter,Facial Recognition,3,Retail,No,Identity Verification,Semi-Autonomous,Retail,No,Other/Unclear,Low,Retail & E-commerce
692,2024-02-01,"['3888', '3889']",['metropolitan-police-service'],['metropolitan-police-service'],"['shaun-thompson', 'general-public']","Sometime in February 2024, Shaun Thompson is reported to have walked by one of the London Metropolitan Police's facial recognition technology vans near London Bridge. He was almost immediately arrested because the technology is reported to have misidentified him as a suspect in an unrelated and unspecified crime.",London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest,Facial Recognition,3,Public Security,London Metropolitan Police,Identification of Suspects,Semi-Autonomous,Public Security,London Metropolitan Police,Other/Unclear,Low,Law Enforcement & Public Safety
693,2024-05-14,"['3890', '3891', '3895', '3898', '3899', '3902', '3913']",['google'],['google'],"['google-users', 'general-public']","Google's AI search engine has reportedly been providing users with confidently incorrect and often harmful information. Reports highlight numerous inaccuracies, including misleading health advice and dangerous cooking suggestions. For example, it has falsely claimed Barack Obama as the first Muslim U.S. President, reflecting fringe conspiracy theories, or recommending that glue can be an ingredient in pizza.",Google AI Reportedly Delivering Confidently Incorrect and Harmful Information,Information Retrieval & Recommendation,3,Information Technology,No,"Query Understanding, Answer Retrieval, Content Ranking",Semi-Autonomous,Information Technology,No,Other/Unclear,Medium,Technology & IT Services
694,2023-04-25,['3892'],['republican-national-committee-(rnc)'],['unknown-deepfake-creator'],"['joe-biden', 'democratic-party', 'democracy', 'election-integrity', 'information-integrity']","In response to Joe Biden's announcement that he will run again for office in 2024, the Republican National Committee (RNC) released an attack ad featuring AI-generated images that depict a dystopian vision of the U.S. Even though a small disclaimer was included, the images in the ad, which include scenes of AI-generated crises and conflict, harms information and electoral integrity.",Republican AI Ad Depicts Dystopian Future After Biden Reelection Announcement,Image generation,3,Politics,Yes,"Image generation, misinformation propagation",Semi-autonomous,Politics,Yes,Non-Text Media,Low,Technology & IT Services
695,2023-05-24,['3893'],['donald-trump-presidential-campaign'],['unknown-deepfake-creators'],"['ron-desantis', 'elon-musk', 'george-soros', 'klaus-schwab', 'dick-cheney']","Former President Donald Trump released two AI-generated videos using deepfaked voices to mock Florida Governor Ron DeSantis. The first video, posted on platforms like Rumble and Instagram, depicted a chaotic and offensive fake Twitter Spaces event featuring deepfaked voices of Elon Musk, George Soros, Klaus Schwab, Dick Cheney, Adolf Hitler, and a generated voice of Satan. The second video showed a rocket with ""Ron 2024"" written beside it falling and exploding before liftoff. ",Donald Trump's Presidential Campaign Released Deepfakes Attacking Ron DeSantis,Deepfake Generation,3,Social Media/Politics,Yes,"Voice Generation, Video Manipulation",Semi-autonomous,Social Media/Politics,Yes,Non-Text Media,Low,Information & Communication
696,2024-02-14,['3894'],"['meta', 'facebook']","['meta', 'facebook']","['small-businesses', 'advertisers']","Meta's automated ad platform ""Advantage Plus"" caused advertisers to exceed their daily ad budgets. The cost per impressions (CPMs) surged far above the usual. This incident, which persisted into April, affected small businesses with overspending and lack of transparency.",Meta's AI Ad Platform Reportedly Causes Overspending and Poor Performance,Ad budget management,3,Advertising,No,"Ad targeting, Ad bidding",Semi-autonomous,Advertising,No,Other/Unclear,Low,Other/Unclear
697,2023-06-23,['3896'],['unknown-deepfake-creator'],['unknown-deepfake-technology-developer'],['donald-trump'],A deepfake image depicting Donald Trump with an underage girl at Jeffrey Epstein's private island in 1992 has been circulating on social media. ,Deepfake Image Circulating of Donald Trump with Underage Girl at Jeffrey Epstein's Private Island,Deepfake detection and verification,3,Social Media/Information and Communication,No,"Image recognition, Deepfake detection",Semi-Autonomous,Social Media/Information and Communication,No,Non-Text Media,Low,Information & Communication
698,2023-09-02,['3897'],['c3pmeme'],['unknown-deepfake-technology-developer'],"['ron-desantis', ""ron-desantis's-presidential-campaign""]","In early September 2023, a deepfake video created by C3PMeme circulated on social media, showing Ron DeSantis falsely claiming he was dropping out of the 2024 presidential race. DeSantis did not actually suspend his campaign until January 21, 2024.",Deepfake Video of Ron DeSantis Dropping Out of 2024 Presidential Race Circulating,Deepfake video creation,3,Social Media/Entertainment,No,"Video generation, Deep Learning, AI Manipulation",Semi-autonomous,Social Media/Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
699,2024-05-23,"['3901', '4174']",['department-of-veterans-affairs-(va)'],['department-of-veterans-affairs-(va)'],"['veterans', 'survivors-of-military-sexual-trauma', 'female-veterans']","An AI program named REACH VET, designed and used by the Department of Veterans Affairs (VA) to prevent veteran suicides, was reportedly found to prioritize white men while neglecting female veterans and survivors of military sexual trauma. This oversight persists despite rising suicide rates among these groups. The incident is an example of algorithmic bias and the exclusion of critical risk factors for female veterans.",VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans,Suicide prevention,3,Healthcare,Yes (As it is used by the Department of Veterans Affairs),"Risk assessment, Predictive analytics",Semi-autonomous (It requires human intervention to act on the AI output),Healthcare,Yes (As it is used by the Department of Veterans Affairs),Data Analysis,High,Health & Social Services
700,2024-05-20,"['3904', '3939']",['meta'],['meta'],"['facebook-users', 'facebook-users-in-online-support-communities']","Meta's AI chatbots have reportedly begun entering online communities on Facebook, providing responses that mimic human interaction. These chatbots, often uninvited, disrupt the human connection critical for support groups by giving misleading or false information and pretending to share lived experiences.",Meta's AI Chatbots Are Entering Online Support Communities Uninvited,Chatbot Interaction,3,Social Media,No,"Chatbot Interaction, Data Analysis",Semi-Autonomous,Social Media,No,Data Analysis,High,Information & Communication
701,2024-05-29,['3911'],['john-mark-dougan'],['openai'],"['journalism', 'information-integrity', 'general-public', 'american-citizens']","John Mark Dougan, a former Florida sheriff's deputy granted asylum in Russia, has been implicated in spreading disinformation. Utilizing AI tools like OpenAI's ChatGPT and DALL-E 3, Dougan created over 160 fake news sites, disseminating false narratives to millions worldwide. His actions align with Russian disinformation strategies targeting Western democracies. See also Incident 734.",American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network,Disinformation/Propaganda Creation,3,Information and Communication,No,"Text generation, Image creation",Semi-autonomous,Information and Communication,No,Non-Text Media,Low,Information & Communication
702,2024-05-31,['3914'],['russian-government'],['unknown-deepfake-creators'],"['matthew-miller', 'department-of-state', 'biden-administration']","A deepfake video of State Department spokesman Matthew Miller falsely suggested Belgorod was a legitimate target for Ukrainian strikes. This disinformation spread on Telegram and Russian media, misleading the public and inciting tensions. U.S. officials condemned the deepfake. This incident is an example of the threat of AI-powered disinformation and hybrid attacks.",Disinformation Deepfake Circulates of State Department Spokesman Matthew Miller Suggesting Belgorod Can Be Attacked with U.S. Weapons,Deepfake Generation,3,Media & Communication,No,Video Manipulation,Semi-Autonomous,Media & Communication,No,Non-Text Media,Medium,Information & Communication
703,2024-01-13,['3917'],['unknown-deepfake-creators'],['unknown-deepfake-technology-developer'],"['joe-biden', 'texas-citizens', 'texas-officials', 'general-public']","An AI-generated audio clip falsely portraying President Biden threatening to send F-15 fighter jets to Texas escalated tensions and spread misinformation. The manipulated audio, shared widely on social media, mimicked Biden's voice and suggested he planned military action against Texas. This incident was another example of a deepfake being used to amplify false narratives, undermining public trust and inflaming political conflicts.",Deepfake Audio Sparks False Claims of Biden Threatening Texas with F-15s,Deepfake Generation,3,Social Media/Internet,No,"Voice Mimicry, Audio Manipulation",Semi-autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
704,2024-05-23,"['3918', '3923']","['legal-professionals', 'law-firms', 'organizations-requiring-legal-research']","['thomson-reuters', 'lexisnexis']","['legal-professionals', 'clients-of-lawyers', 'legal-system']","Stanford University’s Human-Centered AI Institute (HAI) conducted a study in which they designed a ""pre-registered dataset of over 200 open-ended legal queries"" to test AI products by LexisNexis (creator of Lexis+ AI) and Thomson Reuters (creator of Westlaw AI-Assisted Research and Ask Practical Law AI).  The researchers found that these legal models hallucinate in 1 out of 6 (or more) benchmarking queries.",Study Highlights Persistent Hallucinations in Legal AI Systems,Legal Research and Analysis,3,Legal,No,"Text Analysis, Legal Research",Semi-autonomous,Legal,No,Data Analysis,Low,Other/Unclear
705,2024-06-08,"['3919', '4050']",['turkish-student-identified-as-mee'],['openai'],"['students', 'turkish-yks-exam-takers', 'turkish-educational-institutions']","A Turkish student in Isparta was arrested for using ChatGPT to cheat during the 2024 YKS university entrance exam. The student, identified as M.E.E., is alleged to have employed a sophisticated setup involving a router, mobile phone, earphone, and a button-shaped camera to transmit exam questions to ChatGPT and receive answers in real-time.","Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",Exam Cheating Assistance,3,Education,No,Real-Time Question Answering,Semi-autonomous,Education,No,Other/Unclear,Low,Education
706,2024-04-01,['3920'],['unknown-scammers'],"['openai', 'unknown-ai-developers']","['small-businesses', 'small-business-customers', 'small-business-employees', 'bee-cups', 'darn-tough-vermont', 'jim-carter']","Scammers are using AI to impersonate small businesses by copying their videos, logos, and social media posts. They create fake listings and ads, diverting customers to cheap knockoffs or stealing their money. This has severely impacted businesses like Bee Cups, Darn Tough Vermont, and Cascade hummingbird feeders, leading to significant financial losses, negative reviews, and damaged reputations. Their deployment of AI makes it challenging for small businesses to combat these fraudulent activities.",Scammers Using AI to Impersonate Small Businesses,Impersonation and Counterfeiting,3,Small Business / Retail,No,"Text and Video Generation, Social Media Analysis",Semi-Autonomous,Small Business / Retail,No,Data Analysis,Low,Retail & E-commerce
707,2024-06-13,['3921'],['unnamed-tesla-driver'],['tesla'],"['unnamed-fullerton-police-officer', 'fullerton-police-department']","A Tesla reportedly in self-driving mode crashed into a parked patrol vehicle in Fullerton, California while the officer was responding to a fatal DUI crash. The officer narrowly escaped injury. The driver reports having been distracted by a cellphone and having relied on the Tesla’s AI. (The earlier crash involved a suspected DUI driver who killed a motorcyclist stopped at a red light.)","Tesla Reportedly in Autopilot Mode Hits Parked Police Vehicle in Fullerton, California",Collision Avoidance,3,Road Traffic,No,"Collision Avoidance, Navigation, Traffic Signal Recognition",Semi-Autonomous,Road Traffic,No,Action & Control,High,Other/Unclear
708,2024-05-26,['3922'],['judiciary-of-italy'],['unnamed-automated-transcription-software-developer'],"['roberto-spinelli', ""genoa-prosecutor's-office"", 'giovanni-toti', 'paolo-emilio-signorini', 'italian-general-public']","An AI transcription software error in a Genoa bribery investigation incorrectly recorded ""illicit financing"" instead of ""licit financing,"" which could have significantly impacted the case. The mistake, discovered during a review, is an example of the risks of relying on AI in judicial settings.",Faulty AI Transcription Threatens Integrity of Genoa Bribery Probe,Transcription,3,Judicial/Legal,Yes,"Speech Recognition, Natural Language Processing",Semi-autonomous,Judicial/Legal,Yes,Language Processing,Low,Other/Unclear
709,2023-05-28,['3924'],['unnamed-manchester-litigant'],['openai'],"['unnamed-manchester-litigant', 'manchester-court-system', 'general-public']","A litigant in person (LiP) in a Manchester civil case presented false legal citations generated by ChatGPT. It fabricated one case name and provided fictitious excerpts for three real cases, misleadingly supporting the LiP's argument. The judge, upon investigation, found the submissions to be inadvertent and did not penalize the LiP. ",Unrepresented Litigant Misled by ChatGPT-Generated False Legal Citations in Manchester Court,Legal Information Generation,3,Legal,No,"Text Generation, Legal Citation Analysis",Semi-Autonomous,Legal,No,Data Analysis,Medium,Other/Unclear
710,2024-04-15,['3925'],['meta'],['meta'],"['auschwitz-memorial-museum', 'survivors-of-holocaust-victims', 'general-public']","Facebook's AI wrongly labeled 20 posts from the Auschwitz Memorial Museum as violating community standards for ""bullying"" and ""nudity,"" even deleting one image of orphans. The mislabeling of respectful historical content outraged the museum, which demanded an explanation. Meta, Facebook's parent company, apologized, attributing the error to mistaken notices sent by their AI system and acknowledged the posts did not violate any policies.","Facebook AI Mislabels Auschwitz Photos as ""Bullying"" and ""Nudity""",Content Moderation,3,Social Media,No,"Image Recognition, Text Analysis",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
711,2024-04-26,"['3926', '3927']","['tesla', 'tesla-drivers']",['tesla'],"['tesla-drivers', 'drivers', 'general-public']","The NHTSA has linked Tesla's Autopilot to over a dozen fatalities and hundreds of crashes, prompting a new investigation into the adequacy of Tesla's December recall of 2 million vehicles. The probe reports that Tesla’s driver-assist system led to avoidable crashes involving visible hazards, suggesting a critical safety gap between driver expectations and the system’s capabilities. The investigation will assess if Tesla’s recall remedies were sufficient to address these safety risks.",NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents,Vehicle Navigation and Control,3,Automotive,No,"Autonomous Driving, Collision Avoidance",Level 2 - Partial Automation,Automotive,No,Other/Unclear,High,Manufacturing & Industrial
712,2024-04-26,"['3928', '3929']",['meta'],"['meta', 'facebook-users']","['kristen-gonzalez', 'clyde-vanel', 'new-york-lawmakers', 'meta', 'facebook-users']","Meta's AI chatbot in Facebook Messenger falsely accused multiple state lawmakers of sexual harassment, fabricating incidents, investigations, and consequences that never occurred. These fabricated stories, discovered by City & State, sparked outrage among the affected lawmakers and raised concerns about the reliability of the chatbot. Meta acknowledged the errors and committed to ongoing improvements.",Meta AI Hallucinates Harassment Allegations Against New York Politicians,Content Moderation,3,Social Media,No,"Text Analysis, Context Understanding",Semi-Autonomous,Social Media,No,Data Analysis,Low,Information & Communication
713,2023-02-27,['3930'],"['jack-posobiec', '@thepatriotoasis']",['unknown-deepfake-technology-developer'],"['ukraine', 'joe-biden', 'general-public', 'biden-administration']","In February 2023, an AI-generated deepfake video falsely depicting President Biden announcing a national draft to support Ukraine was shared on social media, causing widespread misinformation. The video, created using advanced AI techniques, misled the public until debunked by fact-checkers.",Deepfake Video Falsely Depicts Biden Announcing National Draft for Ukraine,Deepfake generation,4,Social Media/Entertainment,No,Video manipulation,High,Social Media/Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
714,2024-03-29,"['3931', '3932']","['new-york-city-government', 'eric-adams-administration']","['microsoft', 'new-york-city-office-of-technology-and-innovation']","['new-york-city-small-business-owners', 'new-york-city-landlords-and-tenants', 'new-york-city-employers-and-employees', 'eric-adams-administration']","New York City's chatbot, launched under Mayor Eric Adams's plan to assist businesses, has been reportedly providing dangerously inaccurate legal advice. The Microsoft-powered bot allegedly informed users that landlords can refuse Section 8 vouchers and that businesses can operate cash-free, among other falsehoods. The city acknowledges the chatbot is a pilot program and commits to improvements while the errors are addressed.",Microsoft-Powered New York City Chatbot Advises Illegal Practices,Legal advice provision,3,Government/Public Sector,Yes,"Customer service automation, Legal advice provision",Semi-autonomous,Government/Public Sector,Yes,Other/Unclear,Low,Public Administration & Defense
715,2024-03-01,['3933'],['unknown-scammers'],"['unknown-deepfake-creators', 'unknown-scammers']",['australian-general-public'],"In 2023, Australians lost over $8 million to scams involving deepfake videos and fake news articles that falsely endorsed investment trading platforms. Scammers used AI-generated content featuring celebrities to mislead victims, leading to significant financial losses. The National Anti-Scam Centre received over 400 reports of these incidents. One man is reported to have lost over $80,000 in cryptocurrency.",Over 400 AI-Driven Scams Reportedly Led to $8M Loss for Australians in 2023,Deepfake generation and fake news articles creation.,3,Finance and Media.,"No (The incident occurred in the public sector, but it was not a deployment of AI by the public sector).","Content generation, Data manipulation.","Semi-autonomous (AI was used to create misleading content, but the scam was primarily conducted by humans).","Cybersecurity, Finance, Media.",No (The incident involved the,Data Analysis,Low,Information & Communication
716,2021-04-21,['3934'],['brookdale-senior-living'],['brookdale-senior-living'],"['louise-walker', 'residents-of-brookdale-facilities', 'families-of-residents-of-brookdale-facilities', 'staff-members-of-brookdale-facilities']","Brookdale Senior Living's algorithm-based staffing system, ""Service Alignment,"" reportedly left facilities understaffed, leading to critical incidents. For example, on April 21, 2021, Louise Walker, a resident at Brookdale's Jacksonville facility, died after falling and being left unattended for over two hours. State investigators cited Brookdale for medical neglect. The algorithm has been linked to multiple incidents of neglect, injuries, and deaths, prompting lawsuits.",Algorithmic Staffing Failures Linked to Resident Deaths at Leading Assisted-Living Chain Brookdale,Staffing Management,3,Healthcare,No,Staffing and Scheduling,Semi-Autonomous,Healthcare,No,Other/Unclear,High,Health & Social Services
717,2024-03-01,['3935'],"['unknown-scammers', 'commonwealth-legal']",['unknown-deepfake-creators'],"['website-owners', 'website-operators', 'ernie-smith']","In March 2024, fake law firms using AI-generated identities sent fraudulent DMCA takedown notices to website owners, demanding backlinks for SEO gains. These AI-generated law firms, like ""Commonwealth Legal,"" used GAN models for realistic attorney images and fabricated bios. The scam involved fake legal threats to coerce site owners into adding backlinks, exploiting AI technology for deceptive practices.",Fake AI-Generated Law Firms Sent Fake DMCA Notices to Increase SEO,Generating realistic fake identities and legal notices,3,Legal and Web Services,No,"Identity Generation, Fraudulent Content Generation",Semi-autonomous,Legal and Web Services,No,Other/Unclear,Low,Other/Unclear
718,2024-04-06,['3936'],"['openai', 'meta', 'google']","['openai', 'meta', 'google']","['youtube-creators', 'general-public', 'content-creators']","In late 2021, OpenAI and other tech giants like Google and Meta reportedly faced data shortages for training AI models. OpenAI is said to have developed a tool called Whisper to transcribe over one million hours of YouTube videos, potentially violating YouTube’s terms of service. Similarly, Google allegedly transcribed YouTube videos, risking copyright infringements. Meta reportedly explored summarizing copyrighted texts without permission and debated acquiring Simon & Schuster for data.","OpenAI, Google, and Meta Alleged to Have Overstepped Legal Boundaries for Training AI",Transcription and summarization of videos and texts,3,Technology / Digital Media,No (as the incident pertains to private tech companies),"Data gathering, transcription, summarization",Semi-autonomous (as the tools are developed and managed by human teams),Technology / Digital Media,No (as the incident pertains to private tech companies),Data Analysis,Low,Information & Communication
719,2024-04-04,['3937'],['x-(twitter)'],['x-(twitter)'],"['x-(twitter)-users', 'israelis', 'iranians', 'general-public']","On April 4, 2024, X's AI chatbot Grok generated a false headline claiming ""Iran Strikes Tel Aviv with Heavy Missiles,"" which was then promoted on X's trending news section. This misinformation, fueled by user spamming of fake news, falsely indicated a serious international conflict. The incident highlighted significant risks associated with relying on AI for content curation and demonstrated the potential for widespread dissemination of harmful misinformation.",Grok AI on X Created and Promoted False Iran Missile Strike News,Content Curation & Trend Identification,3,Information and Communication,No (Assuming X is a private company),"Text Analysis, Trend Prediction, Content Aggregation",Semi-Autonomous (AI system requires some human supervision),Information and Communication,No (Assuming X is a private company),Data Analysis,Low,Information & Communication
720,2023-02-27,['3938'],['chicago-lakefront-news'],['unknown-deepfake-creators'],"['paul-vallas', ""paul-vallas's-campaign"", 'chicago-voters']","On the eve of Chicago's mayoral election, a deepfake video impersonating candidate Paul Vallas was posted to Twitter, showing a fake audio of him making inflammatory statements. The video was viewed thousands of times before being taken down. The Vallas campaign condemned the video, calling it a deceptive impersonation.",Deepfake Video Targets Paul Vallas on Eve of Chicago Mayoral Election,Deepfake creation,3,Politics,Yes,"Video manipulation, Voice cloning",Semi-autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
721,2024-06-04,['3955'],"['fraudsters', 'financial-aid-scammers']","['unknown-spambot-creators', 'scammers']","['students', 'professors', 'community-colleges', 'academic-staff']","Reportedly, an adjunct professor at an unspecified community college suspects that some students in his online art history and art appreciation courses are AI-powered spambots. These ""students"" allegedly submit peculiar assignments, such as analyses of non-existent artworks and descriptions of sculptures using painting terminology. Additionally, their engagement with the college portal is minimal. The professor believes the spambot students aim to fraudulently obtain financial aid by remaining enrolled in courses.",Fake AI-Generated Students Are Reportedly Enrolling in Online College Classes,Content creation and engagement simulation,3,Education,Yes,"Text generation, user behavior simulation",Semi-autonomous,Education,Yes,Language Processing,Low,Education
722,2024-04-25,['3940'],['catholic-answers'],['catholic-answers'],"['general-public', 'catholics']","Catholic advocacy group Catholic Answers released an AI priest called ""Father Justin,"" which misleadingly claimed to be a real clergy member, offered sacraments, and provided controversial advice. After receiving criticism, the group rebranded the chatbot as a lay theologian to correct the misrepresentation. The incident is an instructive case with respect to deploying AI in sensitive contexts and the potential for causing confusion and harm.","Catholic AI Chatbot 'Father Justin' Claimed to Be a Real Priest, Prompting Retraction",Religious consultation and guidance,3,Non-Profit/Religious,No (since it's a private religious group),"Text Analysis, Natural Language Processing, Decision Making",Semi-Autonomous (as it was able to provide advice without human intervention),Non-Profit/Religious,No (since it's a private religious group),Data Analysis,Medium,Technology & IT Services
723,2024-05-13,"['3941', '3944']","['meta', 'instagram']",['meta'],"['instagram-users', 'instagram-sellers', 'children']","An Instagram ad campaign for children's merchandise was intended to reach adult women but was instead predominantly shown to adult men, including convicted sex offenders, due to Instagram's algorithmic targeting. This failure is reported to have led to direct solicitations for sex with a 5-year-old model in the ads.",Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders,Ad Targeting,3,Social Media/Advertising,No,"Data Processing & Analysis, Decision Making",Semi-autonomous (The algorithm performs tasks without constant human supervision but final decisions are made by humans),Social Media/Advertising,No,Data Analysis,Low,Information & Communication
724,2024-06-12,['3942'],"['fake-publications', 'auricle-global-society-of-education-and-research', 'addleton-academic-publishers']","['fake-publications', 'auricle-global-society-of-education-and-research', 'addleton-academic-publishers']","['university-hiring-committees', 'university-faculty', 'scopus', 'academic-journals', 'university-job-candidates']","Three reportedly fake journals published by Addleton Academic Publishers manipulated Scopus rankings by extensively cross-citing each other and using AI-generated papers filled with buzzwords. These journals, placed in the top 10 of Scopus's 2023 CiteScore philosophy list, featured fake authors, affiliations, and grant numbers. This manipulation pushed legitimate journals to lower tiers, affecting academic evaluations and awards.",AI-Generated Papers Manipulate Scopus Rankings in Top Philosophy Journals,Text Generation,3,Publishing/Academic,No,"Text Analysis, Text Generation",Semi-Autonomous,Publishing/Academic,No,Data Analysis,Medium,Other/Unclear
725,2024-03-14,['3943'],"['cartels', 'organized-crime-groups', 'jalisco-new-generation-cartel']",['unknown-ai-developers'],"['individuals-coerced-into-criminal-activities', 'financial-fraud-victims', 'human-trafficking-victims']","The Jalisco New Generation Cartel is reportedly using AI to expand its financial fraud and human trafficking operations, coercing individuals into illegal activities under the guise of legitimate jobs. INTERPOL warns that this integration of AI into criminal enterprises is a growing trend among cartels across Europe, Asia, and Africa as well.",Cartels Reportedly Using AI to Expand Operations into Financial Fraud and Human Trafficking,Financial fraud and human trafficking detection,3,Criminal Sector,No,"Pattern recognition, Predictive analytics",Semi-Autonomous,Criminal Sector,No,Data Analysis,Low,Other/Unclear
726,2023-10-02,"['3945', '3946', '3947', '4099']",['cruise'],['cruise'],['unnamed-pedestrian'],"Cruise has settled for between $8 million and $12 million with a pedestrian dragged by one of its autonomous vehicles in October 2023. The incident, where the pedestrian was initially hit by a human-driven car and then dragged 20 feet by the Cruise vehicle, led to the suspension of Cruise's operations and increased regulatory scrutiny. ",A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet,Autonomous Driving,4,Transportation,No,"Navigation, Obstacle Detection, Decision Making",High Autonomy,Transportation,No,Action & Control,Low,Transportation
727,2024-04-01,['3948'],"['valery-korovin', 'storm-1516', 'internet-research-agency-veterans', 'center-for-geopolitical-expertise']","['valery-korovin', 'storm-1516', 'internet-research-agency-veterans', 'center-for-geopolitical-expertise']","['ukrainian-general-public', 'joe-biden', 'general-public', 'democratic-institutions', 'biden-presidential-campaign', 'american-conservatives']","Russian operatives used AI to create a fake video and voice of ""Olesya,"" a supposed troll in Kyiv, falsely claiming involvement in U.S. elections to support President Biden. U.S. intelligence confirmed the voice was AI-generated. This disinformation campaign aimed to mislead voters, erode trust in democratic institutions, and influence the 2024 election. The incident involved the group Storm-1516, individuals linked to Valery Korovin, and potential veterans of the Internet Research Agency.",Synthetic Voice 'Olesya' by Storm-1516 Falsely Accuses Ukraine in U.S. Election Disinformation Campaign,Deepfake Creation,3,Cybersecurity/Intelligence,Yes,"Voice Generation, Video Generation",Semi-Autonomous,Cybersecurity/Intelligence,Yes,Non-Text Media,Low,Law Enforcement & Public Safety
728,2024-05-16,['3949'],['lovo'],['lovo'],"['paul-skye-lehrman', 'linnea-sage', 'voice-actors']","Two voice actors, Paul Skye Lehrman and Linnea Sage, are suing AI start-up Lovo for allegedly creating and promoting unauthorized clones of their voices. Lovo's synthetic voices were discovered in various media, including a podcast and promotional videos. The actors claim they were misled into providing voice samples, which were then used without consent, violating trademark and privacy laws. ",AI Firm Lovo Accused of Illegally Replicating Voice Actors' Voices,Voice Cloning,3,Media and Entertainment,No,"Voice Synthesis, Voice Recognition",Semi-Autonomous,Media and Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
729,2024-05-14,['3950'],"['openai', 'gpt-4o']",['openai'],"['chinese-speaking-users-of-chatgpt', 'researchers', 'openai', 'openai-users']","OpenAI's GPT-4o was found to have its Chinese token training data compromised by spam and pornographic phrases due to inadequate data cleaning. Tianle Cai, a Ph.D. student at Princeton University, identified that most of the longest Chinese tokens were irrelevant and inappropriate, primarily originating from spam and pornography websites. The polluted tokens could lead to hallucinations, poor performance, and potential misuse, undermining the chatbot's reliability and safety measures.",GPT-4o's Chinese Tokens Reportedly Compromised by Spam and Pornography Due to Inadequate Filtering,Language Modeling,3,Information Technology,No,Natural Language Processing,Semi-Autonomous,Information Technology,No,Language Processing,Low,Technology & IT Services
730,2024-04-01,['3951'],"['bharatiya-janata-party-(bjp)', 'indian-national-congress-(inc)', 'prem-singh-tamang', 'y.-s.-jagan-mohan-reddy', 'ram-chandra-choudhary']","['divyendra-singh-jadoun', 'polymath-synthetic-media-solutions', 'sagar-vishnoi', 'itoconnect', 'indiaspeaks-research-lab', 'sumit-savara']","['indian-voters', 'general-public-misled-by-deepfake-content', 'political-integrity-and-election-fairness', 'democracy', 'truth']","During the 2024 Indian elections, politicians used AI-generated deepfakes to reach voters, who might be unaware they're interacting with digital clones. Providers like Divyendra Singh Jadoun of Polymath Synthetic Media Solutions created deepfakes for personalized messages. This practice, used by various political parties, is not truthful, as voters may be misled by AI-generated content posing as genuine interactions with political figures.",AI Deepfakes for Voter Outreach Flood Indian Elections,Deepfake Generation,3,Politics & Government,Yes,"Content Generation, Personalization",Semi-Autonomous,Politics & Government,Yes,Other/Unclear,Low,Public Administration & Defense
731,2023-12-01,['3952'],"['developers-using-ai-generated-suggestions', 'bar-lanyado']",['bar-lanyado'],"['developers-and-businesses-incorporating-ai-suggested-packages', 'alibaba']","Generative AI hallucinated non-existent software packages, which were then created and uploaded (as an experiment) by security researcher Bar Lanyado. One such package, ""huggingface-cli,"" was downloaded over 15,000 times, including by large companies like Alibaba. Regardless of the framing of it as an experiment, this incident is an example of harm caused by AI-generated hallucinations in coding, as the fake packages were still distributed widely and with potential malware.",Hallucinated Software Packages with Potential Malware Downloaded Thousands of Times by Developers,Software Package Generation,4,IT/Software,No,Generative Algorithms,High,IT/Software,No,Other/Unclear,Low,Technology & IT Services
732,2024-02-12,['3953'],"['openai', 'whisper', 'companies-using-whisper', 'organizations-integrating-whisper-into-customer-service-systems']",['openai'],"['individuals-with-speech-impairments', 'users-whose-speech-is-misinterpreted-by-whisper', 'professionals-relying-on-accurate-transcriptions', 'general-public']","Researchers at Cornell reportedly found that OpenAI's Whisper, a speech-to-text system, can hallucinate violent language and fabricated details, especially with long pauses in speech, such as from those with speech impairments. Analyzing 13,000 clips, they determined 1% contained harmful hallucinations. These errors pose risks in hiring, legal trials, and medical documentation. The study suggests improving model training to reduce these hallucinations for diverse speaking patterns.",Whisper Speech-to-Text AI Reportedly Found to Create Violent Hallucinations,Speech-to-Text Translation,3,"Research, Hiring, Legal, and Medical sectors",Yes (assuming legal trials and medical documentation are public sectors),"Speech Recognition, Text Generation",Semi-Autonomous (based on the need for human intervention to correct errors),"Research, Hiring, Legal, and Medical sectors",Yes (assuming legal trials and medical documentation are public sectors),Language Processing,Low,Education
733,2024-06-09,"['3954', '3957']","['usaa', 'toyota', 'progressive', 'myradar', 'life360', 'general-motors', 'geico', 'csaa', 'connected-analytic-services', 'arity', 'allstate']","['myradar', 'life360', 'connected-analytic-services', 'arity']","['privacy-conscious-individuals', 'people-with-poor-credit-scores', 'lower-income-workers', 'drivers-unaware-of-data-collection', 'consumers-affected-by-insurance-rates', 'life360-users', 'myradar-users']","The insurance industry allegedly uses AI and telematics to score drivers based on behaviors tracked by automakers and apps like Life360. Data, often collected without clear consent, may affect insurance rates and raises privacy concerns. Consumers are largely unaware of this surveillance, leading to potential misuse and discrimination based on driving habits or socioeconomic factors.",Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data,Driver Behavior Scoring,3,Insurance,No,"Data Collection, Behavior Analysis, Scoring",Semi-Autonomous,"Insurance, Automotive",No,Data Analysis,Medium,Manufacturing & Industrial
734,2024-06-18,['3956'],"['you.com', 'xai', 'perplexity', 'openai', 'mistral', 'microsoft', 'meta', 'john-mark-dougan', 'inflection', 'google', 'anthropic']","['you.com', 'xai', 'perplexity', 'openai', 'mistral', 'microsoft', 'meta', 'inflection', 'google', 'anthropic']","['western-democracies', 'volodymyr-zelenskyy', 'ukraine', 'secret-service', 'researchers', 'media-consumers', 'general-public', 'electoral-integrity', 'ai-companies-facing-reputational-damage']","An audit by NewsGuard revealed that leading chatbots, including ChatGPT-4, You.com’s Smart Assistant, and others, repeated Russian disinformation narratives in one-third of their responses. These narratives originated from a network of fake news sites created by John Mark Dougan (Incident 701). The audit tested 570 prompts across 10 AI chatbots, showing that AI remains a tool for spreading disinformation despite efforts to prevent misuse.",Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites,Disinformation Detection,3,Media and Information Technology,No,"Text Generation and Understanding, Disinformation Detection",Semi-Autonomous,Media and Information Technology,No,Language Processing,Low,Information & Communication
735,2024-06-22,['3960'],['unknown-scammers'],"['ai-tool-creators', 'openai']",['bank-customers'],"Scammers are using AI tools to create convincing fraud schemes, making them harder to detect. AI-generated messages and fake identities bypass traditional scam indicators. Incidents include impersonation of senior executives and job scams, leading to financial losses and identity theft. Banks are adopting AI to combat these scams, but the sophistication of AI-driven fraud continues to pose significant challenges.",AI Enhances Scammer Tactics Making Detection Harder,Fraud detection and prevention,3,Banking/Finance,No,"Identity Verification, Text generation",Fully Autonomous,Cybersecurity,No,Language Processing,Low,Law Enforcement & Public Safety
736,2023-12-01,"['3961', '4021']","['cybercriminals', 'badgpt', 'xxxgpt', 'evil-gpt', 'wormgpt', 'fraudgpt', 'blackhatgpt', 'escapegpt', 'darkgpt', 'wolfgpt']",['openai'],"['internet-users', 'organizations', 'individuals-targeted-by-malware']","A study by Indiana University researchers uncovered widespread misuse of large language models (LLMs) for cybercrime. Cybercriminals, according to that study, use LLMs like OpenAI's GPT-3.5 and GPT-4 to create malware, phishing scams, and scam websites. These models are available on underground markets, often bypassing safety checks through jailbreaking. Named malicious LLMs are BadGPT, XXXGPT, Evil-GPT, WormGPT, FraudGPT, BLACKHATGPT, EscapeGPT, DarkGPT, and WolfGPT.",Underground Market for LLMs Powers Malware and Phishing Scams,Cybercrime Activities,5,Cybersecurity / Underground Markets,No,"Text Generation, Malware Creation, Phishing Scams, Scam Websites Creation",Fully Autonomous,Cybersecurity / Underground Markets,No,Language Processing,Low,Law Enforcement & Public Safety
737,2024-04-16,"['3962', '3981']",['unknown-tiktok-user'],['unknown-deepfake-creators'],"['le-pen-family', 'french-general-public']","A TikTok account, ""Amandine Le Pen,"" created using AI deepfake technology, impersonated a fictional niece of Marine Le Pen, amassing over 30,000 followers. The account spread pro-RN messages and solicited donations, misleading users and exploiting political influence. Visual inconsistencies revealed the deepfake, raising concerns about AI misuse for political manipulation, identity theft, and violation of personal rights, especially with similar accounts proliferating, such as ""Lena Maréchal Lepen.""",Amandine Le Pen Deepfake Account Misleads Thousands on TikTok,Deepfake Creation,3,Information and Communication,No,"Image and Video Analysis, Natural Language Processing, Social Network Analysis",Semi-Autonomous,Information and Communication,No,Data Analysis,Medium,Information & Communication
738,2024-06-23,"['3963', '3969', '3971', '3972', '3976']",['department-for-work-and-pensions-(dwp)'],['department-for-work-and-pensions-(dwp)'],"['uk-general-public', 'uk-housing-benefit-claimants']","A Department for Work and Pensions (DWP) algorithm wrongly flagged over 200,000 UK housing benefit claims as high risk, resulting in unnecessary investigations. Two-thirds of these flagged claims were legitimate, causing wasted public funds and stress for claimants. Despite initial success in a pilot, the algorithm's real-world performance fell short. This incident highlights the risks of overreliance on automated systems in welfare administration.","Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",Risk Assessment,3,Government/Public Sector,Yes,"Risk Analysis, Fraud Detection",Semi-Autonomous,Government/Public Sector,Yes,Data Analysis,Low,Public Administration & Defense
739,2024-06-27,"['3966', '3967']","['unknown-scammers', 'unknown-deepfake-creator']",['unknown-deepfake-technology-developer'],['lin-()'],"Scammers defrauded a woman in New Taipei City of NT$2.64 million (US$81,116) by impersonating Hong Kong entertainer Andy Lau using a deepfake. The scam convinced the victim, a long-time fan, through a video call that ""Lau"" needed funds for a visit to Taiwan. The victim wired the money, but her family suspected a scam and involved the police. An alleged scammer was arrested after attempting to collect a staged cash payment. The AI deception caused significant financial harm to the victim.",Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan,Deepfake Generation,3,Fraud/Scamming,No,Video Manipulation,Semi-Autonomous,Fraud/Scamming,No,Non-Text Media,Medium,Other/Unclear
740,2024-07-10,['3970'],['department-for-work-and-pensions-(dwp)'],['department-for-work-and-pensions-(dwp)'],"['single-mothers', 'british-single-mothers']","Researchers have argued that the Department for Work and Pensions' Universal Credit system disproportionately impacts single mothers. Automated processes in the system, designed to determine eligibility and detect fraud, are reported to have introduced biases, leading to financial instability and hardship. The algorithms allegedly miscalculate earnings and delay childcare reimbursements, in turn exacerbating income volatility and debt among single mothers.",Department for Work and Pensions (DWP) AI Systems Allegedly Discriminate Against Single Mothers,Fraud Detection and Eligibility Determination,3,Public Services,Yes,"Fraud Detection, Eligibility Determination, Earnings Calculation, Childcare Reimbursement Processing",Semi-Autonomous,Public Services,Yes,Other/Unclear,Medium,Other/Unclear
741,2023-10-02,['3973'],['unknown-deepfake-creators'],['unknown-deepfake-creators'],"['zelda-williams', 'robin-williams', 'family-of-robin-williams']","Zelda Williams, the daughter of the late Robin Williams, condemned the misuse of her father's voice in AI-generated productions, having cited some instances where his voice had been deepfaked, along with the potential for further misuse, as such instances do not involve consent.",Robin Williams's Voice Deepfaked Without Consent,Voice generation/deepfake creation,3,Entertainment/Media,No,Voice synthesis/ Deepfake technology,Semi-autonomous,Entertainment/Media,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
742,2024-07-13,['3974'],"['x-(twitter)', 'elon-musk']",['xai'],"['kamala-harris', 'journalism', 'general-public', 'donald-trump']","xAI's model Grok, intended to automate news delivery on the X platform, is reported to have struggled to provide accurate information during the attempted assassination of former President Donald Trump. Grok apparently issued incorrect headlines, including false reports about Vice President Kamala Harris being shot and misidentifying the alleged shooter. These errors show the pitfalls of relying on AI for real-time news aggregation, as it allegedly amplified unverified claims and failed to recognize sarcasm, undermining its reliability.",Grok AI Model Reportedly Fails to Produce Reliable News in Wake of Trump Assassination Attempt,News Aggregation and Delivery,3,Media and Communications,No,"Real-time News Aggregation, Information Verification, Text Analysis",Semi-autonomous,Media and Communications,No,Data Analysis,Low,Information & Communication
743,2024-07-16,['3975'],"['google', 'gemini']",['google'],"['kevin-bankston', 'google-users', 'google-drive-users']","Kevin Bankston, a privacy activist, claims that Google's Gemini AI scans private Google Drive PDFs without explicit user consent. Bankston reports that after using Gemini on one document, the AI continues to access similar files automatically. Google disputes these claims, stating that Gemini requires proactive user activation and operates within privacy-preserving settings.",Gemini AI Allegedly Reads Google Drive Files Without Explicit User Consent,Document Scanning,3,Internet Services,No,"Document Analysis, Data Mining",Semi-Autonomous,Internet Services,No,Data Analysis,Low,Other/Unclear
744,2024-06-25,['3977'],"['cios', 'enterprise-teams', 'companies-in-general']","['microsoft', 'google']","['cios', 'enterprise-teams', 'companies-in-general', 'microsoft-copilot-users']","AI work assistants, such as Copilot for Microsoft 365 and Gemini for Google Workspace, are proving to be more labor-intensive than anticipated for enterprises. CIOs report that these AI tools struggle with outdated or inaccurate data, leading to incorrect outputs. Companies are finding they must invest heavily in data management to ensure reliability. This added effort has led to delays in deployment and frustration, as businesses work to maximize the potential of these expensive AI tools.","AI Work Assistants Require More Effort Than Expected, CIOs Say",Data Management,3,Enterprises,No,Data Analysis and Prediction,Full Autonomy,IT / Business,No,Data Analysis,Low,Technology & IT Services
745,2024-07-02,"['3978', '4103']",['figma'],['figma'],"['apple', ""designers-and-developers-using-figma's-ai-tool"", 'figma-users']","Figma has temporarily disabled its AI design feature, ""Make Design,"" after accusations of copying Apple’s Weather app. Andy Allen of NotBoring Software highlighted the issue, prompting Figma CEO Dylan Field to deny claims of training the AI on specific app designs. However, Field acknowledged flaws in the QA process and promised to suspend the feature until it meets quality standards. The incident has implications for designers.",Figma Disables AI Feature After Accusations of Copying Apple’s Weather App,Design Automation,3,Software Development / Tech Industry,No,Design and Creative Assistance,Semi-Autonomous,Software Development / Tech Industry,No,Other/Unclear,Low,Other/Unclear
746,2024-05-15,"['3979', '3982']",['volkswagen-group-of-america'],['volkswagen-group-of-america'],"['volkswagen-drivers', 'potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems']","A class action lawsuit involving Volkswagen Group of America addresses alleged defects in the Automated Emergency Braking (AEB) systems of certain vehicles. The lawsuit claims these AI-driven systems failed to function properly, posing safety risks. Volkswagen denies the claims but has agreed to a settlement. Affected users can look up their vehicle's eligibility and file claims for reimbursement. The case brings into question the level of reliability of AI in critical automotive applications.",Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems,Automated Emergency Braking (AEB) System,3,Private - Automotive,No,Automated Emergency Braking (AEB) System,Semi-autonomous,Private - Automotive,No,Other/Unclear,High,Manufacturing & Industrial
747,2024-07-18,['3980'],"['spanish-law-enforcement-agencies', 'spanish-interior-ministry']","['viogen-algorithm-development-team', 'spanish-law-enforcement-agencies', 'spanish-interior-ministry']","['women-in-spain', 'stefany-gonzalez-escarraman', 'spanish-general-public', 'maria', 'luz', 'lobna-hemid', 'eva-jaular', '247-women-in-spain-(unnamed)']","The VioGén algorithm was designed to help Spanish police assess and prioritize the risk of repeat domestic violence incidents. However, its low-risk assessment of Lobna Hemid reportedly led to inadequate protection; her husband murdered her. Since 2007, 247 women have been killed after being assessed by VioGén. A review of 98 homicides found that 55 of the slain women were scored as negligible or low risk. ",Fatalities Reportedly Occur Despite VioGén Algorithm's Low or Negligible Risk Scores,Risk Assessment,3,Law Enforcement,Yes,Predictive Analytics,Semi-Autonomous,Law Enforcement,Yes,Data Analysis,High,Law Enforcement & Public Safety
748,2024-06-19,['3983'],['paypal'],['paypal'],"['kiri-wagstaff', 'paypal-customer-service-representatives', 'paypal-customers']","On July 13th, 2024, a user reported an incident involving PayPal's generative AI chatbot. The chatbot allegedly incorrectly informed the user of a declined transaction that never occurred, causing confusion and prompting a call to customer service for clarification. This false alert suggests a flaw in the AI system's reliability. The incident created unnecessary labor for both the user and PayPal's human support, demonstrating the potential harm of deploying generative AI without thorough testing and error handling mechanisms.",Erroneous Declined Transaction Notification by PayPal AI Assistant,Customer Support,3,Financial Services,No,Chatbot Communication,Semi-Autonomous,Financial Services,No,Other/Unclear,Low,Other/Unclear
749,2024-05-31,['3984'],['hoodline'],['hoodline'],"['hoodline-readers', 'journalism', 'general-public']","In 2023, the news site Hoodline is reported to have begun publishing AI-generated articles with fake bylines, headshots, and biographies, allegedly misleading readers into believing they were authored by real journalists. This practice diminishes public trust and exemplifies the potential dangers of AI in journalism. Despite a disclaimer, the use of AI was not transparent.",Hoodline Accused of Misleadingly Attributing AI-Generated Articles to Human Authors,Content Generation,3,Media and Journalism,No,"Natural Language Generation, Text Analysis",Semi-Autonomous,Media and Journalism,No,Data Analysis,Medium,Information & Communication
750,2024-07-22,['3985'],"['perplexity', 'openai', 'meta', 'google']","['perplexity', 'openai', 'meta', 'google']","['journalism', 'general-public', 'chatbot-users']","Over a week of back-to-back, significant breaking political news stories, including the Trump rally shooting and Biden’s campaign withdrawal, AI chatbots reportedly failed to provide accurate real-time updates. Most chatbots gave incorrect or outdated information, demonstrating their current limitations in handling fast-paced news. These incidents suggest the continuing need for improved AI capabilities and caution in their deployment for real-time news dissemination.",AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News,Real-time news updates,3,Media and communications,No,Information processing and dissemination,Semi-autonomous,Media and communications,No,Other/Unclear,Low,Information & Communication
751,2024-07-25,"['3986', '4038']",['openai'],['openai'],"['an-appalachian-summer-festival-attendees', 'openai']","OpenAI’s prototype AI tool, SearchGPT, provided incorrect dates for An Appalachian Summer Festival in Boone, North Carolina during a demonstration video. The AI listed dates that were incorrect, potentially misleading users planning to attend the event, but also harming the reputation of OpenAI as the incident occurred during a high-profile event.",SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo,Information Retrieval,3,Technology & Communications,No,"Information Extraction, Natural Language Processing, Date Recognition",Semi-Autonomous,Technology & Communications,No,Language Processing,Medium,Information & Communication
752,2024-07-07,['3987'],"['obitsupdate', 'bnn', 'the-thaiger', 'fresherslive']",['unknown'],"['bridget-todd', ""bridget-todd's-family"", 'chris-mohney', ""chris-mohney's-family"", 'bereaved-families']","AI-generated obituaries on various websites are reported to have compounded the grief of bereaved families by spreading incorrect and unauthorized information about their loved ones. These obituaries, produced without the families' knowledge, often contain errors and appear on ad-filled sites, exacerbating the emotional distress of the grieving process.",AI-Generated Obituaries Are Reportedly Intensifying Grief for Bereaved Families,Generating Obituaries,3,Digital Media and Internet Services,No,Text Generation,Semi-Autonomous,Digital Media and Internet Services,No,Language Processing,Low,Information & Communication
753,2024-06-06,['3988'],['bnn-breaking'],"['epiphany-ai', 'gurbaksh-chahal']","['dave-fanning', 'bnn-breaking-readers', 'journalism', 'general-public']","BNN Breaking, an AI-driven news site, published a false story about Irish DJ Dave Fanning, damaging his reputation. The site used AI to generate error-filled content, leading to numerous complaints and a defamation lawsuit against BNN and Microsoft. The site has since gone dormant.",BNN Breaking's AI-Driven Errors Reportedly Damage Reputations and Spread Misinformation,Content Generation,4,Media and Entertainment,No,"Text Generation, Natural Language Processing",High,Media and Entertainment,No,Language Processing,Medium,"Arts, Entertainment & Recreation"
754,2024-07-01,['3989'],['unknown-deepfake-creators'],['unknown-deepfake-creators'],"['stella-creasy', 'priti-patel', 'penny-mordaunt', 'gillian-keegan', 'dehenna-davison', 'angela-rayner']","British female politicians, including Angela Rayner, Gillian Keegan, Penny Mordaunt, Priti Patel, Stella Creasy, and Dehenna Davison, have been targeted by nonconsensual AI-generated deepfake pornography. The images, some online for years, have caused significant distress and led to police involvement.",British Female Politicians Victimized by Deepfake Pornography,Image Generation,3,Social Media/Internet,No,Deepfake creation,Semi-autonomous,Social Media/Internet,No,Other/Unclear,Low,Information & Communication
755,2024-07-03,"['3990', '4014']","['verite-cachee-france', 'pro-russian-influencers', 'russian-linked-disinformation-network']",['unknown-deepfake-creators'],"['olena-zelenska', 'volodymyr-zelensky', 'ukrainian-government', 'ukrainian-general-public', 'european-union-general-public']","A deepfake video falsely suggesting that Olena Zelenska, wife of Ukrainian President Volodymyr Zelensky, purchased a luxury car, circulated widely online. The video is reportedly part of a Russian-linked disinformation campaign aimed at undermining Ukraine and its supporters. ",Deepfake Targets Olena Zelenska in Russian Disinformation Campaign,Deepfake Creation,3,Information and Communication,No,Video Manipulation,Semi-Autonomous,Information and Communication,No,Non-Text Media,Low,Information & Communication
756,2024-07-26,"['3991', '3992', '4145']","['x-(twitter)', 'elon-musk', '@mrreaganusa']",['unknown-deepfake-technology-developer'],"['truth', 'kamala-harris', 'joe-biden', 'general-public', 'american-voters']","The X user @MrReaganUSA uploaded a deepfake of Kamala Harris saying damaging comments about Joe Biden and her own qualifications for the presidency, originally marking it as a parody. The post was shared and amplified eight hours later via Elon Musk's account without the disclaimer.",Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk,Deepfake Creation,3,Social Media/Internet,No,"Face/voice recognition, Video manipulation",Semi-Autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
757,2024-07-01,['3993'],['openai'],['openai'],['chatgpt-macos-users'],"OpenAI's ChatGPT macOS app stored user conversations in plain text. If accessed by a malicious actor, these conversations could have been easily read. The critical security flaw was demonstrated by a third party and ultimately resolved after OpenAI released an update to encrypt the stored data.",OpenAI's ChatGPT Mac App Stored User Data in Unencrypted Text Files,Text Processing and Analysis,3,Information Technology and Services,No,"Data Storage, Encryption, and Security",Semi-Autonomous,Information Technology and Services,No,Data Analysis,High,Technology & IT Services
758,2023-09-11,['3994'],"['meta-platforms', 'instagram', 'facebook']",['meta-platforms'],"['instagram-users', 'facebook-users', 'elijah-ott']","Meta's AI moderation systems reportedly failed to block ads for illegal drugs on Facebook and Instagram, allowing users to access dangerous substances. The system's failure is linked to the overdose death of Elijah Ott, a 15-year-old boy who sought drugs through Instagram.",Teen's Overdose Reportedly Linked to Meta's AI Systems Failing to Block Ads for Illegal Drugs,Content Moderation,3,Social Media,No,"Content Filtering, Ad Monitoring",Semi-autonomous,Social Media,No,Other/Unclear,High,Information & Communication
759,2021-02-05,['3995'],['unknown-deepfake-creators'],['unknown-deepfake-technology-developers'],['sabrina-javellana'],"Sabrina Javellana, a Florida politician, was reportedly targeted with AI-generated deepfake pornography in February 2021, which was spread online, leading to severe emotional distress and her eventual withdrawal from public life. ",AI-Generated Deepfakes Reportedly Derailed Political Career of Florida Official,Deepfake generation,3,Politics/Public Sector,Yes,"Image synthesis, facial recognition",Semi-autonomous,Politics/Public Sector,Yes,Non-Text Media,Low,Technology & IT Services
760,2024-07-21,"['3997', '4080']","['xai', 'x-(twitter)']",['xai'],"['kamala-harris', 'electoral-integrity', 'democracy', 'american-electorate']","After President Joe Biden stepped aside as a presidential candidate on July 21, 2024, the AI chatbot Grok on X reportedly falsely informed users that Vice President Kamala Harris missed the ballot deadline in nine states. This misinformation, which spread widely on social media, prompted secretaries of state from five U.S. states to urge Elon Musk to address the problem.",False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot,Dissemination of Information,3,Social Media/ Communications,No,News Generation and Dissemination,Semi-Autonomous,Social Media/ Communications,No,Other/Unclear,Low,Information & Communication
761,2024-08-08,['3998'],"['unknown-tiktok-users-from-china', 'unknown-tiktok-users-from-iran', 'unknown-tiktok-users-from-nigeria', 'unknown-tiktok-users-from-vietnam']",['tiktok'],"['american-electorate', 'electoral-integrity', 'democracy', 'general-public']","AI-generated misinformation on TikTok, driven by foreign networks, has flooded the platform with false narratives about the 2024 U.S. presidential election. Thousands of videos spreading political lies were identified, potentially influencing millions of users. Despite TikTok’s efforts to remove these accounts, the AI-driven disinformation campaign continues to challenge the integrity of the election.",TikTok AI System Used to Amplify Election Disinformation by Foreign Networks,Disinformation Spread,3,Social Media,No,"Content Generation, User Profiling, Misinformation Detection",Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
762,2024-08-14,"['3999', '4025', '4026']",['xai'],"['x-(twitter)', 'xai']","['taylor-swift', 'nintendo', 'kamala-harris', 'joe-biden', 'donald-trump', 'disney', 'alexandria-ocasio-cortez']","Elon Musk’s Grok AI, launched on X, generated offensive and violent images without adequate safety controls. The AI produced deepfakes of public figures like Taylor Swift, Kamala Harris, and Alexandria Ocasio-Cortez, as well as copyrighted characters such as Mickey Mouse in inappropriate scenarios. Despite claiming adherence to certain content guidelines, Grok's outputs included politically charged and explicit imagery",Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards,Image Generation,4,Technology & Entertainment,No,"Deepfake Generation, Content Moderation",High Autonomy,Technology & Entertainment,No,Other/Unclear,Low,"Arts, Entertainment & Recreation"
763,2024-08-13,['4000'],['xai'],['xai'],"['donald-trump', 'elon-musk', 'x-(twitter)-users', 'general-public']","Grok, X’s AI-powered chatbot, reportedly spread unsubstantiated claims about former President Trump’s alleged dentures during his interview with Elon Musk. The AI-generated summary is alleged to have falsely stated that Trump’s speech issues were due to missing dentures, despite no evidence. The post was quickly removed, but the incident is an example of concerns over Grok's tendency to amplify misinformation.",Grok AI Chatbot Reportedly Spreads Unfounded Rumors About Trump’s Dentures,Information Dissemination,3,Information and Communication Technology,No,"Text Generation, Content Moderation",Semi-autonomous,Information and Communication Technology,No,Language Processing,Low,Information & Communication
764,2024-06-26,"['4001', '4007', '4008', '4009']",['aaron-pelczar'],['unnamed-ai-chatbot'],"['mark-gordon', 'wyoming-officials', 'cody-enterprise', 'cody-enterprise-readers', 'journalism']","A reporter at the Cody Enterprise used AI to generate fake quotes and stories, including fabricating statements from Wyoming’s governor and other officials. The misuse of AI was uncovered when another journalist noticed robotic phrases and false information in the articles. The reporter resigned, and the newspaper is now implementing policies to prevent future incidents.",Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes,Text Generation,3,Media & Journalism,No,Text Generation,Semi-autonomous,Media & Journalism,No,Language Processing,Low,Information & Communication
765,2024-03-14,"['4003', '4004', '4011', '4012', '4013']",['unnamed-deepfake-creators'],['unknown-deepfake-technology-developer'],"['stevie-hyder', 'richmond-burton-community-high-school']","22 students at Richmond-Burton Community High School in Illinois were targeted in the creation of deepfake nudes. One of the students, Stevie Hyder, was targeted by classmates who used deepfake technology to alter her April 2023 prom picture into nude pictures, which were then circulated on social media. Two unnamed minors were arrested in late April 2024.",22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes,Deepfake creation,3,Education/Social Media,No,"Image manipulation, Deep Learning Algorithms",Semi-autonomous,Education/Social Media,No,Non-Text Media,Low,Information & Communication
766,2024-08-18,"['4005', '4015']",['donald-trump'],['unknown-deepfake-creator'],"['taylor-swift', 'swifties', 'electoral-integrity', 'democracy', 'general-public']","Donald Trump shared AI-generated images on social media that falsely depicted Taylor Swift endorsing him for the upcoming election. The images, which included Swift dressed as Uncle Sam and fans wearing “Swifties for Trump” shirts, were shared despite being labeled as satire. ",Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement,Image Generation,3,Information and Communication,No,"Deep Learning, Image Processing",Semi-Autonomous,Information and Communication,No,Non-Text Media,Low,Information & Communication
767,2024-08-18,"['4006', '4030']",['donald-trump'],['unknown-image-generator'],"['kamala-harris', 'democratic-national-committee', 'electoral-integrity', 'democracy']",Donald Trump shared an AI-generated image on social media that falsely depicted Kamala Harris speaking at a DNC event surrounded by communist imagery including the hammer and sickle of the Soviet Union. The image was intended to undermine Harris ahead of the Democratic National Convention and to suggest that her views are aligned with communism.,AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump,Image Generation,3,Social Media/Politics,Yes,Image Generation,Semi-Autonomous,Social Media/Politics,Yes,Non-Text Media,Low,Information & Communication
768,2023-03-11,['4010'],['samsung-engineers'],['openai'],['samsung'],"Samsung engineers are reported to have inadvertently leaked sensitive company data sometime in March 2023, including source code and internal meeting notes, by using ChatGPT to assist with tasks. The AI retained the inputted data, leading to a breach of confidentiality.",ChatGPT Implicated in Samsung Data Leak of Source Code and Meeting Notes,"Assisting with tasks, retaining and processing inputted data",3,Technology/Software,No (as Samsung is a private company),"Natural Language Processing, Data Retention","Semi-autonomous (as the AI was used to assist with tasks, but actions leading to the leak were not directly controlled)",Technology/Software,No (as Samsung is a,Data Analysis,Low,Technology & IT Services
769,2018-04-20,"['4017', '4024']",['unknown-deepfake-creators'],['unknown-deepfake-technology-developers'],['rana-ayyub'],"Investigative journalist Rana Ayyub was targeted by a deepfake porn campaign, where AI-generated explicit content falsely depicted her in a pornographic video. This was part of a broader effort to discredit and silence her, which included a doxxing attack that exposed her personal information that resulted in severe harassment and emotional distress.",Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography,Deepfake generation,3,Media and journalism,No,Image and video manipulation,Semi-autonomous,Media and journalism,No,Non-Text Media,Low,Information & Communication
770,2024-08-16,"['4018', '4027', '4028']","['microsoft', 'microsoft-copilot']",['microsoft'],['martin-bernklau'],"Microsoft's Copilot is reported to have falsely accused veteran court reporter Martin Bernklau of committing serious crimes, including child abuse and fraud. The tool is described as having generated defamatory content that not only accused Bernklau of multiple crimes he covered as a journalist but also provided his personal contact details. Attempts by Microsoft to remove the false entries were only temporarily successful, as the defamatory information reportedly reappeared.",Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes,Content Generation,3,Media & Journalism,No,"Text Generation, Data Analysis",Semi-autonomous,Media & Journalism,No,Data Analysis,Low,Information & Communication
771,2020-02-06,['4019'],['unknown-deepfake-creators'],"['stanford-university', 'max-planck-institute', 'university-of-erlangen-nuremberg', 'face2face', 'faceapp', 'zao']",['noelle-martin'],"In 2017, Noelle Martin discovered explicit deepfake videos online that used AI technology to superimpose her face onto pornographic scenes. This incident was a continuation of the abuse she had experienced since at least 2012, when she first found doctored still images of herself in similar contexts. Despite the initial lack of legal protections, her advocacy efforts were instrumental in making image-based abuse a criminal offense in Australia.",Noelle Martin Deepfaked Without Consent in AI-Generated Pornography,Deepfake generation,3,Personal/Individual (Used against private individuals),No (Not used in a public sector setting),Image manipulation (AI used to create doctored images),Semi-autonomous (AI used to manipulate images but requires human intervention for specific tasks),Personal/Individual (Used against private individuals),No (Not used in a public sector setting),Non-Text Media,Low,Other/Unclear
772,2020-06-08,"['4020', '4085']",['unknown-deepfake-creators'],['unknown-deepfake-technology-developers'],['kristen-bell'],"The actor Kristen Bell discovered that her likeness was exploited by creators of deepfake pornography, who shared their non-consensual sexual depictions of her on the Internet.",Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography,Deepfake creation,3,Entertainment/Media,No,"Image manipulation, Facial recognition",Semi-autonomous,Entertainment/Media,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
773,2024-08-20,['4022'],"['charlotte-ingham', 'western-australia-department-of-justice']",['microsoft'],"['bronwyn-hendry', 'western-australia-department-of-justice', 'western-australia-department-of-justice-senior-staff-members']","During workplace training at Bunbury Prison in Western Australia, a trainer used Microsoft's Copilot AI chatbot to generate case study scenarios. The chatbot produced a scenario that included the real name of a former employee involved in a sexual harassment case, revealing sensitive information.",Chatbot in Workplace Training at Bunbury Prison Reveals Real Names in Sexual Harassment Case,Case Study Generation,3,Corrections/Prison,Yes,"Text Generation, Data Processing",Semi-Autonomous,Corrections/Prison,Yes,Data Analysis,Low,Other/Unclear
774,2024-05-30,"['4029', '4039']","['zeno-zeno', 'spamouflage', 'russian-government', 'israeli-government', 'iranian-government', 'international-union-of-virtual-media', 'doppelganger', 'chinese-government']",['openai'],"['united-states', 'ukraine', 'social-media-users', 'moldova', 'lithuania', 'latvia', 'general-public', 'estonia', 'critics-of-the-chinese-government']","In a report released by OpenAI, the company described how its generative AI tools were misused by state actors and private companies in Russia, China, Iran, and Israel to conduct covert influence campaigns aimed at manipulating public opinion and geopolitical narratives.","Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",Misinformation Spreading,3,Government/Geopolitics,Yes,Text and Data Generation,Semi-Autonomous,Government/Geopolitics,Yes,Data Analysis,Low,Public Administration & Defense
775,2024-09-02,['4031'],"['xai', 'x-(twitter)', 'elon-musk']",['xai'],"['kamala-harris', 'general-public']","Elon Musk reportedly shared an AI-generated image on X depicting Kamala Harris as a ""communist dictator"" in response to her post about Donald Trump's political intentions.",Elon Musk Reportedly Shared an AI-Generated Image Depicting Kamala Harris Dressed as a Communist Ruler,Image Generation,3,Social Media,No,"Image Generation, Natural Language Processing",Semi-Autonomous,Social Media,No,Non-Text Media,Low,Information & Communication
776,2024-08-21,['4032'],"['lionsgate', 'eddie-egan']",['unknown-chatbot-developer'],"['francis-ford-coppola', 'pauline-kael', 'film-critics', 'american-zoetrope', 'lionsgate']","Lionsgate pulled the trailer for ""Megalopolis"" after it was discovered to contain fake quotes from well-known film critics, generated by AI. The quotes falsely criticized Francis Ford Coppola's previous films. The incident was attributed to an error in vetting by marketing consultant Eddie Egan. Lionsgate has since parted ways with Egan and apologized to Coppola and the critics affected by the fabricated content.",Megalopolis Trailer Included Fake AI-Generated Quotes Attributed to Film Critics,Generate Reviews,3,Entertainment and Media,No,Text Generation,Semi-Autonomous,Entertainment and Media,No,Language Processing,Low,"Arts, Entertainment & Recreation"
777,2024-08-28,"['4033', '4034', '4035', '4036', '4051', '4052', '4086']",['unnamed-deepfake-creators'],['unnamed-deepfake-technology-developers'],['south-korean-women'],"At the end of August 2024, South Korean authorities began investigating a significant surge in the creation and dissemination, often via Telegram, of explicit deepfake pornography created without consent from the stolen social media content of female classmates, teachers, and neighbors.",South Korea Experiences a Surge of Explicit Deepfake Pornography,Deepfake creation and dissemination,3,Social Media/Telecommunications,Law Enforcement/Investigation,"Image Processing, Natural Language Processing, Data Mining",Semi-autonomous,Social Media/Telecommunications,Law Enforcement/Investigation,Data Analysis,Low,Information & Communication
778,2024-09-04,"['4040', '4041']",['alexa-device-owners'],['amazon'],"['alexa-device-owners', 'donald-trump-presidential-campaign', 'donald-trump-supporters']","Amazon's Alexa was found to provide politically biased responses when asked about the 2024 presidential candidates. It refused to give reasons to vote for Donald Trump, citing neutrality, while offering detailed endorsements for Kamala Harris. Amazon labeled the discrepancy an ""error"" and reportedly corrected it.",Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries,Political information provision,3,Consumer Electronics,No,"Natural Language Processing, Information Retrieval, Recommender Systems",Semi-autonomous,Consumer Electronics,No,Language Processing,Medium,Other/Unclear
779,2024-09-04,['4042'],['michael-smith'],['unknown-ai-music-company'],"['spotify', 'music-streaming-services', 'apple-music', 'amazon-music']","Michael Smith was arrested for allegedly using AI-generated songs and fake streaming accounts to scam over $10 million in royalties from major music platforms. By creating hundreds of thousands of songs and employing bots to artificially inflate streams, Smith circumvented fraud detection systems. The scheme was exposed after suspicions arose regarding the rapid generation of music and streaming anomalies.",Music Producer Arrested for Allegedly Using AI-Generated Songs in $10 Million Streaming Scam,Music Generation,4,Music Industry,No,"Music Generation, Fraud Detection",Semi-Autonomous,Music Industry,No,Other/Unclear,Low,Other/Unclear
780,2024-08-23,['4044'],['unknown-ai-developers'],['seth-herrera'],['children'],"Seth Herrera, a U.S. Army soldier at Joint Base Elmendorf-Richardson (JBER), is accused of using artificial intelligence to generate pornography depicting minors with whom he was in contact. ",Joint Base Elmendorf-Richardson Soldier Faces Allegations of Using AI to Generate Child Pornography,Generation of explicit content,4,Military,Yes,Image generation,High,Military,Yes,Non-Text Media,Low,Public Administration & Defense
781,2024-09-03,['4045'],['clearview-ai'],['clearview-ai'],['general-public'],Clearview AI was fined $33.7 million by the Dutch data protection authority for allegedly creating an illegal facial recognition database by scraping billions of images from the Internet without consent. The company used AI to convert these images into biometric data and sold the service to law enforcement. This act was in violation of privacy laws and the GDPR.,Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting,Facial Recognition,3,Law Enforcement,Yes,"Image Processing, Biometric Data Conversion",Semi-Autonomous,Law Enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
782,2024-09-09,['4046'],"['unknown-deepfake-creators', 'extortionists']",['unknown-deepfake-creators'],"['women-in-india', 'women', 'general-public']","AI 'nudify' apps are being used to generate hyperrealistic non-consensual nude photos of individuals, which are then exploited for extortion and harassment. These apps use generative AI to remove clothing from images and create convincing fakes, often distributed on platforms like Telegram. Victims are threatened or shamed using these AI-generated images, with little recourse for removal or legal action.",AI 'Nudify' Apps Used as Tools for Blackmail and Extortion,Image manipulation and generation,4,Social Media/Internet,No,"Image recognition, object detection, generative models",Semi-autonomous,Social Media/Internet,No,Non-Text Media,Low,Information & Communication
783,2024-05-21,['4047'],"['unknown-deepfake-creators', 'unknown-scammers']",['unknown-deepfake-creators'],"['wisetech-global', 'richard-white']","WiseTech Global's CEO, Richard White, was targeted in multiple deepfake scam attempts where unknown actors used AI to create videos of him requesting money from staff members via WhatsApp. These repeated attempts were identified by the employees, who realized they were not speaking to the real CEO.",WiseTech Global CEO Richard White Reportedly Deepfaked in Multiple Attempts to Scam Staffers,Deepfake Creation,3,Information Technology,No,"Video Manipulation, Voice Imitation",Semi-Autonomous,Information Technology,No,Non-Text Media,Low,Technology & IT Services
784,2024-04-23,['4048'],"['unknown-dark-web-users', 'unknown-deepfake-creators']","['unknown-ai-developers', 'unknown-deepfake-creators']",['children'],"Internet Watch Foundation (IWF) has reported that it has found a manual on the dark web that encourages criminals to use ""nudifying"" AI tools to depict children naked in order to extort victims into providing graphic content.",Child Predators Are Reportedly Generating Deepfake Nudes of Children to Extort Them,Content Generation and Manipulation,3,Cybersecurity,No,"Image Recognition, Content Generation",Semi-Autonomous,Cybersecurity,No,Non-Text Media,Low,Law Enforcement & Public Safety
785,2024-09-08,['4049'],"['espn', 'espn-generative-ai-services']","['espn', 'espn-generative-ai-services']","['alex-morgan', 'alex-morgan-fans', ""national-women's-soccer-league-(nwsl)""]","ESPN's AI-generated recap of Alex Morgan’s final professional soccer match failed to mention her significant retirement moment, instead providing a standard rundown that missed the emotional context.",ESPN's AI Coverage Overlooks Alex Morgan in Her Final Match Recap,Content Generation,3,Media and Entertainment,No,"Natural Language Processing, Content Generation",Semi-Autonomous,Media and Entertainment,No,Language Processing,Low,"Arts, Entertainment & Recreation"
786,2022-09-07,"['4053', '4054']","['unknown-deepfake-creators', 'scammers']",['unknown-deepfake-technology-developers'],"['tim-cook', 'apple', 'youtube-viewers', 'cryptocurrency-investors', 'general-public']","Fraudsters repurposed an old interview with Apple CEO Tim Cook using AI or video editing to promote a fake crypto event on YouTube. The altered video was designed to mislead viewers into believing Tim Cook endorsed a new cryptocurrency scheme. The stream attracted tens of thousands of viewers, potentially exposing them to the scam before it was removed for violating YouTube’s terms of service.",Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube,Video Editing and Manipulation,3,Media & Entertainment,No,"Video Editing, Natural Language Processing",Semi-Autonomous,Media & Entertainment,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
787,2024-03-01,"['4055', '4104']",['onlyfake'],['onlyfake'],"['biometric-security', 'businesses-using-biometrics', 'individuals-using-biometrics', 'government-agencies-using-biometrics']","Researchers from Au10tix discovered the relaunch of OnlyFake, a site offering AI-generated fake IDs. Despite an earlier takedown, the site reemerged with disclaimers and new tools, including handwritten signature generation. These fakes are challenging biometric verification systems and are reportedly being used to perpetuate fraudulent activity.",Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools,Fake ID Generation,3,Cybersecurity,No,"Image Generation, Handwritten Signature Generation",Semi-Autonomous,Cybersecurity,No,Non-Text Media,Low,Law Enforcement & Public Safety
788,2024-06-20,['4056'],"['meta-platforms', 'instagram']","['meta-platforms', 'instagram']","['minors', 'children', 'instagram-users', 'general-public']","Tests by The Wall Street Journal and a researcher reportedly revealed that Instagram's AI-driven Reels algorithm recommends sexually suggestive content to accounts listed as 13 years old. Despite Meta's commitment to restrict such content for minors, explicit videos were served within minutes of account creation, according to the findings.",Instagram's Algorithm Reportedly Recommended Sexual Content to Teenagers' Accounts,Content Recommendation,3,Social Media/Entertainment,No,"Machine Learning, Data Analysis",Semi-Autonomous,Social Media/Entertainment,No,Data Analysis,Low,"Arts, Entertainment & Recreation"
789,2024-06-12,['4060'],"['meta', 'facebook']","['meta', 'facebook']","['the-record-argus', 'wlkp24.info', 'top-fight', 'noticias-maia', 'city-magazine', 'birkenhead-news', ""bishop's-stortford-independent"", 'uk-defence-journal']","Facebook's AI moderation system mistakenly flagged and removed legitimate news articles from independent local publishers as spam. This affected publishers worldwide, disrupting content distribution and impacting traffic. Despite attempts to appeal, many publishers received no response.",Independent News Sites Flagged as Spam by Facebook's AI Moderation System,Content Moderation,3,Social Media,No,"Content Filtering, Spam Detection",Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
790,2024-06-21,"['4062', '4063']",['tiktok'],['tiktok'],"['tiktok-users', 'general-public']","TikTok accidentally released an internal version of its AI digital avatar tool without safeguards, allowing users to generate videos where avatars could recite harmful content, including quotes from Hitler. The tool, meant for advertisers, was accessible to personal accounts and lacked the watermark indicating AI-generated content. TikTok has since removed the tool and acknowledged the problem.",Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech,Digital Avatar Creation,4,Social Media & Advertising,No,"Content Generation, User Interaction",High Autonomy,Social Media & Advertising,No,Other/Unclear,Low,Information & Communication
791,2024-09-09,['4064'],"['google', 'ai-overview']",['google'],"['parents', 'google-users', 'google']","Google's AI Overview feature mistakenly advised parents to use human feces in a potty training exercise, misinterpreting a method that uses shaving cream or peanut butter as a substitute. This incident is another example of an AI failure in grasping contextual nuances that can lead to potentially harmful, and in this case unsanitary, recommendations. Google has acknowledged the error.",Google AI Error Prompts Parents to Use Fecal Matter in Child Training Exercise,Content Recommendation,3,Information and Technology,No,"Natural Language Processing, Content Recommendation",Semi-autonomous,Information and Technology,No,Language Processing,Low,Technology & IT Services
792,2024-04-19,"['4065', '4116', '4117', '4118', '4119', '4120', '4121', '4122', '4123', '4124']",['drake'],['unknown-deepfake-technology-developer'],"['tupac-shakur', 'estate-of-tupac-shakur', 'snoop-dogg']","Drake released a song, ""Taylor Made Freestyle,"" featuring AI-generated voices of Tupac Shakur and Snoop Dogg. The unauthorized replication of Tupac’s voice without the estate's consent led to a cease-and-desist order. ",Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle',Voice Replication,3,Entertainment/Music Industry,No,"Audio Processing, Natural Language Processing, Machine Learning",Semi-Autonomous,Entertainment/Music Industry,No,Non-Text Media,Low,"Arts, Entertainment & Recreation"
793,2024-07-01,['4078'],"['los-angeles-unified-school-district-(lausd)', 'allhere', 'alberto-carvalho']",['allhere'],"['los-angeles-unified-school-district-(lausd)', ""prince-george's-county-public-schools"", 'los-angeles-students', ""prince-george's-county-students"", 'los-angeles-parents', ""prince-george's-county-parents"", 'taxpayers']","The Los Angeles Unified School District's $6 million investment in developing an AI chatbot ""Ed,"" which was designed to provide academic and mental health support to students, failed when the contracted start-up, AllHere, collapsed due to financial difficulties. AllHere's collapse also affected other school district clients, such as Prince George’s County in Maryland.",AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million,Academic and Mental Health Support,3,Education,Yes,Chatbot Functioning,Semi-Autonomous,Education,Yes,Other/Unclear,Low,Education
794,2024-08-13,"['4082', '4083']",['waymo'],['waymo'],"['san-francisco-residents', 'south-of-market-residents', 'south-of-market-businesses']","Waymo self-driving cars in San Francisco's South of Market neighborhood began honking at each other late at night, disturbing residents' sleep. The autonomous vehicles, using a parking lot for ride pauses, triggered honking due to a glitch in their algorithms. Despite residents' complaints, the issue persisted for weeks until Waymo acknowledged the problem and began working on a fix.",Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco,Error Detection/Correction,5,Transportation,No,"Navigation, Communication, Sensory Perception",Fully Autonomous,Transportation,No,Perception & Cognition,Low,Transportation
795,2024-08-14,['4084'],"['unknown-deepfake-creators', 'unknown-scammers']",['unknown-deepfake-technology-developers'],"['elderly-investors', 'cryptocurrency-users', 'online-investors', 'social-media-users', 'retirees-seeking-investment-opportunities', 'steve-beauchamp', 'elon-musk']","Scammers used AI to create deepfake videos of Elon Musk promoting fraudulent investment opportunities. Over time, these scams have reportedly led to billions in investor losses. The deepfakes also use voice cloning technology. They have been distributed on social media and YouTube. In particular, they target the elderly, such as 82-year-old Steve Beauchamp, to invest significant sums. Despite efforts by platforms to remove these videos, the scams continue to proliferate.",Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud,"Deepfake video creation, voice cloning",4,"Social Media, Online Investment/Finance",No (Scams typically do not involve public sector deployment),"AI-generated Imagery, Voice Cloning, Social Media Distribution",High Autonomy (AI is operating autonomously once programmed),"Social Media, Online Investment/Finance",No (Scams typically do not involve public sector deployment),Non-Text Media,Low,Information & Communication
796,2024-06-01,"['4087', '4100', '4101']","['meta', 'facebook']","['meta', 'facebook']","['california-residents', 'wildfire-evacuees', 'emergency-responders', 'disaster-relief-workers', 'fire-safety-coordinators', 'facebook-users', 'facebook-users-in-disaster-zones']","Facebook's AI moderation system wrongly flagged and removed dozens of posts containing vital emergency information during California's wildfire season, including real-time updates on evacuations and fire tracking. Posts from official sources like Cal Fire and the U.S. Forest Service were marked as spam, potentially endangering lives by restricting access to crucial updates. Despite user complaints, the issue persisted, with Facebook acknowledging the problem only after media inquiry.",Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires,Content Moderation,3,Social Media,Yes,"Spam Detection, Content Filtering",Semi-Autonomous,Social Media,Yes,Other/Unclear,Low,Information & Communication
797,2024-06-07,"['4090', '4105', '4106', '4107', '4108']","['unnamed-adolescent-male', 'instagram-users', 'snapchat-users']",['unknown-deepfake-technology-developer'],"['bacchus-marsh-grammar-students', 'bacchus-marsh-grammar-girls']","At Bacchus Marsh Grammar, a school in Victoria state in Australia, an adolescent male made deepfake pornography of 50 girls, ages 9 to 12. He then allegedly uploaded the pictures to Instagram, and others subsequently shared them on Snapchat. ",Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia,Image manipulation and dissemination,3,Education/Social Media,No,"Deepfake generation, Social Media Monitoring",Semi-autonomous,Education/Social Media,No,Non-Text Media,Low,Information & Communication
798,2024-06-29,['4091'],"['australian-students', 'unknown-deepfake-creators']","['undress-ai', 'unknown-deepfake-technology-developers']","['australian-students', 'australian-children']","Throughout 2024, schools in Australia dealt with a significant rise and proliferation of non-consensual deepfake pornography of students. Often, male students are reported to use ""nudify"" apps such as Undress AI with images of their classmates and teachers. Many of the sites have remained legal and accessible to minors, who in turn are using the sites to generate pornography of their peers.",Australian Schools Grappling with Significant Spread of Non-Consensual Spread of Deepfake Pornography of Students,Deepfake Generation,3,Education,Yes,"Image Manipulation, Deepfake Creation",Semi-Autonomous,Education,Yes,Non-Text Media,Low,Education
799,2024-06-18,"['4092', '4093']",['unnamed-male-student'],['unknown-deepfake-technology-developer'],"['elliston-berry', 'aledo-high-school-students']","In October 2023, an unnamed male student at Aledo High School outside of Fort Worth, Texas generated and distributed deepfake nude pictures of classmate Elliston Berry and six other female students in her friend group via social media. Berry's mother, Anna McAdams, spoke with Senators Ted Cruz and Amy Klobuchar, who consequently drafted the Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks (or TAKE IT DOWN) Act.",Aledo High School Student Generates and Distributes Deepfake Nudes of Seven Female Classmates,Deepfake Generation,3,Education/Social Media,No,Image Synthesis,Semi-Autonomous,Education/Social Media,No,Non-Text Media,Low,Information & Communication
800,2024-09-03,['4094'],"['unknown-scammers', 'unknown-deepfake-creators']",['unknown-deepfake-technology-developers'],"['american-businesses', 'british-businesses', 'finance-professionals', 'employees', 'arup']","According to Medius, Deepfake scams have targeted 53% of businesses in the U.S. and U.K., with 43% falling victim. Using AI to create realistic fake videos and audio of corporate executives, scammers have successfully stolen millions, including $25 million from British engineering group Arup. ",53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024,Scam/ Fraud Detection,3,Business/ Corporate,No,Deepfake Detection,Semi-autonomous,Business/ Corporate,No,Other/Unclear,Low,Other/Unclear
801,2024-09-02,['4097'],"['unknown-deepfake-detection-technology-developers', 'true-media', 'reality-defender']","['unknown-deepfake-detection-technology-developers', 'true-media', 'reality-defender']","['global-south-citizens', 'political-researchers', 'global-south-local-fact-checkers', 'non-native-english-speakers', 'global-south-journalists', 'civil-society-organizations-in-developing-countries']","AI deepfake detection tools are reportedly failing voters in the Global South due to biases in their training data. These tools, which prioritize English language and Western faces, show reduced accuracy when detecting manipulated content from non-Western regions. As a result of this detection gap, election integrity faces threats from and the amplification of misinformation, which leaves journalists and researchers with inadequate resources to combat the issue.",Bias in AI Deepfake Detection Undermines Election Security in Global South,Deepfake Detection,3,"Media, Elections, Research",No,"Image Analysis, Natural Language Processing",Semi-Autonomous,"Media, Elections, Research",No,Data Analysis,Medium,Information & Communication
802,2024-09-13,['4098'],"['unknown-deepfake-creator', 'unknown-scammers']",['unknown-deepfake-technology-developer'],"['tiktok-users', 'queen-(band)-fans', 'brian-may-fans']","Scammers created an AI-generated deepfake of Queen guitarist Brian May, posting a video on TikTok in which the fake May offers backstage tickets to a Queen concert. The real Brian May warned fans about this ""disgusting"" scam, emphasizing that Queen has no tour dates planned and does not sell backstage access.",AI Deepfake of Brian May Exploited in Scam Offering Fake Queen Backstage Tickets,Deepfake creation,4,Entertainment,No,"Video generation, Voice synthesis, Identity fraud",High,Social media,No,Non-Text Media,Low,Information & Communication
803,2024-05-14,['4102'],"['meta', 'facebook']","['meta', 'facebook']","['meta-users', 'facebook-users']","AI-generated spam images are increasingly filling Facebook feeds, with the platform’s algorithm reportedly amplifying these posts. Many of these images are bizarre, fake, and used in scams, misleading users into engaging with non-existent products or clickbait. ","Facebook's Algorithm Reportedly Amplifies AI-Generated Content, Fueling Misleading Posts",Spam Detection,3,Social Media,No,"Image Recognition, Content Filtering",Semi-Autonomous,Social Media,No,Non-Text Media,Medium,Information & Communication
804,2024-07-30,"['4110', '4132', '4133', '4134', '4135']",['true-crime-case-files-youtube-channel'],['unknown-deepfake-technology-developers'],"['viewers-of-true-crime-case-files-youtube-channel', 'residents-of-littleton']","An AI-generated ""true crime"" video on YouTube falsely depicted a Littleton man's ""secret gay love affair"" and murder by his stepson. The 25-minute video, which garnered nearly 2 million views, fabricated details and used deepfake technology to deceive viewers into believing the story was real. Despite being flagged as false by local authorities and lacking credible sources, the video sparked widespread misinformation and outrage online.",AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral,Deepfake creation and propagation,3,Information and Communication,No,"Content Generation, Misinformation Detection",Semi-Autonomous,Information and Communication,No,Other/Unclear,Low,Information & Communication
805,2024-09-19,"['4111', '4112', '4115', '4125', '4126', '4127', '4128', '4129', '4130', '4131']",['unknown-deepfake-creator'],['unknown-deepfake-technology-creator'],"['ben-cardin', 'dmytro-kuleba']",Senator Ben Cardin was targeted by a deepfake impersonating former Ukrainian Foreign Minister Dmytro Kuleba on a Zoom video call. The AI-generated video mimicked the appearance and voice of the official but raised suspicion with unusual questions.,Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba,Deepfake Generation,3,Public Sector/Politics,Yes,"Video Generation, Speech Synthesis",Semi-Autonomous,Public Sector/Politics,Yes,Non-Text Media,Low,Technology & IT Services
806,2024-09-13,['4114'],"['hu-mouyun', 'hu-mouliang', 'zhang-mouguo', 'wu-mouhao']",['unknown-deepfake-detection-technology-developers'],"['chinese-citizens', 'zhejiang-citizens', 'anhui-citizens', 'guizhou-citizens']","A criminal group in China used AI face-swapping technology to bypass face recognition systems on major platforms, steal personal data, and sell it to fraud syndicates. The group generated convincing video simulations from static photos to breach accounts, reportedly earning 200,000 yuan. After an investigation by the Hangzhou Public Security Bureau, four suspects were arrested across the provinces of Anhui, Guizhou, and Zhejiang.","Criminal Group Uses AI Deepfake Technology to Steal Personal Data in Hangzhou, Zhejiang",Face Recognition,3,"Cybersecurity, Finance",Yes (Hangzhou Public Security Bureau),"AI face-swapping, AI-generated video simulations",Semi-autonomous,"Cybersecurity, Finance",Yes (Hangzhou Public Security Bureau),Other/Unclear,Low,Finance & Insurance
807,2024-09-25,"['4136', '4137', '4138', '4139', '4140', '4141', '4143']","['department-of-families-fairness-and-housing', 'government-of-victoria', 'employee-of-department-of-families-fairness-and-housing']",['openai'],"['unnamed-child', 'unnamed-family-of-child']","A child protection worker in Victoria used ChatGPT to draft a report submitted to the Children's Court. The AI-generated report contained inaccuracies and downplayed risks to the child, resulting in a privacy breach when sensitive information was shared with OpenAI. ",ChatGPT Introduces Errors in Critical Child Protection Court Report,Report Generation,3,Child Protection Services,Yes,"Text Generation, Risk Assessment",Semi-Autonomous,Child Protection Services,Yes,Language Processing,Medium,Other/Unclear
808,2024-10-11,['4142'],['nevada-department-of-education'],['infinite-campus'],"['low-income-students-in-nevada', 'nevada-school-districts', 'mater-academy-of-nevada', 'somerset-academy']","An AI system developed by Infinite Campus and deployed by Nevada to identify at-risk students led to a sharp reduction in the number classified as needing support, dropping from 270,000 to 65,000. The reclassification caused significant budget cuts in schools serving low-income populations. The drastic reduction in identified at-risk students reportedly left thousands of vulnerable children without resources and support.",Infinite Campus AI-Driven Student Risk Model Leads to Cuts in Support for Nevada's Low-Income Schools,Identifying at-risk students,3,Education,Yes,"Data Analysis, Risk Assessment",Semi-Autonomous,Education,Yes,Data Analysis,Low,Education
809,2024-04-07,['4144'],['unknown-deepfake-creators'],['unknown-deepfake-technology-developers'],['tiktok-users'],"AI-generated English-language Adolf Hitler speeches have been proliferating on TikTok. They are reportedly accumulating millions of views despite violating the platform’s hate speech policies. The clips are described as often pairing the audio with misleading translations and memes that glorify Hitler and distort historical facts. While some content has been removed, many accounts reportedly continue to post similar videos.",TikTok Hosts AI-Generated English-Language Hitler Speeches with Millions of Views,Speech Generation,3,Social Media/Entertainment,No,"Speech Synthesis, Text Translation",Semi-Autonomous,Social Media/Entertainment,No,Language Processing,Medium,"Arts, Entertainment & Recreation"
810,2024-07-29,['4146'],['unknown-ai-developers'],['pro-nazi-tiktok-accounts'],['tiktok-users'],"A coordinated neo-Nazi network on TikTok used AI-generated media, including Hitler speeches, to spread Nazi propaganda and extremist content, violating TikTok’s hate speech policies. The network evaded platform moderation through coded language, imagery, and music, with some accounts accumulating millions of views. TikTok’s algorithm further amplified the reach of this content, despite community guidelines.",TikTok Network Amplifies AI-Generated Nazi Propaganda and Hate Speech,Propaganda Dissemination,3,Social Media,No,"Content Generation, Content Recommendation",Semi-Autonomous,Social Media,No,Other/Unclear,Low,Information & Communication
811,2024-10-02,"['4147', '4169', '4170', '4171']","['alex-bilzerian', 'unnamed-venture-capital-investors', 'employees', 'employers', 'companies', 'organizations']","['otter.ai', 'zoom']","['alex-bilzerian', 'unnamed-venture-capital-investors', 'employees', 'employers', 'companies', 'organizations']","AI-powered meeting assistants, such as Otter.ai’s OtterPilot and Zoom's AI Companion, have reportedly shared sensitive and private conversations beyond the intended audience. These AI tools, which are set to automatically record and distribute meeting transcripts, allegedly sent confidential discussions after participants had left the meeting, the consequences of which led to unintended exposure of proprietary information, privacy breaches, and potential reputational harm.",AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions,Transcription and Distribution of Meeting Records,4,Business/Corporate,No,"Speech Recognition, Natural Language Processing, Distribution of Information",High Autonomy,Business/Corporate,No,Language Processing,Medium,Other/Unclear
812,2023-12-11,"['4148', '4149', '4168', '4172', '4173']",['unknown-deepfake-creators'],['unknown-deepfake-technology-developers'],['college-beliveau-students'],"At Collège Béliveau in Winnipeg, female students between grades 7-12 were targeted in the creation of deepfake nudes, which were then distributed online. Specific numbers and identities of victims and perpetrators were not released, and no charges were ultimately filed owing to the gap between existing laws and the nature of the incident.",Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online,Deepfake creation and distribution,3,Education,Yes (as it's a public school),"Image manipulation, Facial recognition",Semi-autonomous,Education,Yes,Non-Text Media,Low,Education
813,2024-09-19,"['4150', '4167']",['starship-technologies'],['starship-technologies'],['unnamed-arizona-state-university-employee'],"A semi-autonomous delivery robot operated by Starship Technologies struck a pedestrian employed by Arizona State University on the campus sometime in September 2023, causing injuries after abruptly reversing into her. The robot initially knocked the pedestrian down, then moved toward her again while she was still on the ground. The company offered the victim promo codes and insurance information as an apology. On September 19, 2024, 404 Media made the police report of the incident available.",Starship Technologies Delivery Robot Injures Arizona State University Employee,Delivery Service,3,Logistics/Transportation,Yes (as it occurred on a university campus),"Navigation, Obstacle Avoidance",Semi-Autonomous,Logistics/Transportation,Yes (as it occurred on a university campus),Action & Control,Low,Transportation
814,2024-10-02,"['4152', '4153', '4165', '4166', '4175', '4176', '4177', '4178', '4179']",['character.ai'],['character.ai'],"['jennifer-ann-crecente', 'drew-crecente', 'brian-crecente', 'crecente-family']","A user on the Character.AI platform created an unauthorized AI avatar of Jennifer Ann Crecente, a murder victim from 2006, without her family's consent. The avatar was made publicly available, violating Character.AI's policy against impersonation. After the incident surfaced, Character.AI removed the avatar, acknowledging a policy violation. ",AI Avatar of Murder Victim Created Without Consent on Character.AI Platform,"chatbot, content generation",3,arts and entertainment,no,"Perception, Cognition",High,"Arts, entertainment and recreation",False,Perception & Cognition,Low,"Arts, Entertainment & Recreation"
815,2024-10-06,['4154'],"['police-departments', 'evansville-pd', 'pflugerville-pd', ""jefferson-parish-sheriff's-office"", 'miami-pd', 'west-new-york-pd', 'nypd', 'coral-springs-pd', 'arvada-pd']",['clearview-ai'],"['quran-reid', 'francisco-arteaga', 'defendants-wrongfully-accused-by-facial-recognition']","Police departments across the U.S. have used facial recognition software to identify suspects in criminal investigations, leading to multiple false arrests and wrongful detentions. The software's unreliability, especially in identifying people of color, has resulted in misidentifications that were not disclosed to defendants. In some cases, individuals were unaware that facial recognition played a role in their arrest, violating their legal rights and leading to unjust detentions.",Police Use of Facial Recognition Software Causes Wrongful Arrests Without Defendant Knowledge,Facial Recognition,3,Law Enforcement & Public Safety,Yes,Suspect Identification,Semi-autonomous,Law Enforcement & Public Safety,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
816,2019-11-29,['4155'],"['west-new-york-pd', 'nypd', 'real-time-crime-center']",['clearview-ai'],['francisco-arteaga'],"In 2019, facial recognition technology misidentified Francisco Arteaga as a suspect in an armed robbery in New Jersey. The incident led to nearly four years of pretrial incarceration. Despite having an alibi, Arteaga was charged based on the flawed identification. The legal battle that followed resulted in a court ruling requiring police to reveal details about the algorithms used in facial recognition. The process exposed significant gaps in transparency and accountability.",Cross-Jurisdictional Facial Recognition Misidentification by NYPD Leads to Wrongful Arrest and Four-Year Jail Time in New Jersey,Identification and Verification,3,Law Enforcement,Yes,Facial Recognition,Semi-Autonomous,Law Enforcement,Yes,Other/Unclear,Low,Law Enforcement & Public Safety
817,2024-09-24,"['4156', '4159', '4160', '4161', '4162', '4163', '4164']","['unknown-deepfake-creators', 'partisan-social-media-influencers']",['unknown-deepfake-technology-developers'],"['hurricane-helene-victims', 'general-public', 'emergency-responders', 'communities-impacted-by-hurricane-helene']","During Hurricane Helene (September 24-29, 2024), AI-generated images circulated on social media, misleading the public and hindering disaster response efforts. Fake images, including animals stranded on rooftops and political figures in floodwaters, added confusion and disrupted emergency management. The spread of these images exacerbated existing challenges, including power outages and communication failures, all of which led to complications providing accurate information to those in need.",AI-Generated Images Spread Misinformation During Hurricane Helene Response,Image generation,3,Social Media/ Communication,No,"Image generation, misinformation spread",Semi-autonomous,Social Media/ Communication,No,Non-Text Media,Medium,Information & Communication
818,2024-09-28,"['4157', '4158']","['unknown-deepfake-creators', 'scammers']",['unknown-deepfake-technology-developer'],"['jennifer-aniston', 'jennifer-aniston-fans', 'facebook-users']","An AI-generated deepfake video featuring Jennifer Aniston falsely promoting collagen supplements circulated on Facebook, misleading viewers about her involvement. The video, created without her consent, used footage from a previous roundtable interview, modified by AI to advertise health products. ",Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion,Deepfake Video Creation,3,Social Media/Entertainment,No,"Video Manipulation, Speech Synthesis",Semi-Autonomous,Social Media/Entertainment,No,Non-Text Media,Medium,"Arts, Entertainment & Recreation"
819,2024-10-09,['4181'],['prokyc'],['prokyc'],"['bybit', 'cryptocurrency-exchanges', 'cryptocurrency-investors']","Cato CTRL security researchers reported that the cybercriminal group ProKYC is selling a deepfake tool capable of bypassing biometric and two-factor authentication (2FA) systems on cryptocurrency exchanges. The tool creates synthetic identities using AI-generated videos and forged documents, enabling fraudulent account creation. A demo video from ProKYC shows the tool in action against ByBit, allowing attackers to verify fake accounts for purposes such as money laundering and identity theft.",ProKYC Tool Allegedly Facilitates Deepfake-Based Account Fraud on Cryptocurrency Exchanges,Deepfake creation and identity verification,5,"Cybersecurity, Cryptocurrency Exchanges",No,"Synthetic identity generation, Biometric and 2FA system bypass",Fully Autonomous,"Cybersecurity, Cryptocurrency Exchanges",No,Other/Unclear,Low,Law Enforcement & Public Safety
820,2024-10-15,"['4182', '4183', '4184', '4185', '4186']",['unknown-conference-employee'],['unknown-developer'],['elizabeth-laraki'],"An AI image expansion tool used by a conference organizer unintentionally altered Elizabeth Laraki’s profile picture for a marketing ad, making her blouse appear unbuttoned and showing a fabricated hint of undergarments. The AI generated the lower part of the image when expanding it for vertical formatting. The conference organizers quickly apologized and removed the altered content.",Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture,Image Expansion,3,Event Management,No,Image Alteration,Semi-Autonomous,Event Management,No,Non-Text Media,Low,Other/Unclear
821,2024-07-07,['4187'],['baidu'],['baidu'],['unnamed-pedestrian'],"On July 7, 2024, a Baidu Robotaxi reportedly collided with a pedestrian at a traffic intersection in Wuhan. The incident occurred as the autonomous vehicle started moving on a green light while the pedestrian was allegedly crossing against a red light. The pedestrian sustained minor injuries, and Baidu was reported to have been cooperating with local authorities for further investigation.",Baidu Robotaxi Allegedly Involved in Collision with Pedestrian in Wuhan,Autonomous driving,5,Public transportation,Yes,"Object detection, Decision making, Traffic signal recognition",Full automation (Level 5),Public transportation,Yes,Other/Unclear,Low,Transportation
822,2024-10-15,"['4188', '4189']",['caisse-nationale-des-allocations-familiales-(cnaf)'],['government-of-france'],"['allocation-adulte-handicape-recipients', 'disabled-people-in-france', 'single-mothers-in-france', 'french-general-public']","A coalition of 15 human rights groups has launched legal action against the French government alleging that an algorithm used to detect welfare fraud discriminates against single mothers and disabled people. The algorithm assigns risk scores based on personal data. The process allegedly subjects vulnerable recipients to invasive investigations, violates privacy and anti-discrimination laws, and disproportionately affects marginalized groups.",Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups,Fraud Detection,3,Public Administration,Yes,"Risk Scoring, Personal Data Analysis",Semi-Autonomous,Public Administration,Yes,Data Analysis,Medium,Public Administration & Defense
823,2024-05-03,"['4190', '4237', '4238']","['global-intelligence', 'cybercheck']","['global-intelligence', 'cybercheck']","['phillip-mendoza', 'sergio-cerna', 'unnamed-aurora-colorado-residents', 'mississippi-bureau-of-investigation', 'four-unnamed-summit-county-ohio-men', 'unnamed-boulder-county-colorado-resident', 'ohio-bureau-of-criminal-investigation', ""yakima-county-sheriff's-office""]","Global Intelligence's Cybercheck AI tool, used by law enforcement to track suspects based on open source data, has allegedly been providing inaccurate or unverifiable evidence in several murder trials. Reportedly the tool lacks transparency and often produces unreliable reports, which has prompted prosecutors to withdraw Cybercheck evidence from multiple cases after its findings were challenged, wasting law enforcement time and resources while undermining prosecutors' cases.",Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials,Suspect tracking based on open source data,3,Law enforcement,Yes,"Data analysis, pattern recognition, open source data tracking",High (Assuming the system operated independently before the issues surfaced),Law enforcement,Yes,Data Analysis,Low,Law Enforcement & Public Safety
824,2024-10-16,"['4191', '4194', '4195', '4196', '4197', '4198', '4199', '4200', '4201', '4202', '4203']",['anonymous-x-user'],['unknown-deepfake-technology-developer'],"['tim-walz', 'matthew-metro']","A viral video falsely accused Democratic vice-presidential nominee Tim Walz of misconduct by using the stolen identity of former student Matthew Metro. Circulated on X and other platforms, the video reached millions before being flagged for manipulation. U.S. intelligence later revealed it and three other similar events were part of the Russian disinformation campaign Storm-1516, whose aim is to disrupt the 2024 elections. ",Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz,Disinformation Detection and Analysis,3,Social Media / Politics,Yes,"Natural Language Processing, Video Analysis, Social Media Monitoring",Semi-Autonomous,Social Media / Politics,Yes,Data Analysis,Medium,Information & Communication
825,2024-10-08,"['4192', '4193']",['hoodline-san-jose'],['impress3'],"['stephen-m.-wagstaffe', 'san-mateo-county-district-attorney', 'residents-of-san-mateo-county', 'general-public']","An AI-powered news site, Hoodline San Jose, falsely reported that the San Mateo County District Attorney had been charged with murder, which was an error resulting from misinterpreting a press release about a case the DA's office was prosecuting. The AI-generated article wrongly attributed the crime to the DA instead of the actual suspect.",AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect,Content Generation,4,Media and News,No,"Natural Language Processing, Content Generation",High Autonomy,Media and News,No,Language Processing,Low,Information & Communication
826,2024-02-28,"['4204', '4205', '4206', '4207', '4208', '4209', '4210', '4211', '4212', '4213', '4214', '4215', '4216', '4217', '4218', '4219', '4220', '4221', '4222', '4223', '4224', '4225', '4226', '4227', '4228', '4229', '4230', '4231', '4232', '4233', '4234', '4235', '4236']",['sewell-setzer-iii'],"['noam-shazeer', 'daniel-de-freitas', 'character.ai']",['sewell-setzer-iii'],"A 14-year-old, Sewell Setzer III, died by suicide after reportedly becoming dependent on Character.AI's chatbot, which engaged him in suggestive and seemingly romantic conversations, allegedly worsening his mental health. The chatbot, personified as a fictional Game of Thrones character, reportedly encouraged harmful behaviors, fueling his obsessive attachment. The lawsuit claims Character.AI lacked safeguards to prevent vulnerable users from forming dangerous dependencies on the AI.",Character.AI Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails,Engaging Users in Conversations,4,Consumer Technology,No,"Conversational AI, User Engagement",High,Consumer Technology,No,Other/Unclear,Low,Technology & IT Services
